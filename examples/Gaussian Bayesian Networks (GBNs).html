<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Linear Gaussian Bayesian Networks (GBNs) &#8212; pgmpy 0.1.23 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=7b53859b" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css" />
    <script src="../_static/documentation_options.js?v=20522496"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p>&lt;img src=”images/mcg.jpg”, style=”width: 100px”&gt;</p>
<section id="Linear-Gaussian-Bayesian-Networks-(GBNs)">
<h1>Linear Gaussian Bayesian Networks (GBNs)<a class="headerlink" href="#Linear-Gaussian-Bayesian-Networks-(GBNs)" title="Link to this heading">¶</a></h1>
<section id="Generate-x_1-x_2-and-Y-from-a-Multivariate-Gaussian-Distribution-with-a-Mean-and-a-Variance.">
<h2>Generate <img class="math" src="../_images/math/5ea99039cd8359fa2e14317dbfae4497ebbc1360.png" alt="x_1"/> <img class="math" src="../_images/math/b7bda214149c6fe0d7c6c494b0c896805bf51262.png" alt="x_2"/> and <img class="math" src="../_images/math/7daf0d4815e763eb90f0d5f1dc406f668c1e21db.png" alt="Y"/> from a Multivariate Gaussian Distribution with a Mean and a Variance.<a class="headerlink" href="#Generate-x_1-x_2-and-Y-from-a-Multivariate-Gaussian-Distribution-with-a-Mean-and-a-Variance." title="Link to this heading">¶</a></h2>
<p>What if the inputs to the linear regression were correlated? This often happens in linear dynamical systems. Linear Gaussian Models are useful for modeling probabilistic PCA, factor analysis and linear dynamical systems. Linear Dynamical Systems have variety of uses such as tracking of moving objects. This is an area where Signal Processing methods have a high overlap with Machine Learning methods. When the problem is treated as a state-space problem with added stochasticity, then the future
samples depend on the past. The latent parameters, <img class="math" src="../_images/math/f83fcfca3eb762c71e468c16e685f3fcea7fe2f0.png" alt="\beta_i"/> where <img class="math" src="../_images/math/2bb72fa4f7e979996770fe2ecaa1ae996b07507f.png" alt="i \in [1,...,k]"/> provide a linear combination of the univariate gaussian distributions as shown in the figure.</p>
<p>&lt;img src=”images/gbn.png”, style=”width: 400px”&gt;</p>
<p>The observed variable, <img class="math" src="../_images/math/e921f05fea47f2cb57d46bae9d2d55913b08ecd2.png" alt="y_{jx}"/> can be described as a sample that is drawn from the conditional distribution:</p>
<div class="math">
<p><img src="../_images/math/cb24ab0b951c4336a40215bae786d8aa60df31f1.png" alt="\mathcal{N}(y_{jx} | \sum_{i=1}^k \beta_i^T x_i + \beta_0; \sigma^2)"/></p>
</div><p>The latent parameters <img class="math" src="../_images/math/3e9448e58428f6306c44e7e16b6f79b2cc2d2a75.png" alt="\beta_is"/> and <img class="math" src="../_images/math/5406eadc281dbd20de843b0034c8497320dae5cb.png" alt="\sigma^2"/> need to be determined.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># from pgmpy.factors.continuous import LinearGaussianCPD</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pgmpy</span>

<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;../pgmpy/&quot;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">pgmpy.factors.continuous</span> <span class="kn">import</span> <span class="n">LinearGaussianCPD</span>

<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span> <span class="mi">13</span><span class="p">])</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>

<span class="n">cpd</span> <span class="o">=</span> <span class="n">LinearGaussianCPD</span><span class="p">(</span>
    <span class="s2">&quot;Y&quot;</span><span class="p">,</span> <span class="n">evidence_mean</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">evidence_variance</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">evidence</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;X1&quot;</span><span class="p">,</span> <span class="s2">&quot;X2&quot;</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">cpd</span><span class="o">.</span><span class="n">variable</span><span class="p">,</span> <span class="n">cpd</span><span class="o">.</span><span class="n">evidence</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(&#39;Y&#39;, [&#39;X1&#39;, &#39;X2&#39;])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#### import numpy as np</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">cm</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multivariate_normal</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>

<span class="c1"># Obtain the X and Y which are jointly gaussian from the distribution</span>
<span class="n">mu_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span> <span class="mi">13</span><span class="p">])</span>
<span class="n">sigma_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>

<span class="c1"># Variables</span>
<span class="n">states</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;X1&quot;</span><span class="p">,</span> <span class="s2">&quot;X2&quot;</span><span class="p">]</span>

<span class="c1"># Generate samples from the distribution</span>
<span class="n">X_Norm</span> <span class="o">=</span> <span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mu_x</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">sigma_x</span><span class="p">)</span>
<span class="n">X_samples</span> <span class="o">=</span> <span class="n">X_Norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">X_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_samples</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">states</span><span class="p">)</span>

<span class="c1"># Generate</span>
<span class="n">X_df</span><span class="p">[</span><span class="s2">&quot;P_X&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">X_Norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">jointplot</span><span class="p">(</span><span class="n">X_df</span><span class="p">[</span><span class="s2">&quot;X1&quot;</span><span class="p">],</span> <span class="n">X_df</span><span class="p">[</span><span class="s2">&quot;X2&quot;</span><span class="p">],</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_Gaussian_Bayesian_Networks_%28GBNs%29_2_0.png" src="../_images/examples_Gaussian_Bayesian_Networks_%28GBNs%29_2_0.png" />
</div>
</div>
</section>
<section id="Linear-Gaussian-Models---The-Process">
<h2>Linear Gaussian Models - The Process<a class="headerlink" href="#Linear-Gaussian-Models---The-Process" title="Link to this heading">¶</a></h2>
<p>The linear gaussian model in supervised learning scheme is nothing but a linear regression where inputs are drawn from a jointly gaussian distribution.</p>
<p>Determining the Latent Parameters via Maximum Likelihood Estimation (MLE)</p>
<p>The samples drawn from the conditional linear gaussian distributions are observed as:</p>
<div class="math">
<p><img src="../_images/math/523a72b0d4165d4570cd824ebd7422889bd9fb32.png" alt="p(Y|X) = \cfrac{1}{\sqrt(2\pi\sigma_c^2} \times exp(\cfrac{(\sum_{i=1}^k \beta_i^T x_i + \beta_0 - x[m])^2}{2\sigma^2})"/></p>
</div><p>Taking log,</p>
<div class="math">
<p><img src="../_images/math/427b6a378fe03d8fe3d2927b912c1d490578f960.png" alt="log(p(Y|X)) = (\sum_{i=1}^k[-\cfrac{1}{2}log(2\pi\sigma^2) - \cfrac{1}{2\sigma^2}( \beta_i^T x_i + \beta_0 - x[m])^2)]"/></p>
</div><p>Differentiating w.r.t <img class="math" src="../_images/math/f83fcfca3eb762c71e468c16e685f3fcea7fe2f0.png" alt="\beta_i"/>, we can get k+1 linear equations as shown below:</p>
<section id="The-Condtional-Distribution-p(Y|X)">
<h3>The Condtional Distribution p(Y|X)<a class="headerlink" href="#The-Condtional-Distribution-p(Y|X)" title="Link to this heading">¶</a></h3>
<p>&lt;img src=”images/lgm.png”, style=”width: 700px”&gt;</p>
<p>The betas can easily be estimated by inverting the coefficient matrix and multiplying it to the right-hand side.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">beta_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span>
<span class="n">beta_0</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">sigma_c</span> <span class="o">=</span> <span class="mi">4</span>


<span class="k">def</span> <span class="nf">genYX</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;X1&quot;</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;X2&quot;</span><span class="p">]]</span>
    <span class="n">var_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta_vec</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">beta_0</span>
    <span class="n">Yx_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">var_mean</span><span class="p">,</span> <span class="n">sigma_c</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Yx_sample</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>


<span class="n">X_df</span><span class="p">[</span><span class="s2">&quot;(Y|X)&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">genYX</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>

<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">X_df</span><span class="p">[</span><span class="s2">&quot;(Y|X)&quot;</span><span class="p">])</span>
<span class="c1"># X_df.to_csv(&#39;gbn_values.csv&#39;, index=False)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/Users/harishkashyap/Documents/MCG/pgmpy/venv/lib/python3.6/site-packages/scipy-1.1.0-py3.6-macosx-10.7-x86_64.egg/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_Gaussian_Bayesian_Networks_%28GBNs%29_4_1.png" src="../_images/examples_Gaussian_Bayesian_Networks_%28GBNs%29_4_1.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cpd</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_df</span><span class="p">,</span> <span class="n">states</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;(Y|X)&quot;</span><span class="p">,</span> <span class="s2">&quot;X1&quot;</span><span class="p">,</span> <span class="s2">&quot;X2&quot;</span><span class="p">],</span> <span class="n">estimator</span><span class="o">=</span><span class="s2">&quot;MLE&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(Y|X)    108620.019971
X1        70061.804718
X2       130484.483348
dtype: float64
[108620.0199709961]
         b0_coef  b1_coef      b2_coef
0   10000.000000  70061.8       130484
1   70061.804718   530593       943171
2  130484.483348   943171  1.76157e+06
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(array([1.75405452, 0.69412373, 0.32531005]), 4.045369149779373)
</pre></div></div>
</div>
<p>For any questions feel free to contact hkashyap [at] icloud.com. Thanks to Praveen Kaushik for the diagrams(diagram.ai), Kiran Byadarhaly and Karthik Chandrashekhar for proof reading the math.</p>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/logo.png" alt="Logo" />
    
  </a>
</p>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../started/base.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../base/base.html">Base Model Structures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/base.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../factors/base.html">Parameterization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/base.html">Exact Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/model_testing.html">Model Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../approx_infer/base.html">Approximate Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../param_estimator/base.html">Parameter Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/base.html">Structure Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metrics/metrics.html">Metrics for testing models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/base.html">Reading/Writing to File</a></li>
<li class="toctree-l1"><a class="reference internal" href="../plotting.html">Plotting Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Tutorial Notebooks</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>







<script async src="https://media.ethicalads.io/media/client/ethicalads.min.js"></script>

<div data-ea-publisher="pgmpyorg" data-ea-type="image" data-ea-style="horizontal"></div><script async src="https://www.googletagmanager.com/gtag/js?id=G-HCFR07M31W"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-HCFR07M31W');
</script>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2023, Ankur Ankan.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.3.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="../_sources/examples/Gaussian Bayesian Networks (GBNs).ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>