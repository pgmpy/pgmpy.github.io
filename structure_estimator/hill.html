
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Hill Climb Search &#8212; pgmpy 0.1.23 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Tree Search" href="tree.html" />
    <link rel="prev" title="PC (Constraint-Based Estimator)" href="pc.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="hill-climb-search">
<h1>Hill Climb Search<a class="headerlink" href="#hill-climb-search" title="Permalink to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="pgmpy.estimators.HillClimbSearch">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pgmpy.estimators.</span></span><span class="sig-name descname"><span class="pre">HillClimbSearch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/HillClimbSearch.html#HillClimbSearch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.HillClimbSearch" title="Permalink to this definition">¶</a></dt>
<dd><p>Class for heuristic hill climb searches for DAGs, to learn
network structure from data. <cite>estimate</cite> attempts to find a model with optimal score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>pandas DataFrame object</em>) – dataframe object where each column represents one variable.
(If some values in the data are missing the data cells should be set to <cite>numpy.NaN</cite>.
Note that pandas converts each column containing <cite>numpy.NaN`s to dtype `float</cite>.)</p></li>
<li><p><strong>state_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a><em> (</em><em>optional</em><em>)</em>) – A dict indicating, for each variable, the discrete set of states (or values)
that the variable can take. If unspecified, the observed values in the data set
are taken to be the only possible states.</p></li>
<li><p><strong>use_caching</strong> (<em>boolean</em>) – If True, uses caching of score for faster computation.
Note: Caching only works for scoring methods which are decomposable. Can
give wrong results in case of custom scoring methods.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p>Koller &amp; Friedman, Probabilistic Graphical Models - Principles and Techniques, 2009
Section 18.4.3 (page 811ff)</p>
<dl class="py method">
<dt class="sig sig-object py" id="pgmpy.estimators.HillClimbSearch.estimate">
<span class="sig-name descname"><span class="pre">estimate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scoring_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'k2score'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_dag</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_edges</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tabu_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_indegree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">black_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">white_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000000.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/HillClimbSearch.html#HillClimbSearch.estimate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.HillClimbSearch.estimate" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs local hill climb search to estimates the <cite>DAG</cite> structure that
has optimal score, according to the scoring method supplied. Starts at
model <cite>start_dag</cite> and proceeds by step-by-step network modifications
until a local maximum is reached. Only estimates network structure, no
parametrization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scoring_method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em> or </em><em>StructureScore instance</em>) – The score to be optimized during structure estimation.  Supported
structure scores: k2score, bdeuscore, bdsscore, bicscore, aicscore. Also accepts a
custom score, but it should be an instance of <cite>StructureScore</cite>.</p></li>
<li><p><strong>start_dag</strong> (<em>DAG instance</em>) – The starting point for the local search. By default, a completely
disconnected network is used.</p></li>
<li><p><strong>fixed_edges</strong> (<em>iterable</em>) – A list of edges that will always be there in the final learned model.
The algorithm will add these edges at the start of the algorithm and
will never change it.</p></li>
<li><p><strong>tabu_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – If provided, the last <cite>tabu_length</cite> graph modifications cannot be reversed
during the search procedure. This serves to enforce a wider exploration
of the search space. Default value: 100.</p></li>
<li><p><strong>max_indegree</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em> or </em><em>None</em>) – If provided and unequal None, the procedure only searches among models
where all nodes have at most <cite>max_indegree</cite> parents. Defaults to None.</p></li>
<li><p><strong>black_list</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> or </em><em>None</em>) – If a list of edges is provided as <cite>black_list</cite>, they are excluded from the search
and the resulting model will not contain any of those edges. Default: None</p></li>
<li><p><strong>white_list</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><em>list</em></a><em> or </em><em>None</em>) – If a list of edges is provided as <cite>white_list</cite>, the search is limited to those
edges. The resulting model will then only contain edges that are in <cite>white_list</cite>.
Default: None</p></li>
<li><p><strong>epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><em>float</em></a><em> (</em><em>default: 1e-4</em><em>)</em>) – Defines the exit condition. If the improvement in score is less than <cite>epsilon</cite>,
the learned model is returned.</p></li>
<li><p><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em> (</em><em>default: 1e6</em><em>)</em>) – The maximum number of iterations allowed. Returns the learned model when the
number of iterations is greater than <cite>max_iter</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Estimated model</strong> – A <cite>DAG</cite> at a (local) score maximum.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../base/base.html#pgmpy.base.DAG" title="pgmpy.base.DAG">pgmpy.base.DAG</a></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pgmpy.estimators</span> <span class="kn">import</span> <span class="n">HillClimbSearch</span><span class="p">,</span> <span class="n">BicScore</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># create data sample with 9 random variables:</span>
<span class="gp">... </span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">9</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;ABCDEFGHI&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># add 10th dependent variable</span>
<span class="gp">... </span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;J&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span> <span class="o">=</span> <span class="n">HillClimbSearch</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">best_model</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">estimate</span><span class="p">(</span><span class="n">scoring_method</span><span class="o">=</span><span class="n">BicScore</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span><span class="p">(</span><span class="n">best_model</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
<span class="go">[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;, &#39;J&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">best_model</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>
<span class="go">OutEdgeView([(&#39;B&#39;, &#39;J&#39;), (&#39;A&#39;, &#39;J&#39;)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># search a model with restriction on the number of parents:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span><span class="o">.</span><span class="n">estimate</span><span class="p">(</span><span class="n">max_indegree</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>
<span class="go">OutEdgeView([(&#39;J&#39;, &#39;A&#39;), (&#39;B&#39;, &#39;J&#39;)])</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="structure-score">
<h1>Structure Score<a class="headerlink" href="#structure-score" title="Permalink to this heading">¶</a></h1>
<section id="bdeu-score">
<h2>BDeu Score<a class="headerlink" href="#bdeu-score" title="Permalink to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="pgmpy.estimators.BDeuScore">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pgmpy.estimators.</span></span><span class="sig-name descname"><span class="pre">BDeuScore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equivalent_sample_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/StructureScore.html#BDeuScore"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.BDeuScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Class for Bayesian structure scoring for BayesianNetworks with Dirichlet priors.
The BDeu score is the result of setting all Dirichlet hyperparameters/pseudo_counts to
<cite>equivalent_sample_size/variable_cardinality</cite>.
The <cite>score</cite>-method measures how well a model is able to describe the given data set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>pandas DataFrame object</em>) – dataframe object where each column represents one variable.
(If some values in the data are missing the data cells should be set to <cite>numpy.NaN</cite>.
Note that pandas converts each column containing <cite>numpy.NaN`s to dtype `float</cite>.)</p></li>
<li><p><strong>equivalent_sample_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em> (</em><em>default: 10</em><em>)</em>) – The equivalent/imaginary sample size (of uniform pseudo samples) for the dirichlet hyperparameters.
The score is sensitive to this value, runs with different values might be useful.</p></li>
<li><p><strong>state_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a><em> (</em><em>optional</em><em>)</em>) – A dict indicating, for each variable, the discrete set of states (or values)
that the variable can take. If unspecified, the observed values in the data set
are taken to be the only possible states.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p>[1] Koller &amp; Friedman, Probabilistic Graphical Models - Principles and Techniques, 2009
Section 18.3.4-18.3.6 (esp. page 806)
[2] AM Carvalho, Scoring functions for learning Bayesian networks,
<a class="reference external" href="http://www.lx.it.pt/~asmc/pub/talks/09-TA/ta_pres.pdf">http://www.lx.it.pt/~asmc/pub/talks/09-TA/ta_pres.pdf</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pgmpy.estimators.BDeuScore.local_score">
<span class="sig-name descname"><span class="pre">local_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">variable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parents</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/StructureScore.html#BDeuScore.local_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.BDeuScore.local_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a score that measures how much a         given variable is “influenced” by a given list of potential parents.</p>
</dd></dl>

</dd></dl>

</section>
<section id="bic-score">
<h2>Bic Score<a class="headerlink" href="#bic-score" title="Permalink to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="pgmpy.estimators.BicScore">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pgmpy.estimators.</span></span><span class="sig-name descname"><span class="pre">BicScore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/StructureScore.html#BicScore"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.BicScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Class for Bayesian structure scoring for BayesianNetworks with
Dirichlet priors.  The BIC/MDL score (“Bayesian Information Criterion”,
also “Minimal Descriptive Length”) is a log-likelihood score with an
additional penalty for network complexity, to avoid overfitting.  The
<cite>score</cite>-method measures how well a model is able to describe the given
data set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>pandas DataFrame object</em>) – dataframe object where each column represents one variable.
(If some values in the data are missing the data cells should be set to <cite>numpy.NaN</cite>.
Note that pandas converts each column containing <cite>numpy.NaN`s to dtype `float</cite>.)</p></li>
<li><p><strong>state_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a><em> (</em><em>optional</em><em>)</em>) – A dict indicating, for each variable, the discrete set of states (or values)
that the variable can take. If unspecified, the observed values in the data set
are taken to be the only possible states.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p>[1] Koller &amp; Friedman, Probabilistic Graphical Models - Principles and Techniques, 2009
Section 18.3.4-18.3.6 (esp. page 802)
[2] AM Carvalho, Scoring functions for learning Bayesian networks,
<a class="reference external" href="http://www.lx.it.pt/~asmc/pub/talks/09-TA/ta_pres.pdf">http://www.lx.it.pt/~asmc/pub/talks/09-TA/ta_pres.pdf</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pgmpy.estimators.BicScore.local_score">
<span class="sig-name descname"><span class="pre">local_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">variable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parents</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/StructureScore.html#BicScore.local_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.BicScore.local_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a score that measures how much a         given variable is “influenced” by a given list of potential parents.</p>
</dd></dl>

</dd></dl>

</section>
<section id="k2-score">
<h2>K2 Score<a class="headerlink" href="#k2-score" title="Permalink to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="pgmpy.estimators.K2Score">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pgmpy.estimators.</span></span><span class="sig-name descname"><span class="pre">K2Score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/StructureScore.html#K2Score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.K2Score" title="Permalink to this definition">¶</a></dt>
<dd><p>Class for Bayesian structure scoring for BayesianNetworks with Dirichlet priors.
The K2 score is the result of setting all Dirichlet hyperparameters/pseudo_counts to 1.
The <cite>score</cite>-method measures how well a model is able to describe the given data set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>pandas DataFrame object</em>) – dataframe object where each column represents one variable.
(If some values in the data are missing the data cells should be set to <cite>numpy.NaN</cite>.
Note that pandas converts each column containing <cite>numpy.NaN`s to dtype `float</cite>.)</p></li>
<li><p><strong>state_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a><em> (</em><em>optional</em><em>)</em>) – A dict indicating, for each variable, the discrete set of states (or values)
that the variable can take. If unspecified, the observed values in the data set
are taken to be the only possible states.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p>[1] Koller &amp; Friedman, Probabilistic Graphical Models - Principles and Techniques, 2009
Section 18.3.4-18.3.6 (esp. page 806)
[2] AM Carvalho, Scoring functions for learning Bayesian networks,
<a class="reference external" href="http://www.lx.it.pt/~asmc/pub/talks/09-TA/ta_pres.pdf">http://www.lx.it.pt/~asmc/pub/talks/09-TA/ta_pres.pdf</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pgmpy.estimators.K2Score.local_score">
<span class="sig-name descname"><span class="pre">local_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">variable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parents</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/StructureScore.html#K2Score.local_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.K2Score.local_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a score that measures how much a         given variable is “influenced” by a given list of potential parents.</p>
</dd></dl>

</dd></dl>

</section>
<section id="bdsscore">
<h2>BDsScore<a class="headerlink" href="#bdsscore" title="Permalink to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="pgmpy.estimators.BDsScore">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pgmpy.estimators.</span></span><span class="sig-name descname"><span class="pre">BDsScore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">equivalent_sample_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/StructureScore.html#BDsScore"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.BDsScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Class for Bayesian structure scoring for BayesianNetworks with
Dirichlet priors.  The BDs score is the result of setting all Dirichlet
hyperparameters/pseudo_counts to
<cite>equivalent_sample_size/modified_variable_cardinality</cite> where for the
modified_variable_cardinality only the number of parent configurations
where there were observed variable counts are considered.  The
<cite>score</cite>-method measures how well a model is able to describe the given
data set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>pandas DataFrame object</em>) – dataframe object where each column represents one variable.
(If some values in the data are missing the data cells should be set to <cite>numpy.NaN</cite>.
Note that pandas converts each column containing <cite>numpy.NaN`s to dtype `float</cite>.)</p></li>
<li><p><strong>equivalent_sample_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em> (</em><em>default: 10</em><em>)</em>) – The equivalent/imaginary sample size (of uniform pseudo samples) for the dirichlet
hyperparameters.
The score is sensitive to this value, runs with different values might be useful.</p></li>
<li><p><strong>state_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.12)"><em>dict</em></a><em> (</em><em>optional</em><em>)</em>) – A dict indicating, for each variable, the discrete set of states (or values)
that the variable can take. If unspecified, the observed values in the data set
are taken to be the only possible states.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p>[1] Scutari, Marco. An Empirical-Bayes Score for Discrete Bayesian Networks.
Journal of Machine Learning Research, 2016, pp. 438–48</p>
<dl class="py method">
<dt class="sig sig-object py" id="pgmpy.estimators.BDsScore.local_score">
<span class="sig-name descname"><span class="pre">local_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">variable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parents</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/StructureScore.html#BDsScore.local_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.BDsScore.local_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a score that measures how much a         given variable is “influenced” by a given list of potential parents.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pgmpy.estimators.BDsScore.structure_prior">
<span class="sig-name descname"><span class="pre">structure_prior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/StructureScore.html#BDsScore.structure_prior"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.BDsScore.structure_prior" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements the marginal uniform prior for the graph structure where each arc
is independent with the probability of an arc for any two nodes in either direction
is 1/4 and the probability of no arc between any two nodes is 1/2.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pgmpy.estimators.BDsScore.structure_prior_ratio">
<span class="sig-name descname"><span class="pre">structure_prior_ratio</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">operation</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/StructureScore.html#BDsScore.structure_prior_ratio"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.BDsScore.structure_prior_ratio" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the log ratio of the prior probabilities for a given proposed change to
the DAG.</p>
</dd></dl>

</dd></dl>

</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/logo.png" alt="Logo"/>
    
  </a>
</p>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../started/base.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../base/base.html">Base Model Structures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/base.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../factors/base.html">Parameterization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/base.html">Exact Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/model_testing.html">Model Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../approx_infer/base.html">Approximate Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../param_estimator/base.html">Parameter Estimation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="base.html">Structure Learning</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="pc.html">PC (Constraint-Based Estimator)</a></li>
<li class="toctree-l2"><a class="reference internal" href="pc.html#module-pgmpy.estimators.CITests">Conditional Independence Tests for PC algorithm</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Hill Climb Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="#structure-score">Structure Score</a></li>
<li class="toctree-l2"><a class="reference internal" href="tree.html">Tree Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="mmhc.html">Mmhc Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="exhaustive.html">Exhaustive Search</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../metrics/metrics.html">Metrics for testing models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/base.html">Reading/Writing to File</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Tutorial Notebooks</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="base.html">Structure Learning</a><ul>
      <li>Previous: <a href="pc.html" title="previous chapter">PC (Constraint-Based Estimator)</a></li>
      <li>Next: <a href="tree.html" title="next chapter">Tree Search</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>







<script async src="https://media.ethicalads.io/media/client/ethicalads.min.js"></script>

<div data-ea-publisher="pgmpyorg" data-ea-type="image" data-ea-style="horizontal"></div><script async src="https://www.googletagmanager.com/gtag/js?id=G-HCFR07M31W"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-HCFR07M31W');
</script>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, Ankur Ankan.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 6.2.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/structure_estimator/hill.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>