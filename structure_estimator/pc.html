<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="PC (Constraint-Based Estimator)" />
<meta property="og:type" content="website" />
<meta property="og:url" content="structure_estimator/pc.html" />
<meta property="og:site_name" content="pgmpy" />
<meta property="og:description" content="Conditional Independence Tests for PC algorithm:" />
<meta property="og:image:width" content="1146" />
<meta property="og:image:height" content="600" />
<meta property="og:image" content="_images/social_previews/summary_structure_estimator_pc_f6e644b1.png" />
<meta property="og:image:alt" content="Conditional Independence Tests for PC algorithm:" />
<meta name="description" content="Conditional Independence Tests for PC algorithm:" />
<meta name="twitter:card" content="summary_large_image" />

    <title>PC (Constraint-Based Estimator) &#8212; 1.0.0 | pgmpy docs</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=7b53859b" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <script src="../_static/documentation_options.js?v=8d563738"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://pgmpy.org/structure_estimator/pc.html" />
    <link rel="icon" href="../_static/logo_favi.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Hill Climb Search" href="hill.html" />
    <link rel="prev" title="Causal Discovery / Structure Learning" href="base.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="pc-constraint-based-estimator">
<h1>PC (Constraint-Based Estimator)<a class="headerlink" href="#pc-constraint-based-estimator" title="Link to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="pgmpy.estimators.PC">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">pgmpy.estimators.</span></span><span class="sig-name descname"><span class="pre">PC</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">independencies</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/PC.html#PC"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.PC" title="Link to this definition">¶</a></dt>
<dd><p>Class for constraint-based estimation of DAGs using the PC algorithm
from a given data set.  Identifies (conditional) dependencies in data
set using statistical independence tests and estimates a DAG pattern
that satisfies the identified dependencies. The DAG pattern can then be
completed to a faithful DAG, if possible.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<em>pandas DataFrame object</em>) – dataframe object where each column represents one variable.  (If some
values in the data are missing the data cells should be set to
<cite>numpy.nan</cite>.  Note that pandas converts each column containing
<cite>numpy.nan`s to dtype `float</cite>.)</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="simple">
<dt>[1] Koller &amp; Friedman, Probabilistic Graphical Models - Principles and Techniques,</dt><dd><p>2009, Section 18.2</p>
</dd>
</dl>
<p>[2] Neapolitan, Learning Bayesian Networks, Section 10.1.2 for the PC algorithm (page 550), <a class="reference external" href="http://www.cs.technion.ac.il/~dang/books/Learning%20Bayesian%20Networks(Neapolitan,%20Richard).pdf">http://www.cs.technion.ac.il/~dang/books/Learning%20Bayesian%20Networks(Neapolitan,%20Richard).pdf</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="pgmpy.estimators.PC.apply_orientation_rules">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">apply_orientation_rules</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pdag</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">apply_r4</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/PC.html#PC.apply_orientation_rules"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.PC.apply_orientation_rules" title="Link to this definition">¶</a></dt>
<dd><p>Orients the edges of a graph skeleton based on information from
<cite>separating_sets</cite> to form a DAG pattern (CPDAG/MPDAG).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pdag</strong> (<a class="reference internal" href="../models/pdag.html#pgmpy.base.PDAG" title="pgmpy.base.PDAG"><em>pgmpy.base.PDAG</em></a>) – A  partial DAG produced by orienting v-structures in
the skeleton.</p></li>
<li><p><strong>apply_r4</strong> (<em>boolean</em>) – If true, use Rule 4 of Meek’s rules to integrate background knowledge into
the phase of orienting edges. Defaults to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Model after edge orientation</strong> – An estimate for the DAG pattern of the BN underlying the data. The
graph might contain some nodes with both-way edges (X-&gt;Y and Y-&gt;X).
Any completion by (removing one of the both-way edges for each such
pair) results in a I-equivalent Bayesian network DAG.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../models/dag.html#pgmpy.base.DAG" title="pgmpy.base.DAG">pgmpy.base.DAG</a></p>
</dd>
</dl>
<p class="rubric">References</p>
<p>Neapolitan, Learning Bayesian Networks, Section 10.1.2, Algorithm 10.2 (page 550)
<a class="reference external" href="http://www.cs.technion.ac.il/~dang/books/Learning%20Bayesian%20Networks(Neapolitan,%20Richard).pdf">http://www.cs.technion.ac.il/~dang/books/Learning%20Bayesian%20Networks(Neapolitan,%20Richard).pdf</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pgmpy.estimators</span> <span class="kn">import</span> <span class="n">PC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;ABDE&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;D&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;E&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">PC</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pdag</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">orient_colliders</span><span class="p">(</span><span class="o">*</span><span class="n">c</span><span class="o">.</span><span class="n">build_skeleton</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pdag</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span> <span class="c1"># edges: A-&gt;C, B-&gt;C, A--D (not directed), C--E (not directed)</span>
<span class="go">OutEdgeView([(&#39;B&#39;, &#39;C&#39;), (&#39;C&#39;, &#39;E&#39;), (&#39;A&#39;, &#39;C&#39;), (&#39;A&#39;, &#39;D&#39;), (&#39;E&#39;, &#39;C&#39;), (&#39;D&#39;, &#39;A&#39;)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pdag</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">apply_orientation_rules</span><span class="p">(</span><span class="n">pdag</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pdag</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span>
<span class="go">OutEdgeView([(&#39;C&#39;, &#39;E&#39;), (&#39;B&#39;, &#39;C&#39;), (&#39;A&#39;, &#39;C&#39;), (&#39;A&#39;, &#39;D&#39;), (&#39;D&#39;, &#39;A&#39;)])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pgmpy.estimators.PC.build_skeleton">
<span class="sig-name descname"><span class="pre">build_skeleton</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">variant</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'stable'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ci_test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'chi_square'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">significance_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_cond_vars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expert_knowledge</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enforce_expert_knowledge</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/PC.html#PC.build_skeleton"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.PC.build_skeleton" title="Link to this definition">¶</a></dt>
<dd><p>Estimates a graph skeleton (UndirectedGraph) from a set of independencies
using (the first part of) the PC algorithm. The independencies can either be
provided as an instance of the <cite>Independencies</cite>-class or by passing a
decision function that decides any conditional independency assertion.
Returns a tuple <cite>(skeleton, separating_sets)</cite>.</p>
<p>If an Independencies-instance is passed, the contained IndependenceAssertions
have to admit a faithful BN representation. This is the case if
they are obtained as a set of d-seperations of some Bayesian network or
if the independence assertions are closed under the semi-graphoid axioms.
Otherwise, the procedure may fail to identify the correct structure.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>skeleton</strong> (<em>UndirectedGraph</em>) – An estimate for the undirected graph skeleton of the BN underlying the data.</p></li>
<li><p><strong>separating_sets</strong> (<em>dict</em>) – A dict containing for each pair of not directly connected nodes a
separating set (“witnessing set”) of variables that makes then
conditionally independent. (needed for edge orientation procedures)</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="simple">
<dt>[1] Neapolitan, Learning Bayesian Networks, Section 10.1.2, Algorithm 10.2 (page 550)</dt><dd><p><a class="reference external" href="http://www.cs.technion.ac.il/~dang/books/Learning%20Bayesian%20Networks(Neapolitan,%20Richard).pdf">http://www.cs.technion.ac.il/~dang/books/Learning%20Bayesian%20Networks(Neapolitan,%20Richard).pdf</a></p>
</dd>
<dt>[2] Koller &amp; Friedman, Probabilistic Graphical Models - Principles and Techniques, 2009</dt><dd><p>Section 3.4.2.1 (page 85), Algorithm 3.3</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pgmpy.estimators.PC.estimate">
<span class="sig-name descname"><span class="pre">estimate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">variant</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'parallel'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ci_test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'chi_square'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'pdag'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">significance_level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_cond_vars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expert_knowledge</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enforce_expert_knowledge</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/PC.html#PC.estimate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.PC.estimate" title="Link to this definition">¶</a></dt>
<dd><p>Estimates a DAG/PDAG from the given dataset using the PC algorithm which
is a constraint-based structure learning algorithm[1]. The independencies
in the dataset are identified by doing statistical independece test. This
method returns a DAG/PDAG structure which is faithful to the independencies
implied by the dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>variant</strong> (<em>str</em><em> (</em><em>one</em><em> of </em><em>&quot;orig&quot;</em><em>, </em><em>&quot;stable&quot;</em><em>, </em><em>&quot;parallel&quot;</em><em>)</em>) – <dl class="simple">
<dt>The variant of PC algorithm to run.</dt><dd><dl class="simple">
<dt>”orig”: The original PC algorithm. Might not give the same</dt><dd><p>results in different runs but does less independence
tests compared to stable.</p>
</dd>
<dt>”stable”: Gives the same result in every run but does needs to</dt><dd><p>do more statistical independence tests.</p>
</dd>
<dt>”parallel”: Parallel version of PC Stable. Can run on multiple</dt><dd><p>cores with the same result on each run.</p>
</dd>
</dl>
</dd>
</dl>
</p></li>
<li><p><strong>ci_test</strong> (<em>str</em><em> or </em><em>fun</em>) – <p>The statistical test to use for testing conditional independence in
the dataset. If <cite>str</cite> values should be one of:</p>
<blockquote>
<div><dl class="simple">
<dt>”independence_match”: If using this option, an additional parameter</dt><dd><p><cite>independencies</cite> must be specified.</p>
</dd>
<dt>”chi_square”: Uses the Chi-Square independence test. This works</dt><dd><p>only for discrete datasets.</p>
</dd>
<dt>”pearsonr”: Uses the pertial correlation based on pearson</dt><dd><p>correlation coefficient to test independence. This works
only for continuous datasets.</p>
</dd>
</dl>
<p>”g_sq”: G-test. Works only for discrete datasets.
“log_likelihood”: Log-likelihood test. Works only for discrete dataset.
“freeman_tuckey”: Freeman Tuckey test. Works only for discrete dataset.
“modified_log_likelihood”: Modified Log Likelihood test. Works only for discrete variables.
“neyman”: Neyman test. Works only for discrete variables.
“cressie_read”: Cressie Read test. Works only for discrete variables.</p>
</div></blockquote>
</p></li>
<li><p><strong>return_type</strong> (<em>str</em><em> (</em><em>one</em><em> of </em><em>&quot;dag&quot;</em><em>, </em><em>&quot;cpdag&quot;</em><em>, </em><em>&quot;pdag&quot;</em><em>, </em><em>&quot;skeleton&quot;</em><em>)</em>) – <p>The type of structure to return.</p>
<dl class="simple">
<dt>If <cite>return_type=pdag</cite> or <cite>return_type=cpdag</cite>: a partially directed structure</dt><dd><p>is returned.</p>
</dd>
<dt>If <cite>return_type=dag</cite>, a fully directed structure is returned if it</dt><dd><p>is possible to orient all the edges.</p>
</dd>
<dt>If <a href="#id1"><span class="problematic" id="id2">`</span></a>return_type=”skeleton”, returns an undirected graph along</dt><dd><p>with the separating sets.</p>
</dd>
</dl>
</p></li>
<li><p><strong>significance_level</strong> (<em>float</em><em> (</em><em>default: 0.01</em><em>)</em>) – <p>The statistical tests use this value to compare with the p-value of
the test to decide whether the tested variables are independent or
not. Different tests can treat this parameter differently:</p>
<blockquote>
<div><ol class="arabic simple">
<li><dl class="simple">
<dt>Chi-Square: If p-value &gt; significance_level, it assumes that the</dt><dd><p>independence condition satisfied in the data.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>pearsonr: If p-value &gt; significance_level, it assumes that the</dt><dd><p>independence condition satisfied in the data.</p>
</dd>
</dl>
</li>
</ol>
</div></blockquote>
</p></li>
<li><p><strong>expert_knowledge</strong> (<em>pgmpy.estimators.ExpertKnowledge instance</em>) – Expert knowledge to be used with the algorithm. Expert knowledge
includes required/forbidden edges in the final graph, temporal
information about the variables etc. Please refer
pgmpy.estimators.ExpertKnowledge class for more details.</p></li>
<li><p><strong>enforce_expert_knowledge</strong> (<em>boolean</em><em> (</em><em>default: False</em><em>)</em>) – <p>If True, the algorithm modifies the search space according to the
edges specified in expert knowledge object. This implies the following:</p>
<blockquote>
<div><ol class="arabic simple">
<li><dl class="simple">
<dt>For every edge (u, v) specified in <cite>forbidden_edges</cite>, there will</dt><dd><p>be no edge between u and v.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>For every edge (u, v) specified in <cite>required_edges</cite>, one of the</dt><dd><p>following would be present in the final model: u -&gt; v, u &lt;-
v, or u - v (if CPDAG is returned).</p>
</dd>
</dl>
</li>
</ol>
</div></blockquote>
<p>If False, the algorithm attempts to make the edge orientations as
specified by expert knowledge after learning the skeleton. This
implies the following:</p>
<blockquote>
<div><ol class="arabic simple">
<li><dl class="simple">
<dt>For every edge (u, v) specified in <cite>forbidden_edges</cite>, the final</dt><dd><p>graph would have either v &lt;- u or no edge except if u -&gt; v is part
of a collider structure in the learned skeleton.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>For every edge (u, v) specified in <cite>required_edges</cite>, the final graph</dt><dd><p>would either have u -&gt; v or no edge except if v &lt;- u is part of a
collider structure in the learned skeleton.</p>
</dd>
</dl>
</li>
</ol>
</div></blockquote>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p><strong>Estimated model</strong> –</p>
<dl class="simple">
<dt>The estimated model structure:</dt><dd><ol class="arabic simple">
<li><p>Partially Directed Graph (PDAG) if <cite>return_type=’pdag’</cite> or <cite>return_type=’cpdag’</cite>.</p></li>
<li><p>Directed Acyclic Graph (DAG) if <cite>return_type=’dag’</cite>.</p></li>
<li><p>(nx.Graph, separating sets) if <cite>return_type=’skeleton’</cite>.</p></li>
</ol>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../models/dag.html#pgmpy.base.DAG" title="pgmpy.base.DAG">pgmpy.base.DAG</a>, <a class="reference internal" href="../models/pdag.html#pgmpy.base.PDAG" title="pgmpy.base.PDAG">pgmpy.base.PDAG</a>, or tuple(networkx.UndirectedGraph, dict)</p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="simple">
<dt>[1] Original PC: P. Spirtes, C. Glymour, and R. Scheines, Causation,</dt><dd><p>Prediction, and Search, 2nd ed. Cambridge, MA: MIT Press, 2000.</p>
</dd>
<dt>[2] Stable PC:  D. Colombo and M. H. Maathuis, “A modification of the PC algorithm</dt><dd><p>yielding order-independent skeletons,” ArXiv e-prints, Nov. 2012.</p>
</dd>
<dt>[3] Parallel PC: Le, Thuc, et al. “A fast PC algorithm for high dimensional causal</dt><dd><p>discovery with multi-core PCs.” IEEE/ACM transactions on computational
biology and bioinformatics (2016).</p>
</dd>
<dt>[4] Expert Knowledge: Meek, Christopher. “Causal inference and causal</dt><dd><p>explanation with background knowledge.” arXiv preprint arXiv:1302.4972
(2013).</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pgmpy.utils</span> <span class="kn">import</span> <span class="n">get_example_model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pgmpy.estimators</span> <span class="kn">import</span> <span class="n">PC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">get_example_model</span><span class="p">(</span><span class="s1">&#39;alarm&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span> <span class="o">=</span> <span class="n">PC</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model_chi</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">estimate</span><span class="p">(</span><span class="n">ci_test</span><span class="o">=</span><span class="s1">&#39;chi_square&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model_chi</span><span class="o">.</span><span class="n">edges</span><span class="p">()))</span>
<span class="go">28</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model_gsq</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">estimate</span><span class="p">(</span><span class="n">ci_test</span><span class="o">=</span><span class="s1">&#39;g_sq&#39;</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;skeleton&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model_gsq</span><span class="o">.</span><span class="n">edges</span><span class="p">()))</span>
<span class="go">33</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="pgmpy.estimators.PC.orient_colliders">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">orient_colliders</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">skeleton</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">separating_sets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_ordering</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/PC.html#PC.orient_colliders"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.PC.orient_colliders" title="Link to this definition">¶</a></dt>
<dd><p>Orients the edges that form v-structures in a graph skeleton
based on information from <cite>separating_sets</cite> to form a DAG pattern (PDAG).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>skeleton</strong> (<em>nx.Graph</em>) – An undirected graph skeleton as e.g. produced by the
estimate_skeleton method.</p></li>
<li><p><strong>separating_sets</strong> (<em>dict</em>) – A dict containing for each pair of not directly connected nodes a
separating set (“witnessing set”) of variables that makes them
conditionally independent.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Model after edge orientation</strong> – An estimate for the DAG pattern of the BN underlying the data. The
graph might contain some nodes with both-way edges (X-&gt;Y and Y-&gt;X).
Any completion by (removing one of the both-way edges for each such
pair) results in a I-equivalent Bayesian network DAG.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="../models/pdag.html#pgmpy.base.PDAG" title="pgmpy.base.PDAG">pgmpy.base.PDAG</a></p>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="simple">
<dt>[1] Neapolitan, Learning Bayesian Networks, Section 10.1.2, Algorithm</dt><dd><p>10.2 (page 550)</p>
</dd>
</dl>
<p>[2] <a class="reference external" href="http://www.cs.technion.ac.il/~dang/books/Learning%20Bayesian%20Networks(Neapolitan,%20Richard).pdf">http://www.cs.technion.ac.il/~dang/books/Learning%20Bayesian%20Networks(Neapolitan,%20Richard).pdf</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pgmpy.estimators</span> <span class="kn">import</span> <span class="n">PC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;ABD&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;D&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">PC</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pdag</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">orient_colliders</span><span class="p">(</span><span class="o">*</span><span class="n">c</span><span class="o">.</span><span class="n">build_skeleton</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pdag</span><span class="o">.</span><span class="n">edges</span><span class="p">()</span> <span class="c1"># edges: A-&gt;C, B-&gt;C, A--D (not directed)</span>
<span class="go">OutEdgeView([(&#39;B&#39;, &#39;C&#39;), (&#39;A&#39;, &#39;C&#39;), (&#39;A&#39;, &#39;D&#39;), (&#39;D&#39;, &#39;A&#39;)])</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="module-pgmpy.estimators.CITests">
<span id="conditional-independence-tests-for-pc-algorithm"></span><h1>Conditional Independence Tests for PC algorithm<a class="headerlink" href="#module-pgmpy.estimators.CITests" title="Link to this heading">¶</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="pgmpy.estimators.CITests.chi_square">
<span class="sig-prename descclassname"><span class="pre">pgmpy.estimators.CITests.</span></span><span class="sig-name descname"><span class="pre">chi_square</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boolean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/CITests.html#chi_square"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.CITests.chi_square" title="Link to this definition">¶</a></dt>
<dd><p>Chi-square conditional independence test.
Tests the null hypothesis that X is independent from Y given Zs.</p>
<p>This is done by comparing the observed frequencies with the expected
frequencies if X,Y were conditionally independent, using a chisquare
deviance statistic. The expected frequencies given independence are
<img class="math" src="../_images/math/025c892b64f439d43f5a8b81a3ee6265b8c6aabf.png" alt="P(X,Y,Zs) = P(X|Zs)*P(Y|Zs)*P(Zs)"/>. The latter term can be computed
as :math:<a href="#id3"><span class="problematic" id="id4">`</span></a>P(X,Zs)*P(Y,Zs)/P(Zs).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>int</em><em>, </em><em>string</em><em>, </em><em>hashable object</em>) – A variable name contained in the data set</p></li>
<li><p><strong>Y</strong> (<em>int</em><em>, </em><em>string</em><em>, </em><em>hashable object</em>) – A variable name contained in the data set, different from X</p></li>
<li><p><strong>Z</strong> (<em>list</em><em>, </em><em>array-like</em>) – A list of variable names contained in the data set, different from X and Y.
This is the separating set that (potentially) makes X and Y independent.
Default: []</p></li>
<li><p><strong>data</strong> (<em>pandas.DataFrame</em>) – The dataset on which to test the independence condition.</p></li>
<li><p><strong>boolean</strong> (<em>bool</em>) – If boolean=True, an additional argument <cite>significance_level</cite> must
be specified. If p_value of the test is greater than equal to
<cite>significance_level</cite>, returns True. Otherwise returns False.
If boolean=False, returns the chi2 and p_value of the test.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>CI Test Results</strong> – If boolean = False, Returns a tuple (chi, p_value, dof). <cite>chi</cite> is the
chi-squared test statistic. The <cite>p_value</cite> for the test, i.e. the
probability of observing the computed chi-square statistic (or an even
higher value), given the null hypothesis that X ⟂ Y | Zs is True.
If boolean = True, returns True if the p_value of the test is greater
than <cite>significance_level</cite> else returns False.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple or bool</p>
</dd>
</dl>
<p class="rubric">References</p>
<p>[1] <a class="reference external" href="https://en.wikipedia.org/wiki/Chi-squared_test">https://en.wikipedia.org/wiki/Chi-squared_test</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;ABCD&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;E&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">chi_square</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="p">[],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">chi_square</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;D&#39;</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">chi_square</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="s1">&#39;E&#39;</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="go">False</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pgmpy.estimators.CITests.g_sq">
<span class="sig-prename descclassname"><span class="pre">pgmpy.estimators.CITests.</span></span><span class="sig-name descname"><span class="pre">g_sq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boolean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/CITests.html#g_sq"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.CITests.g_sq" title="Link to this definition">¶</a></dt>
<dd><p>G squared test for conditional independence. Also commonly known as G-test,
likelihood-ratio or maximum likelihood statistical significance test.
Tests the null hypothesis that X is independent of Y given Zs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>int</em><em>, </em><em>string</em><em>, </em><em>hashable object</em>) – A variable name contained in the data set</p></li>
<li><p><strong>Y</strong> (<em>int</em><em>, </em><em>string</em><em>, </em><em>hashable object</em>) – A variable name contained in the data set, different from X</p></li>
<li><p><strong>Z</strong> (<em>list</em><em> (</em><em>array-like</em><em>)</em>) – A list of variable names contained in the data set, different from X and Y.
This is the separating set that (potentially) makes X and Y independent.
Default: []</p></li>
<li><p><strong>data</strong> (<em>pandas.DataFrame</em>) – The dataset on which to test the independence condition.</p></li>
<li><p><strong>boolean</strong> (<em>bool</em>) – If boolean=True, an additional argument <cite>significance_level</cite> must be
specified. If p_value of the test is greater than equal to
<cite>significance_level</cite>, returns True. Otherwise returns False. If
boolean=False, returns the chi2 and p_value of the test.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>CI Test Results</strong> – If boolean = False, Returns a tuple (chi, p_value, dof). <cite>chi</cite> is the
chi-squared test statistic. The <cite>p_value</cite> for the test, i.e. the
probability of observing the computed chi-square statistic (or an even
higher value), given the null hypothesis that X ⟂ Y | Zs is True.
If boolean = True, returns True if the p_value of the test is greater
than <cite>significance_level</cite> else returns False.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple or bool</p>
</dd>
</dl>
<p class="rubric">References</p>
<p>[1] <a class="reference external" href="https://en.wikipedia.org/wiki/G-test">https://en.wikipedia.org/wiki/G-test</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;ABCD&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;E&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g_sq</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="p">[],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g_sq</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;D&#39;</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">g_sq</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="s1">&#39;E&#39;</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="go">False</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pgmpy.estimators.CITests.gcm">
<span class="sig-prename descclassname"><span class="pre">pgmpy.estimators.CITests.</span></span><span class="sig-name descname"><span class="pre">gcm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boolean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/CITests.html#gcm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.CITests.gcm" title="Link to this definition">¶</a></dt>
<dd><p>The Generalized Covariance Measure(GCM) test for CI.</p>
<p>It performs linear regressions on the conditioning variable and then tests
for a vanishing covariance between the resulting residuals. Details of the
method can be found in [1].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>str</em>) – The first variable for testing the independence condition X ⟂ Y | Z</p></li>
<li><p><strong>Y</strong> (<em>str</em>) – The second variable for testing the independence condition X ⟂ Y | Z</p></li>
<li><p><strong>Z</strong> (<em>list/array-like</em>) – A list of conditional variable for testing the condition X ⟂ Y | Z</p></li>
<li><p><strong>data</strong> (<em>pandas.DataFrame</em>) – The dataset in which to test the indepenedence condition.</p></li>
<li><p><strong>boolean</strong> (<em>bool</em>) – <dl class="simple">
<dt>If boolean=True, an additional argument <cite>significance_level</cite> must</dt><dd><p>be specified. If p_value of the test is greater than equal to
<cite>significance_level</cite>, returns True. Otherwise returns False.</p>
</dd>
<dt>If boolean=False, returns the pearson correlation coefficient and p_value</dt><dd><p>of the test.</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>CI Test results</strong> – If boolean=True, returns True if p-value &gt;= significance_level, else False. If
boolean=False, returns a tuple of (Pearson’s correlation Coefficient, p-value)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple or bool</p>
</dd>
</dl>
<p class="rubric">References</p>
<p>[1] Rajen D. Shah, and Jonas Peters. “The Hardness of Conditional Independence Testing and the Generalised Covariance Measure”.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pgmpy.estimators.CITests.independence_match">
<span class="sig-prename descclassname"><span class="pre">pgmpy.estimators.CITests.</span></span><span class="sig-name descname"><span class="pre">independence_match</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">independencies</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/CITests.html#independence_match"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.CITests.independence_match" title="Link to this definition">¶</a></dt>
<dd><p>Checks if <cite>X ⟂ Y | Z</cite> is in <cite>independencies</cite>. This method is implemented to
have an uniform API when the independencies are provided instead of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>str</em>) – The first variable for testing the independence condition X ⟂ Y | Z</p></li>
<li><p><strong>Y</strong> (<em>str</em>) – The second variable for testing the independence condition X ⟂ Y | Z</p></li>
<li><p><strong>Z</strong> (<em>list/array-like</em>) – A list of conditional variable for testing the condition X ⟂ Y | Z</p></li>
<li><p><strong>data</strong> (<em>pandas.DataFrame The dataset in which to test the indepenedence condition.</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>p-value</strong></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float (Fixed to 0 since it is always confident)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pgmpy.estimators.CITests.log_likelihood">
<span class="sig-prename descclassname"><span class="pre">pgmpy.estimators.CITests.</span></span><span class="sig-name descname"><span class="pre">log_likelihood</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boolean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/CITests.html#log_likelihood"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.CITests.log_likelihood" title="Link to this definition">¶</a></dt>
<dd><p>Log likelihood ratio test for conditional independence. Also commonly known
as G-test, G-squared test or maximum likelihood statistical significance
test.  Tests the null hypothesis that X is independent of Y given Zs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>int</em><em>, </em><em>string</em><em>, </em><em>hashable object</em>) – A variable name contained in the data set</p></li>
<li><p><strong>Y</strong> (<em>int</em><em>, </em><em>string</em><em>, </em><em>hashable object</em>) – A variable name contained in the data set, different from X</p></li>
<li><p><strong>Z</strong> (<em>list</em><em> (</em><em>array-like</em><em>)</em>) – A list of variable names contained in the data set, different from X and Y.
This is the separating set that (potentially) makes X and Y independent.
Default: []</p></li>
<li><p><strong>data</strong> (<em>pandas.DataFrame</em>) – The dataset on which to test the independence condition.</p></li>
<li><p><strong>boolean</strong> (<em>bool</em>) – If boolean=True, an additional argument <cite>significance_level</cite> must be
specified. If p_value of the test is greater than equal to
<cite>significance_level</cite>, returns True. Otherwise returns False.  If
boolean=False, returns the chi2 and p_value of the test.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>CI Test Results</strong> – If boolean = False, Returns a tuple (chi, p_value, dof). <cite>chi</cite> is the
chi-squared test statistic. The <cite>p_value</cite> for the test, i.e. the
probability of observing the computed chi-square statistic (or an even
higher value), given the null hypothesis that X ⟂ Y | Zs is True.
If boolean = True, returns True if the p_value of the test is greater
than <cite>significance_level</cite> else returns False.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple or bool</p>
</dd>
</dl>
<p class="rubric">References</p>
<p>[1] <a class="reference external" href="https://en.wikipedia.org/wiki/G-test">https://en.wikipedia.org/wiki/G-test</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;ABCD&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;E&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="p">[],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;D&#39;</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="s1">&#39;E&#39;</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="go">False</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pgmpy.estimators.CITests.modified_log_likelihood">
<span class="sig-prename descclassname"><span class="pre">pgmpy.estimators.CITests.</span></span><span class="sig-name descname"><span class="pre">modified_log_likelihood</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boolean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/CITests.html#modified_log_likelihood"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.CITests.modified_log_likelihood" title="Link to this definition">¶</a></dt>
<dd><p>Modified log likelihood ratio test for conditional independence.
Tests the null hypothesis that X is independent of Y given Zs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>int</em><em>, </em><em>string</em><em>, </em><em>hashable object</em>) – A variable name contained in the data set</p></li>
<li><p><strong>Y</strong> (<em>int</em><em>, </em><em>string</em><em>, </em><em>hashable object</em>) – A variable name contained in the data set, different from X</p></li>
<li><p><strong>Z</strong> (<em>list</em><em> (</em><em>array-like</em><em>)</em>) – A list of variable names contained in the data set, different from X and Y.
This is the separating set that (potentially) makes X and Y independent.
Default: []</p></li>
<li><p><strong>data</strong> (<em>pandas.DataFrame</em>) – The dataset on which to test the independence condition.</p></li>
<li><p><strong>boolean</strong> (<em>bool</em>) – If boolean=True, an additional argument <cite>significance_level</cite> must be
specified. If p_value of the test is greater than equal to
<cite>significance_level</cite>, returns True. Otherwise returns False.
If boolean=False, returns the chi2 and p_value of the test.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>CI Test Results</strong> – If boolean = False, Returns a tuple (chi, p_value, dof). <cite>chi</cite> is the
chi-squared test statistic. The <cite>p_value</cite> for the test, i.e. the
probability of observing the computed chi-square statistic (or an even
higher value), given the null hypothesis that X ⟂ Y | Zs is True.
If boolean = True, returns True if the p_value of the test is greater
than <cite>significance_level</cite> else returns False.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple or bool</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;ABCD&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;E&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">modified_log_likelihood</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="p">[],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">modified_log_likelihood</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;D&#39;</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">modified_log_likelihood</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="s1">&#39;E&#39;</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="go">False</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pgmpy.estimators.CITests.pearsonr">
<span class="sig-prename descclassname"><span class="pre">pgmpy.estimators.CITests.</span></span><span class="sig-name descname"><span class="pre">pearsonr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boolean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/CITests.html#pearsonr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.CITests.pearsonr" title="Link to this definition">¶</a></dt>
<dd><blockquote>
<div><p>Computes Pearson correlation coefficient and p-value for testing non-correlation.
Should be used only on continuous data. In case when :math:<a href="#id5"><span class="problematic" id="id6">`</span></a>Z !=</p>
</div></blockquote>
<dl>
<dt>ull` uses</dt><dd><p>linear regression and computes pearson coefficient on residuals.</p>
<dl class="simple">
<dt>X: str</dt><dd><p>The first variable for testing the independence condition X ⟂ Y | Z</p>
</dd>
<dt>Y: str</dt><dd><p>The second variable for testing the independence condition X ⟂ Y | Z</p>
</dd>
<dt>Z: list/array-like</dt><dd><p>A list of conditional variable for testing the condition X ⟂ Y | Z</p>
</dd>
<dt>data: pandas.DataFrame</dt><dd><p>The dataset in which to test the indepenedence condition.</p>
</dd>
<dt>boolean: bool</dt><dd><dl class="simple">
<dt>If boolean=True, an additional argument <cite>significance_level</cite> must</dt><dd><p>be specified. If p_value of the test is greater than equal to
<cite>significance_level</cite>, returns True. Otherwise returns False.</p>
</dd>
<dt>If boolean=False, returns the pearson correlation coefficient and p_value</dt><dd><p>of the test.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="simple">
<dt>CI Test results: tuple or bool</dt><dd><p>If boolean=True, returns True if p-value &gt;= significance_level, else False. If
boolean=False, returns a tuple of (Pearson’s correlation Coefficient, p-value)</p>
</dd>
</dl>
<p>[1] <a class="reference external" href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">https://en.wikipedia.org/wiki/Pearson_correlation_coefficient</a>
[2] <a class="reference external" href="https://en.wikipedia.org/wiki/Partial_correlation#Using_linear_regression">https://en.wikipedia.org/wiki/Partial_correlation#Using_linear_regression</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pgmpy.estimators.CITests.pillai_trace">
<span class="sig-prename descclassname"><span class="pre">pgmpy.estimators.CITests.</span></span><span class="sig-name descname"><span class="pre">pillai_trace</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boolean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/CITests.html#pillai_trace"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.CITests.pillai_trace" title="Link to this definition">¶</a></dt>
<dd><p>A mixed-data residualization based conditional independence test[1].</p>
<p>Uses XGBoost estimator to compute LS residuals[2], and then does an
association test (Pillai’s Trace) on the residuals.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>str</em>) – The first variable for testing the independence condition X ⟂ Y | Z</p></li>
<li><p><strong>Y</strong> (<em>str</em>) – The second variable for testing the independence condition X ⟂ Y | Z</p></li>
<li><p><strong>Z</strong> (<em>list/array-like</em>) – A list of conditional variable for testing the condition X ⟂ Y | Z</p></li>
<li><p><strong>data</strong> (<em>pandas.DataFrame</em>) – The dataset in which to test the indepenedence condition.</p></li>
<li><p><strong>boolean</strong> (<em>bool</em>) – <dl class="simple">
<dt>If boolean=True, an additional argument <cite>significance_level</cite> must</dt><dd><p>be specified. If p_value of the test is greater than equal to
<cite>significance_level</cite>, returns True. Otherwise returns False.</p>
</dd>
<dt>If boolean=False, returns the pearson correlation coefficient and p_value</dt><dd><p>of the test.</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>CI Test results</strong> – If boolean=True, returns True if p-value &gt;= significance_level, else False. If
boolean=False, returns a tuple of (Pearson’s correlation Coefficient, p-value)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple or bool</p>
</dd>
</dl>
<p class="rubric">References</p>
<p>[1] Ankan, Ankur, and Johannes Textor. “A simple unified approach to testing high-dimensional conditional independences for categorical and ordinal data.” Proceedings of the AAAI Conference on Artificial Intelligence.
[2] Li, C.; and Shepherd, B. E. 2010. Test of Association Between Two Ordinal Variables While Adjusting for Covariates. Journal of the American Statistical Association.
[3] Muller, K. E. and Peterson B. L. (1984) Practical Methods for computing power in testing the multivariate general linear hypothesis. Computational Statistics &amp; Data Analysis.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pgmpy.estimators.CITests.power_divergence">
<span class="sig-prename descclassname"><span class="pre">pgmpy.estimators.CITests.</span></span><span class="sig-name descname"><span class="pre">power_divergence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">boolean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambda_</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cressie-read'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/pgmpy/estimators/CITests.html#power_divergence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#pgmpy.estimators.CITests.power_divergence" title="Link to this definition">¶</a></dt>
<dd><p>Computes the Cressie-Read power divergence statistic [1]. The null hypothesis
for the test is X is independent of Y given Z. A lot of the frequency comparision
based statistics (eg. chi-square, G-test etc) belong to power divergence family,
and are special cases of this test.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>int</em><em>, </em><em>string</em><em>, </em><em>hashable object</em>) – A variable name contained in the data set</p></li>
<li><p><strong>Y</strong> (<em>int</em><em>, </em><em>string</em><em>, </em><em>hashable object</em>) – A variable name contained in the data set, different from X</p></li>
<li><p><strong>Z</strong> (<em>list</em><em>, </em><em>array-like</em>) – A list of variable names contained in the data set, different from X and Y.
This is the separating set that (potentially) makes X and Y independent.
Default: []</p></li>
<li><p><strong>data</strong> (<em>pandas.DataFrame</em>) – The dataset on which to test the independence condition.</p></li>
<li><p><strong>lambda</strong> (<em>float</em><em> or </em><em>string</em>) – <p>The lambda parameter for the power_divergence statistic. Some values of
<a href="#id7"><span class="problematic" id="id8">lambda_</span></a> results in other well known tests:</p>
<blockquote>
<div><p>”pearson”             1          “Chi-squared test”
“log-likelihood”      0          “G-test or log-likelihood”
“freeman-tuckey”     -1/2        “Freeman-Tuckey Statistic”
“mod-log-likelihood”  -1         “Modified Log-likelihood”
“neyman”              -2         “Neyman’s statistic”
“cressie-read”        2/3        “The value recommended in the paper[1]”</p>
</div></blockquote>
</p></li>
<li><p><strong>boolean</strong> (<em>bool</em>) – <dl class="simple">
<dt>If boolean=True, an additional argument <cite>significance_level</cite> must</dt><dd><p>be specified. If p_value of the test is greater than equal to
<cite>significance_level</cite>, returns True. Otherwise returns False.</p>
</dd>
</dl>
<p>If boolean=False, returns the chi2 and p_value of the test.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>CI Test Results</strong> – If boolean = False, Returns a tuple (chi, p_value, dof). <cite>chi</cite> is the
chi-squared test statistic. The <cite>p_value</cite> for the test, i.e. the
probability of observing the computed chi-square statistic (or an even
higher value), given the null hypothesis that X ⟂ Y | Zs is True.
If boolean = True, returns True if the p_value of the test is greater
than <cite>significance_level</cite> else returns False.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple or bool</p>
</dd>
</dl>
<p class="rubric">References</p>
<p>[1] Cressie, Noel, and Timothy RC Read. “Multinomial goodness‐of‐fit tests.” Journal of the Royal Statistical Society: Series B (Methodological) 46.3 (1984): 440-464.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;ABCD&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;E&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">chi_square</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="p">[],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">chi_square</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;D&#39;</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">chi_square</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="s1">&#39;E&#39;</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="go">False</span>
</pre></div>
</div>
</dd></dl>

</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/logo.png" alt="Logo" />
    
  </a>
</p>









<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../started/base.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/base.html">Supported Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../factors/base.html">Parameterization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infer/base.html">Probabilistic Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../causal_infer/base.html">Causal Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../param_estimator/base.html">Parameter Estimation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="base.html">Causal Discovery / Structure Learning</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">PC (Constraint-Based Estimator)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-pgmpy.estimators.CITests">Conditional Independence Tests for PC algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="hill.html">Hill Climb Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="hill.html#structure-scores">Structure Scores</a></li>
<li class="toctree-l2"><a class="reference internal" href="ges.html">Greedy Equivalence Search (GES)</a></li>
<li class="toctree-l2"><a class="reference internal" href="tree.html">Tree Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="expert.html">Expert In The Loop</a></li>
<li class="toctree-l2"><a class="reference internal" href="mmhc.html">Mmhc Estimator</a></li>
<li class="toctree-l2"><a class="reference internal" href="exhaustive.html">Exhaustive Search</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../metrics/metrics.html">Metrics for Testing Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/base.html">Reading/Writing to File</a></li>
<li class="toctree-l1"><a class="reference internal" href="../plotting.html">Plotting Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Tutorial Notebooks</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="base.html">Causal Discovery / Structure Learning</a><ul>
      <li>Previous: <a href="base.html" title="previous chapter">Causal Discovery / Structure Learning</a></li>
      <li>Next: <a href="hill.html" title="next chapter">Hill Climb Search</a></li>
  </ul></li>
  </ul></li>
</ul>
</div><script async src="https://media.ethicalads.io/media/client/ethicalads.min.js"></script>

<div data-ea-publisher="pgmpyorg" data-ea-type="image" data-ea-style="horizontal"></div><script async src="https://www.googletagmanager.com/gtag/js?id=G-HCFR07M31W"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-HCFR07M31W');
</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2025, Ankur Ankan.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.2.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="../_sources/structure_estimator/pc.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>