

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>8. Sampling In Continuous Graphical Models &mdash; pgmpy 0.1.15 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="9. Reading and Writing from pgmpy file formats" href="9.%20Reading%20and%20Writing%20from%20pgmpy%20file%20formats.html" />
    <link rel="prev" title="7. Parameterizing with Continuous Variables" href="7.%20Parameterizing%20with%20Continuous%20Variables.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> pgmpy
          

          
          </a>

          
            
            
              <div class="version">
                0.1.15
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../started/install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../started/contributing.html">Contributing to pgmpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../started/license.html">License</a></li>
</ul>
<p class="caption"><span class="caption-text">Base Structures</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../base/base.html">Directed Acyclic Graph (DAG)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../base/base.html#module-pgmpy.base.PDAG">Partial Directed Acyclic Graph (PDAG)</a></li>
</ul>
<p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../models/bayesiannetwork.html">Bayesian Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/dbn.html">Dynamic Bayesian Network (DBN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/sem.html">Structural Equation Models (SEM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/naive.html">Naive Bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/noisyor.html">NoisyOr Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/markovnetwork.html">Markov Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/junctiontree.html">Junction Tree</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/clustergraph.html">Cluster Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/factorgraph.html">Factor Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/markovchain.html">Markov Chain</a></li>
</ul>
<p class="caption"><span class="caption-text">Parameterization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../factors/discrete.html">Discrete</a></li>
<li class="toctree-l1"><a class="reference internal" href="../factors/continuous.html">Continuous</a></li>
<li class="toctree-l1"><a class="reference internal" href="../factors/discretize.html">Discretizing Methods</a></li>
</ul>
<p class="caption"><span class="caption-text">Exact Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/ve.html">Variable Elimination</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/ve.html#module-pgmpy.inference.EliminationOrder">Elimination Ordering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/bp.html">Belief Propagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/causal.html">Causal Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/mplp.html">MPLP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/dbn_infer.html">Dynamic Bayesian Network Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/model_testing.html">Model Testing</a></li>
</ul>
<p class="caption"><span class="caption-text">Approximate Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../approx_infer/bn_sampling.html">Bayesian Model Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../approx_infer/gibbs.html">Gibbs Sampling</a></li>
</ul>
<p class="caption"><span class="caption-text">Parameter Estimation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../param_estimator/mle.html">Maximum Likelihood Estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../param_estimator/bayesian_est.html">Bayesian Estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../param_estimator/em.html">Expectation Maximization (EM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../param_estimator/sem_estimator.html">Structural Equation Model Estimators</a></li>
</ul>
<p class="caption"><span class="caption-text">Structure Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/pc.html">PC (Constraint-Based Estimator)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/pc.html#module-pgmpy.estimators.CITests">Conditional Independence Tests for PC algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/hill.html">Hill Climb Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/hill.html#structure-score">Structure Score</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/tree.html">Tree Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/mmhc.html">Mmhc Estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/exhaustive.html">Exhaustive Search</a></li>
</ul>
<p class="caption"><span class="caption-text">Input/Output</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/bif.html">BIF (Bayesian Interchange Format)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/uai.html">UAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/xmlbif.html">XMLBIF</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/pomdpx.html">PomdpX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/xmlbelief.html">XMLBeliefNetwork</a></li>
</ul>
<p class="caption"><span class="caption-text">Example Notebooks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../examples/Earthquake.html">1. Example Using the Earthquake network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Monty%20Hall%20Problem.html">2. Monty Hall Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Creating%20a%20Discrete%20Bayesian%20Network.html">3. Creating discrete Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Inference%20in%20Discrete%20Bayesian%20Networks.html">4. Inference in Discrete Bayesian Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Causal%20Games.html">5. Causal Games</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Causal%20Inference.html">6. Causal Inference Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Learning%20Parameters%20in%20Discrete%20Bayesian%20Networks.html">7. Parameter Learning in Discrete Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Structure%20Learning%20in%20Bayesian%20Networks.html">8. Structure Learning in Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Structure%20Learning%20with%20Chow-Liu.html">9. Learning Tree Structure from Data using the Chow-Liu Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Structure%20Learning%20with%20TAN.html">10. Learning Tree-augmented Naive Bayes (TAN) Structure from Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Extending%20pgmpy.html">11. Extending pgmpy</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorial Notebooks</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="1.%20Introduction%20to%20Probabilistic%20Graphical%20Models.html">1. Introduction to Probabilitic Graphical Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="2.%20Bayesian%20Networks.html">2. Bayesian Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.%20Causal%20Bayesian%20Networks.html">3. Causal Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.%20Markov%20Models.html">4. Markov Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="5.%20Exact%20Inference%20in%20Graphical%20Models.html">5. Exact Inference in Graphical Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="6.%20Approximate%20Inference%20in%20Graphical%20Models.html">6. Approximate Inference in Graphical Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="7.%20Parameterizing%20with%20Continuous%20Variables.html">7. Parameterizing with Continuous Variables</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">8. Sampling In Continuous Graphical Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Hamiltonian-Monte-Carlo">8.1. Hamiltonian Monte Carlo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Hamiltonian-Dynamics">8.1.1. Hamiltonian Dynamics</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Euler’s-Method">8.1.1.1. Euler’s Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Leapfrog-Method">8.1.1.2. Leapfrog Method</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Example:-Simulating-Hamiltonian-dynamics-of-a-simple-pendulum">8.1.1.3. Example: Simulating Hamiltonian dynamics of a simple pendulum</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Hamiltonian-and-Probability:-Canonical-Distributions">8.1.2. Hamiltonian and Probability: Canonical Distributions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Hamiltonian-Monte-Carlo-Algorithm">8.1.3. Hamiltonian Monte Carlo Algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Hamiltonian-Monte-Carlo-in-pgmpy">8.1.4. Hamiltonian Monte Carlo in pgmpy</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Hamiltonian-Monte-Carlo-with-dual-averaging">8.1.5. Hamiltonian Monte Carlo with dual averaging</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#No-U-Turn-Sampler">8.2. No-U-Turn Sampler</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#No-U-Turn-Sampler-with-dual-averaging">8.2.1. No-U-Turn Sampler with dual averaging</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Support-for-coustom-Models">8.3. Support for coustom Models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="9.%20Reading%20and%20Writing%20from%20pgmpy%20file%20formats.html">9. Reading and Writing from pgmpy file formats</a></li>
<li class="toctree-l1"><a class="reference internal" href="10.%20Learning%20Bayesian%20Networks%20from%20Data.html">10. Learning Bayesian Networks from Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="11.%20A%20Bayesian%20Network%20to%20model%20the%20influence%20of%20energy%20consumption%20on%20greenhouse%20gases%20in%20Italy.html">11. A Bayesian Network to model the influence of energy consumption on greenhouse gases in Italy</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">pgmpy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li><span class="section-number">8. </span>Sampling In Continuous Graphical Models</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/detailed_notebooks/8. Sampling Algorithms.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="Sampling-In-Continuous-Graphical-Models">
<h1><span class="section-number">8. </span>Sampling In Continuous Graphical Models<a class="headerlink" href="#Sampling-In-Continuous-Graphical-Models" title="Permalink to this headline">¶</a></h1>
<p>As we know inference is asking conditional probability questions to the models, the exact solution of these problems quickly becomes intractable. Sampling algorithms can be used to get approximate inference results by generating a large number of coherent samples that converge to original distribution. In this notebook we take a look at some of the sampling algorithms that can be used to sample from continuous case models.</p>
<ol class="arabic simple">
<li><p>Hamiltonian Monte Carlo</p></li>
<li><p>No-U-Turn Sample</p></li>
</ol>
<section id="Hamiltonian-Monte-Carlo">
<h2><span class="section-number">8.1. </span>Hamiltonian Monte Carlo<a class="headerlink" href="#Hamiltonian-Monte-Carlo" title="Permalink to this headline">¶</a></h2>
<p>Hamiltonian Monte Carlo (HMC) is a Markov Chain Monte Carlo (MCMC) that proposes future states in Markov Chain using Hamiltonian Dynamics. Before understanding the HMC algorithm lets first understand Hamiltonian Dynamics.</p>
<section id="Hamiltonian-Dynamics">
<h3><span class="section-number">8.1.1. </span>Hamiltonian Dynamics<a class="headerlink" href="#Hamiltonian-Dynamics" title="Permalink to this headline">¶</a></h3>
<p>Hamiltonian dynamics are used to describe how objects move throughout a system. Hamiltonian dynamics is defined in terms of object location <img class="math" src="../_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.png" alt="x"/> and its momentum <img class="math" src="../_images/math/141bbefb74014fc5e43499901bf78607ae335583.png" alt="p"/> (equivalent to object’s mass times velocity) at some time <img class="math" src="../_images/math/907a4add6d5db5b7f197f7924f1371b8ac404fe6.png" alt="t"/>. For each location of object there is an associated potential energy <img class="math" src="../_images/math/f27e04a3bf55c0b10cc028169f91878fda1bcd9e.png" alt="U(x)"/> and with momentum there is associated kinetic energy <img class="math" src="../_images/math/d202e378ff02af696b2d38bd1ea983e92a5f2743.png" alt="K(p)"/>. The total energy of system is constant and is called as Hamiltonian <img class="math" src="../_images/math/44bfc9c9aaf5a94b2aa0b21b5ccf3092d71ada0e.png" alt="H(x, p)"/>, defined as the sum of
potential energy and kinetic energy:</p>
<div class="math">
<p><img src="../_images/math/0ecc8bab0b4b4658401a59cc62710ab4c2c3578a.png" alt="H(x, p) = U(x) + K(p)"/></p>
</div><p>The partial derivatives of the Hamiltonian determines how position <img class="math" src="../_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.png" alt="x"/> and momentum <img class="math" src="../_images/math/141bbefb74014fc5e43499901bf78607ae335583.png" alt="p"/> change over time <img class="math" src="../_images/math/907a4add6d5db5b7f197f7924f1371b8ac404fe6.png" alt="t"/>, according to Hamiltonian’s equations:</p>
<div class="math">
<p><img src="../_images/math/21b1a3e5ce44e7913de823553a48e53cf8fc2e7d.png" alt="\frac{dx_i}{dt} = \frac{\partial H}{\partial p_i} = \frac{\partial K(p)}{\partial p_i}"/></p>
</div><div class="math">
<p><img src="../_images/math/13d7dec09fca3075decce7b314a8ca096457e689.png" alt="\frac{dp_i}{dt} = -\frac{\partial H}{\partial x_i} = -\frac{\partial U(x)}{\partial x_i}"/></p>
</div><p>The above equations operates on a <em>d-dimensional position vector :math:`x`</em> and a <em>d-dimensional momentum vector :math:`p`</em>, for <img class="math" src="../_images/math/e43960c1376a9268121e5f7cca445c7d393edc88.png" alt="i = 1, 2, \cdots, d"/>.</p>
<p>Thus, if we can evaluate <img class="math" src="../_images/math/e6766d320f6f8f2c20d9d108b026f8db9db99848.png" alt="\frac{\partial U(x)}{\partial x_i}"/> and <img class="math" src="../_images/math/96791fd8289860b0ebb718ebc1fc02964ef4c492.png" alt="\frac{\partial K(p)}{\partial p_i}"/> and have a set of initial conditions i.e an initial position and initial momentum at time <img class="math" src="../_images/math/ec0f4b5ec85f2c2005b5f78c12cf51c1cb2bb167.png" alt="t_0"/>, then we can predict the location and momentum of object at any future time <img class="math" src="../_images/math/c820f2f0a659008aa458fba1abfda7938f21c28e.png" alt="t = t_0 + T"/> by simulating dynamics for a time duration <img class="math" src="../_images/math/e8dea8254118f111b5fb20895b03528c17566f06.png" alt="T"/>. ### Discretizing Hamiltonian’s Equations</p>
<p>The Hamiltonian’s equations describes an object’s motion in regard to time, which is a continuous variable. For simulating dynamics on a computer, Hamiltonian’s equations must be numerically approximated by discretizing time. This is done by splitting the time interval <img class="math" src="../_images/math/e8dea8254118f111b5fb20895b03528c17566f06.png" alt="T"/> into small intervals of size <img class="math" src="../_images/math/0ad7b30534898f253002222f998f38001e604648.png" alt="\epsilon"/>.</p>
<section id="Euler’s-Method">
<h4><span class="section-number">8.1.1.1. </span>Euler’s Method<a class="headerlink" href="#Euler’s-Method" title="Permalink to this headline">¶</a></h4>
<p>For Hamiltonian’s equations, this method performs the following steps, for each component of position and momentum (indexed by <img class="math" src="../_images/math/865bf9c8cbee3576138321ac5e622030a2624d47.png" alt="i=1, ...,d"/>)</p>
<div class="math">
<p><img src="../_images/math/0b147fa60a9d06a93c2314b32d5d24953d31e09f.png" alt="p_i(t + \epsilon) = p_i(t) + \epsilon \frac{dp_i}{dt}(t) = p_i(t) - \epsilon \frac{\partial U}{\partial x_i(t)}"/></p>
</div><div class="math">
<p><img src="../_images/math/ee672719746c870de0e1cc42c054f2eed2346ee0.png" alt="x_i(t + \epsilon) = x_i(t) + \epsilon \frac{dx_i}{dt} = x_i(t) + \epsilon \frac{\partial K}{\partial p_i(t)}"/></p>
</div><p>Even better results can be obtained if we use updated value of momentum in later equation</p>
<div class="math">
<p><img src="../_images/math/32bc467308ee3756a12bccf43dceb32973388b98.png" alt="x_i(t + \epsilon) = x_i(t) + \epsilon \frac{\partial K}{\partial p_i(t + \epsilon)}"/></p>
</div><p>This method is called as <strong>Modified Euler’s method</strong>.</p>
</section>
<section id="Leapfrog-Method">
<h4><span class="section-number">8.1.1.2. </span>Leapfrog Method<a class="headerlink" href="#Leapfrog-Method" title="Permalink to this headline">¶</a></h4>
<p>Unlike Euler’s method where we take full steps for updating position and momentum in leapfrog method we take half steps to update momentum value.</p>
<div class="math">
<p><img src="../_images/math/69e5349bfd834e15e39e4b8280649a87a7c702f3.png" alt="p_i(t + \epsilon / 2) = p_i(t) - (\epsilon / 2) \frac{\partial U}{\partial x_i(t)}"/></p>
</div><div class="math">
<p><img src="../_images/math/2eb588502f3bf1f757670c4668f406b923b6ea16.png" alt="x_i(t + \epsilon) = x_i(t) + \epsilon \frac{\partial K}{\partial p_i(t + \epsilon /2)}"/></p>
</div><div class="math">
<p><img src="../_images/math/65a1a8d3ca3d74e0bc164ecb05b1342b08a18e99.png" alt="p_i(t + \epsilon) = p_i(t) - (\epsilon / 2) \frac{\partial U}{\partial x_i(t + \epsilon)}"/></p>
</div><p>Leapfrog method yields even better result than Modified Euler Method.</p>
</section>
<section id="Example:-Simulating-Hamiltonian-dynamics-of-a-simple-pendulum">
<h4><span class="section-number">8.1.1.3. </span>Example: Simulating Hamiltonian dynamics of a simple pendulum<a class="headerlink" href="#Example:-Simulating-Hamiltonian-dynamics-of-a-simple-pendulum" title="Permalink to this headline">¶</a></h4>
<p>Imagine a bob of mass <img class="math" src="../_images/math/5b86129132ab70546e40931c75182dfb9883645a.png" alt="m = 1"/> attached to a string of length <img class="math" src="../_images/math/db5ab47290508c9c3c34eca635ea2f08a72db2ac.png" alt="l=1.5"/> whose one end is fixed at point <img class="math" src="../_images/math/962c1d81036036ef55bc76d513ca5e160bae8ab4.png" alt="(x=0, y=0)"/>. The equilibrium position of the pendulum is at <img class="math" src="../_images/math/72810d8f4a084481458a621a19c31dfa768e0a30.png" alt="x = 0"/>. Now keeping string stretched we move it some distance horizontally say <img class="math" src="../_images/math/ed7fb0260e58d3ca5851e823ff991dae4cde5671.png" alt="x_0"/>. The corresponding change in potential energy is given by</p>
<p>$ U(h) = mg:nbsphinx-math:<cite>Delta `h $, where :math:</cite>Delta h` is change in height and <img class="math" src="../_images/math/157ba5711de84b4c715a0478fd8ae440e596d96e.png" alt="g"/> is gravity of earth.</p>
<p>Using simple trigonometry one can derive relationship between <img class="math" src="../_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.png" alt="x"/> and <img class="math" src="../_images/math/852b8ffc2553dfa818c2e131e468d82d26f1af1e.png" alt="\Delta h"/>.</p>
<div class="math">
<p><img src="../_images/math/77a5147233187c0026b4b9120709b4cb1648ddc0.png" alt="U(x) = mgl(1 - cos(sin^{-1}(x/l)))"/></p>
</div><p>Kinetic energy of bob can be written in terms of momentum as</p>
<div class="math">
<p><img src="../_images/math/3197a04a4f787dede91fedcfc4badc487d3bb463.png" alt="K(v) = \frac{mv^2}{2} = \frac{(mv)^2}{2m} = \frac{p^2}{2m} = K(p)"/></p>
</div><p>Further, partial derivatives of potential and kinetic energy can be written as:</p>
<div class="math">
<p><img src="../_images/math/46e9f32c19f5d6a3b9ca4f211fbc7991341c6c73.png" alt="\frac{\partial U}{\partial x} = \frac{mglx}{\sqrt{l^2 - x^2}}"/></p>
</div><p>and</p>
<div class="math">
<p><img src="../_images/math/3eaca3f740efcd398ef2a9dc9ae43605d16156bb.png" alt="\frac{\partial K}{\partial p} = \frac{p}{m}"/></p>
</div><p>Here is a animation that uses these equations to simulate the dynamics of simple pendulum <img alt="Drawing" src="images/simple_pendulum.gif" /> The sub-plot in the right upper half of the output demonstrates the energies. The red portion of first bar plot represents potential energy and black represents kinetic energy. The second bar plot represents the Hamiltonian. The lower right sub-plot shows the phase space showing how momentum and position are varying. We can see that phase space maps out an ellipse without
deviating from its path. In case of Euler method the particle doesn’t fully trace a ellipse instead diverges slowly towards infinity. One can clearly see that value of position and momentum are not completely random, but takes a deterministic circular kind of trajectory. If we use Leapfrog method to propose future states than we can avoid random-walk behavior which we saw in Metropolis-Hastings algorithm. This is the main reason for good performance of HMC algorithm.</p>
</section>
</section>
<section id="Hamiltonian-and-Probability:-Canonical-Distributions">
<h3><span class="section-number">8.1.2. </span>Hamiltonian and Probability: Canonical Distributions<a class="headerlink" href="#Hamiltonian-and-Probability:-Canonical-Distributions" title="Permalink to this headline">¶</a></h3>
<p>Now having a bit of understanding what is Hamiltonian and how we can simulate Hamiltonian dynamics, we now need to understand how we can use these Hamiltonian dynamics for MCMC. We need to develop some relation between probability distribution and Hamiltonian so that we can use Hamiltonian dynamics to explore the distribution. To relate <img class="math" src="../_images/math/44bfc9c9aaf5a94b2aa0b21b5ccf3092d71ada0e.png" alt="H(x, p)"/> to target distribution <img class="math" src="../_images/math/f01cb75ce76498bd7c3e6f4505d157bc0315ce1d.png" alt="P(x)"/> we use a concept from statistical mechanics known as the canonical distribution. For any energy function
<img class="math" src="../_images/math/b0768d119ea759f089b0f0b0f7ebaef6c1c5e7df.png" alt="E(q)"/>, defined over a set of variables <img class="math" src="../_images/math/a5fa84b363f309ebc8fe7db38304541732c7de9a.png" alt="q"/>, we can find corresponding <img class="math" src="../_images/math/71fb18a44e207c5ea02b63133a8d236bdf1a2e9e.png" alt="P(q)"/></p>
<div class="math">
<p><img src="../_images/math/d8428756932d67042a90d260fba1286d2daa73ef.png" alt="P(q) = \frac{1}{Z} exp \left( \frac{-E(q)}{T} \right)"/></p>
</div><p>, where <img class="math" src="../_images/math/95f028ab2b20b895fa12d986e0d9f40f7b6e52d3.png" alt="Z"/> is normalizing constant called Partition function and <img class="math" src="../_images/math/e8dea8254118f111b5fb20895b03528c17566f06.png" alt="T"/> is temperature of system. For our use case we will consider <img class="math" src="../_images/math/e34a1b031a138965671cf521ade17793401d7f9b.png" alt="T=1"/>.</p>
<p>Since, the Hamiltonian is an energy function for the joint state of “position”, <img class="math" src="../_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.png" alt="x"/> and “momentum”, <img class="math" src="../_images/math/141bbefb74014fc5e43499901bf78607ae335583.png" alt="p"/>, so we can define a joint distribution for them as follows:</p>
<div class="math">
<p><img src="../_images/math/44599eb0b230db147e9e473f98ea20c0902aac5f.png" alt="P(x, p) = \frac{e^{-H(x, p)}}{Z}"/></p>
</div><p>Since <img class="math" src="../_images/math/98e629ed9ded44dbf2a5ae17bc87bbf07694f0f1.png" alt="H(x, p) = U(x) + K(p)"/>, we can write above equation as</p>
<div class="math">
<p><img src="../_images/math/00257f4c81caede10b52352b14b0609ecacdc223.png" alt="P(x, p) = \frac{e^{-U(x)-K(p)}}{z}"/></p>
</div><div class="math">
<p><img src="../_images/math/f3ed69f9cd65732904beeefc3c6ece8f0b787d97.png" alt="P(x, p) = \frac{e^{-U(x)}e^{-K(p)}}{Z}"/></p>
</div><p>Furthermore we can associate probability distribution with each of the potential and kinetic energy (<img class="math" src="../_images/math/f01cb75ce76498bd7c3e6f4505d157bc0315ce1d.png" alt="P(x)"/> with potential energy and <img class="math" src="../_images/math/e84db8e2d4a78055fe6b7c8446b5f08b142b2deb.png" alt="P(p)"/>, with kinetic energy). Thus, we can write above equation as:</p>
<div class="math">
<p><img src="../_images/math/33423448ad9abac66bde53a1377fe99bf4d0e476.png" alt="P(x, p) = \frac{P(x)P(p)}{Z'}"/></p>
</div><p>,where <img class="math" src="../_images/math/1f360609d1924e50e1b95caf88bbdec5543c7449.png" alt="Z'"/> is new normalizing constant. Since joint distribution factorizes over <img class="math" src="../_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.png" alt="x"/> and <img class="math" src="../_images/math/141bbefb74014fc5e43499901bf78607ae335583.png" alt="p"/>, we can conclude that <img class="math" src="../_images/math/f01cb75ce76498bd7c3e6f4505d157bc0315ce1d.png" alt="P(x)"/> and <img class="math" src="../_images/math/e84db8e2d4a78055fe6b7c8446b5f08b142b2deb.png" alt="P(p)"/> are independent. Because of this independence we can choose any distribution from which we want to sample the momentum variable. A common choice is to use a zero mean and unit variance Normal distribution <img class="math" src="../_images/math/5eb7c99280e4fdcbe9545e8db4287554dc6ce6e8.png" alt="N(0, I)"/> The target distribution of interest <img class="math" src="../_images/math/f01cb75ce76498bd7c3e6f4505d157bc0315ce1d.png" alt="P(x)"/> from which we actually want to sample from is associated with
potential energy.</p>
<div class="math">
<p><img src="../_images/math/906061d5e00fea9bc78e72f7373785ca9d418e64.png" alt="U(x) = - log (P(x))"/></p>
</div><p>Thus, if we can calculate <img class="math" src="../_images/math/ecff9011ea620116ec69c76346ed05d1e8281144.png" alt="\frac{\partial log(P(x))}{\partial x_i}"/>, then we are in business and we can use Hamiltonian dynamics to generate samples.</p>
</section>
<section id="Hamiltonian-Monte-Carlo-Algorithm">
<h3><span class="section-number">8.1.3. </span>Hamiltonian Monte Carlo Algorithm<a class="headerlink" href="#Hamiltonian-Monte-Carlo-Algorithm" title="Permalink to this headline">¶</a></h3>
<p>Given initial state <img class="math" src="../_images/math/ed7fb0260e58d3ca5851e823ff991dae4cde5671.png" alt="x_0"/>, stepsize <img class="math" src="../_images/math/0ad7b30534898f253002222f998f38001e604648.png" alt="\epsilon"/>, number of steps <img class="math" src="../_images/math/19eef1966f7c545af3ac8c0fa486974d873e3c65.png" alt="L"/>, log density function <img class="math" src="../_images/math/9098c1c4618d7a0f321cee441aabee7f1b57a19b.png" alt="U"/>, number of samples to be drawn <img class="math" src="../_images/math/4abba779877abb276b98ccb2b4ba9bf2e41947ab.png" alt="M"/>, we can write HMC algorithm as:</p>
<ul class="simple">
<li><p>set $m = 0 $</p></li>
<li><p>repeat until <img class="math" src="../_images/math/0994508bf8ec492baf5961e27711c5f4702fb938.png" alt="m = M"/></p>
<ol class="arabic simple">
<li><p>set <img class="math" src="../_images/math/3c6b023ad7724de7080faf34092775288c92a7cd.png" alt="m \leftarrow m + 1"/></p></li>
<li><p>Sample new initial momentum <img class="math" src="../_images/math/8968e4fd6ebe2d668010ed37e2172340daaefa2d.png" alt="p_0"/> ~ <img class="math" src="../_images/math/5eb7c99280e4fdcbe9545e8db4287554dc6ce6e8.png" alt="N(0, I)"/></p></li>
<li><p>Set <img class="math" src="../_images/math/50ee8a46e5392ab3f1d63c6912b173830ca05fbe.png" alt="x_m \leftarrow x_{m-1}, x' \leftarrow x_{m-1}, p' \leftarrow p_0"/></p></li>
<li><p>repeat for <img class="math" src="../_images/math/19eef1966f7c545af3ac8c0fa486974d873e3c65.png" alt="L"/> steps</p>
<ul>
<li><p>Set <img class="math" src="../_images/math/30596a4b5911ed38e017a9b0546719fd7114b283.png" alt="x', p' \leftarrow Leapfrog(x', p', \epsilon)"/></p></li>
</ul>
</li>
<li><p>Calculate acceptance probability <img class="math" src="../_images/math/b790c27f5a8e4d84e74875106b690478720fcefe.png" alt="\alpha = min \left(1, \frac{exp( U(x') - (p'.p')/2 )}{exp( U(x_{m-1}) - (p_0.p_0)/2 )} \right)"/></p></li>
<li><p>Draw a random number u ~ Uniform(0, 1)</p></li>
<li><p>if <img class="math" src="../_images/math/d2408e3c25783435885e9d5ec6548d2d4c0217d7.png" alt="u \leq \alpha"/> then <img class="math" src="../_images/math/43f4c9915a4dcf883f328a0c43374dcba71a7389.png" alt="x_m \leftarrow x', p_m \leftarrow -p'"/></p></li>
</ol>
</li>
</ul>
<p><img class="math" src="../_images/math/135140df16b895f03c6a28279df53029df1573a5.png" alt="Leapfrog"/> is a function that runs a single iteration of Leapfrog method.</p>
<p>In practice sometimes instead of explicitly giving number of steps <img class="math" src="../_images/math/19eef1966f7c545af3ac8c0fa486974d873e3c65.png" alt="L"/>, we use <strong>trajectory length</strong> which is product of number of steps <img class="math" src="../_images/math/19eef1966f7c545af3ac8c0fa486974d873e3c65.png" alt="L"/>, and stepsize <img class="math" src="../_images/math/0ad7b30534898f253002222f998f38001e604648.png" alt="\epsilon"/>.</p>
</section>
<section id="Hamiltonian-Monte-Carlo-in-pgmpy">
<h3><span class="section-number">8.1.4. </span>Hamiltonian Monte Carlo in pgmpy<a class="headerlink" href="#Hamiltonian-Monte-Carlo-in-pgmpy" title="Permalink to this headline">¶</a></h3>
<p>In pgmpy one can use Hamiltonian Monte Carlo algorithm by importing HamiltonianMC from pgmpy.inference.continuous</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pgmpy.sampling</span> <span class="kn">import</span> <span class="n">HamiltonianMC</span> <span class="k">as</span> <span class="n">HMC</span>
</pre></div>
</div>
</div>
<p>Lets use the HamiltonianMC implementation and draw some samples from a multivariate disrtibution $ P(x) = N(<span class="math">\mu</span>, <span class="math">\Sigma</span>)$, where</p>
<div class="math">
<p><img src="../_images/math/33c7b05d4d768a1944807b61af8ee91465b5197c.png" alt="\mu = [0, 0], \qquad
\Sigma = \left[
    \begin{array}{cc}
    1 &amp; 0.97 \\
    0.97 &amp; 1
    \end{array}
    \right]"/></p>
</div><div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">from</span> <span class="nn">pgmpy.factors.distributions</span> <span class="kn">import</span> <span class="n">GaussianDistribution</span> <span class="k">as</span> <span class="n">JGD</span>
<span class="kn">from</span> <span class="nn">pgmpy.sampling</span> <span class="kn">import</span> <span class="n">LeapFrog</span><span class="p">,</span> <span class="n">GradLogPDFGaussian</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">77777</span><span class="p">)</span>
<span class="c1"># Defining a multivariate distribution model</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">covariance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.97</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.97</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">JGD</span><span class="p">([</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">],</span> <span class="n">mean</span><span class="p">,</span> <span class="n">covariance</span><span class="p">)</span>

<span class="c1"># Creating a HMC sampling instance</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">HMC</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">grad_log_pdf</span><span class="o">=</span><span class="n">GradLogPDFGaussian</span><span class="p">,</span> <span class="n">simulate_dynamics</span><span class="o">=</span><span class="n">LeapFrog</span><span class="p">)</span>
<span class="c1"># Drawing samples</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">initial_pos</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
                         <span class="n">trajectory_length</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">stepsize</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">));</span> <span class="n">plt</span><span class="o">.</span><span class="n">hold</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">],</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;HMC samples&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">],</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">],</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;First 100 samples&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">hold</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/utgup/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:18: MatplotlibDeprecationWarning: pyplot.hold is deprecated.
    Future behavior will be consistent with the long-time default:
    plot commands add elements without first clearing the
    Axes and/or Figure.
/home/utgup/anaconda3/lib/python3.5/site-packages/matplotlib/__init__.py:917: UserWarning: axes.hold is deprecated. Please remove it from your matplotlibrc and/or style files.
  warnings.warn(self.msg_depr_set % key)
/home/utgup/anaconda3/lib/python3.5/site-packages/matplotlib/rcsetup.py:152: UserWarning: axes.hold is deprecated, will be removed in 3.0
  warnings.warn(&#34;axes.hold is deprecated, will be removed in 3.0&#34;)
/home/utgup/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:21: MatplotlibDeprecationWarning: pyplot.hold is deprecated.
    Future behavior will be consistent with the long-time default:
    plot commands add elements without first clearing the
    Axes and/or Figure.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/detailed_notebooks_8._Sampling_Algorithms_3_1.png" src="../_images/detailed_notebooks_8._Sampling_Algorithms_3_1.png" />
</div>
</div>
<p>One, can change the values of parameters <code class="docutils literal notranslate"><span class="pre">stepsize</span></code> and <code class="docutils literal notranslate"><span class="pre">trajectory_length</span></code> and see the convergence towards target distribution. For example set the value of <code class="docutils literal notranslate"><span class="pre">stepsize</span> <span class="pre">=</span> <span class="pre">0.5</span></code> and let rest parameters have the same value and see the output. With this you might get a feel that performance of HMC critically depends upon choice of these parameters.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">stepsize</span></code> parameter for HamiltonianMC implementation is optional, but should be use only as starting point value. One should hand-tune the model using this stepsize value for good performance.</p>
</section>
<section id="Hamiltonian-Monte-Carlo-with-dual-averaging">
<h3><span class="section-number">8.1.5. </span>Hamiltonian Monte Carlo with dual averaging<a class="headerlink" href="#Hamiltonian-Monte-Carlo-with-dual-averaging" title="Permalink to this headline">¶</a></h3>
<p>In pgmpy we have implemented an another variant of HMC in which we adapt the stepsize during the course of sampling thus completely eliminates the need of specifying <code class="docutils literal notranslate"><span class="pre">stepsize</span></code> (but still requires <code class="docutils literal notranslate"><span class="pre">trajectory_length</span></code> to be specified by user). This variant of HMC is known as Hamiltonian Monte Carlo with dual averaging (HamiltonianMCda in pgmpy). One can also use Modified Euler to simulate dynamics instead of leapfrog, or even can plug-in one’s own implementation for simulating dynamics using
base class for it.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pgmpy.sampling</span> <span class="kn">import</span> <span class="n">HamiltonianMCDA</span> <span class="k">as</span> <span class="n">HMCda</span><span class="p">,</span> <span class="n">ModifiedEuler</span>
<span class="c1"># Using modified euler instead of Leapfrog for simulating dynamics</span>
<span class="n">sampler_da</span> <span class="o">=</span> <span class="n">HMCda</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">GradLogPDFGaussian</span><span class="p">,</span> <span class="n">simulate_dynamics</span><span class="o">=</span><span class="n">ModifiedEuler</span><span class="p">)</span>
<span class="c1"># num_adapt is number of iteration to run adaptation of stepsize</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">sampler_da</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">initial_pos</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">num_adapt</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">trajectory_length</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Acceptance rate:&quot;</span><span class="p">,</span><span class="n">sampler_da</span><span class="o">.</span><span class="n">acceptance_rate</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
               x         y
0   7.000000e+00  0.000000
1  3.458460e-323  0.000000
2  3.458460e-323  0.000000
3  3.458460e-323  0.000000
4  3.458460e-323  0.000000
5   3.614684e+00  0.780326
6   1.316832e+00  0.643645
7   1.316832e+00  0.643645
8  -1.111247e-01 -0.306480
9   1.163398e+00  1.357304

Acceptance rate: 0.5
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/utgup/anaconda3/lib/python3.5/site-packages/pgmpy-0.1.6-py3.5.egg/pgmpy/sampling/HMC.py:111: RuntimeWarning: divide by zero encountered in double_scalars
  return (1/(acceptance_prob ** a)) &gt; (2**(-a))
</pre></div></div>
</div>
<p>The values returned by HamiltonianMC and HamiltonianMCda depends upon the installation available in the working environment. In working env has a installation of pandas, it returns a pandas.DataFrame object otherwise it returns a numpy.recarry (numpy recorded arrays).</p>
<p>Lets now use base class for simulating hamiltonian dynamics and write our own Modified Euler method</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pgmpy.sampling</span> <span class="kn">import</span> <span class="n">BaseSimulateHamiltonianDynamics</span>

<span class="k">class</span> <span class="nc">ModifiedEulerMethod</span><span class="p">(</span><span class="n">BaseSimulateHamiltonianDynamics</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">position</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">stepsize</span><span class="p">,</span> <span class="n">grad_log_pdf</span><span class="p">,</span> <span class="n">grad_log_position</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="n">BaseSimulateHamiltonianDynamics</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">position</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span>
                                                 <span class="n">stepsize</span><span class="p">,</span> <span class="n">grad_log_pdf</span><span class="p">,</span> <span class="n">grad_log_position</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">new_position</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_momentum</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_grad_logp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_proposed_values</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_get_proposed_values</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">new_momentum</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">stepsize</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_log_position</span>
        <span class="n">new_position</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">stepsize</span> <span class="o">*</span> <span class="n">new_momentum</span>

        <span class="n">grad_log</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_log_pdf</span><span class="p">(</span><span class="n">new_position</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">get_gradient_log_pdf</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">new_position</span><span class="p">,</span> <span class="n">new_momentum</span><span class="p">,</span> <span class="n">grad_log</span>

<span class="n">hmc_sampler</span> <span class="o">=</span> <span class="n">HMC</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">GradLogPDFGaussian</span><span class="p">,</span> <span class="n">simulate_dynamics</span><span class="o">=</span><span class="n">ModifiedEulerMethod</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">hmc_sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">initial_pos</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">trajectory_length</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">stepsize</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total accepted proposal:&quot;</span><span class="p">,</span> <span class="n">hmc_sampler</span><span class="o">.</span><span class="n">accepted_proposals</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
          x         y
0  0.000000  0.000000
1  0.624716  0.680638
2  0.928227  1.143031
3 -0.234847 -0.118653
4 -1.633648 -1.977647
5 -1.282438 -1.442565
6 -1.734446 -1.282935
7 -1.552439 -1.300669
8  0.729025  0.793016
9 -0.489195 -0.430182
Total accepted proposal: 10.0
</pre></div></div>
</div>
</section>
</section>
<section id="No-U-Turn-Sampler">
<h2><span class="section-number">8.2. </span>No-U-Turn Sampler<a class="headerlink" href="#No-U-Turn-Sampler" title="Permalink to this headline">¶</a></h2>
<p>Both (HMC and HMCda) of these algorithms requires some hand-tuning from user, which can be time consuming especially for high dimensional complex model. No-U-Turn Sampler(NUTS) is an extension of HMC that eliminates the need to specify the trajectory length but requires user to specify stepsize.</p>
<p>NUTS, removes the need of parameter number of steps by considering a metric to evaluate whether we have ran Leapfrog algorithm for long enough, that is when running the simulation for more steps would no longer increase the distance between the proposal value of <img class="math" src="../_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.png" alt="x"/> and initial value of <img class="math" src="../_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.png" alt="x"/></p>
<p>At high level, NUTS uses the leapfrog method to trace out a path forward and backward in fictitious time, first running forwards or backwards 1 step, the forwards and backwards 2 steps, then forwards or backwards 4 steps etc. This doubling process builds a balanced binary tree whose leaf nodes correspond to position-momentum states. The doubling process is halted when the sub-trajectory from the leftmost to the rightmost nodes of any balanced subtree of the overall binary tree starts to double
back on itself (i.e., the fictional particle starts to make a “U-Turn”). At this point NUTS stops the simulation and samples from among the set of points computed during the simulation, taking are to preserve detailed balance.</p>
<p>Lets use NUTS and draw some samples.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pgmpy.sampling</span> <span class="kn">import</span> <span class="n">NoUTurnSampler</span> <span class="k">as</span> <span class="n">NUTS</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">covariance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">JGD</span><span class="p">([</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;z&#39;</span><span class="p">],</span> <span class="n">mean</span><span class="p">,</span> <span class="n">covariance</span><span class="p">)</span>

<span class="c1"># Creating sampling instance of NUTS</span>
<span class="n">NUTS_sampler</span> <span class="o">=</span> <span class="n">NUTS</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">grad_log_pdf</span><span class="o">=</span><span class="n">GradLogPDFGaussian</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">NUTS_sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">initial_pos</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">stepsize</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">Axes3D</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hold</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">],</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">],</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;z&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;NUTS Samples&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">][:</span><span class="mi">50</span><span class="p">],</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">][:</span><span class="mi">50</span><span class="p">],</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;z&#39;</span><span class="p">][:</span><span class="mi">50</span><span class="p">],</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Warm-up period&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Scatter plot of samples&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hold</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/utgup/anaconda3/lib/python3.5/site-packages/pgmpy-0.1.6-py3.5.egg/pgmpy/sampling/NUTS.py:130: RuntimeWarning: invalid value encountered in true_divide
  if np.random.rand() &lt; candidate_set_size2 / (candidate_set_size2 + candidate_set_size):
/home/utgup/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:13: MatplotlibDeprecationWarning: pyplot.hold is deprecated.
    Future behavior will be consistent with the long-time default:
    plot commands add elements without first clearing the
    Axes and/or Figure.
/home/utgup/anaconda3/lib/python3.5/site-packages/matplotlib/__init__.py:917: UserWarning: axes.hold is deprecated. Please remove it from your matplotlibrc and/or style files.
  warnings.warn(self.msg_depr_set % key)
/home/utgup/anaconda3/lib/python3.5/site-packages/matplotlib/rcsetup.py:152: UserWarning: axes.hold is deprecated, will be removed in 3.0
  warnings.warn(&#34;axes.hold is deprecated, will be removed in 3.0&#34;)
/home/utgup/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:18: MatplotlibDeprecationWarning: pyplot.hold is deprecated.
    Future behavior will be consistent with the long-time default:
    plot commands add elements without first clearing the
    Axes and/or Figure.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/detailed_notebooks_8._Sampling_Algorithms_9_1.png" src="../_images/detailed_notebooks_8._Sampling_Algorithms_9_1.png" />
</div>
</div>
<p>The <strong>Warm-up period</strong> a.k.a <strong>Burn-in period</strong> of Markov chain , is the amount of time it takes for the markov chain to reach the target stationary distribution. The samples generated during this period of Markov chain are usually thrown away because they don’t show the characteristics of distribution from which they are sampled.</p>
<p>Since it is difficult to visualize more than 3-Dimensions we generally use a trace-plot of Markov chain to determine this warm-up period.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hold</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">],</span><span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">],</span> <span class="s1">&#39;g-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s1">&#39;z&#39;</span><span class="p">],</span> <span class="s1">&#39;c-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;z&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Warm-up period&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Trace plot of Markov Chain&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hold</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/utgup/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:2: MatplotlibDeprecationWarning: pyplot.hold is deprecated.
    Future behavior will be consistent with the long-time default:
    plot commands add elements without first clearing the
    Axes and/or Figure.
  from ipykernel import kernelapp as app
/home/utgup/anaconda3/lib/python3.5/site-packages/matplotlib/__init__.py:917: UserWarning: axes.hold is deprecated. Please remove it from your matplotlibrc and/or style files.
  warnings.warn(self.msg_depr_set % key)
/home/utgup/anaconda3/lib/python3.5/site-packages/matplotlib/rcsetup.py:152: UserWarning: axes.hold is deprecated, will be removed in 3.0
  warnings.warn(&#34;axes.hold is deprecated, will be removed in 3.0&#34;)
/home/utgup/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:9: MatplotlibDeprecationWarning: pyplot.hold is deprecated.
    Future behavior will be consistent with the long-time default:
    plot commands add elements without first clearing the
    Axes and/or Figure.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/detailed_notebooks_8._Sampling_Algorithms_11_1.png" src="../_images/detailed_notebooks_8._Sampling_Algorithms_11_1.png" />
</div>
</div>
<section id="No-U-Turn-Sampler-with-dual-averaging">
<h3><span class="section-number">8.2.1. </span>No-U-Turn Sampler with dual averaging<a class="headerlink" href="#No-U-Turn-Sampler-with-dual-averaging" title="Permalink to this headline">¶</a></h3>
<p>Like HMCda in No-U-Turn sampler with dual averaging (NUTSda) we adapt the stepsize during the course of sampling thus completely eliminates the need of specifying <code class="docutils literal notranslate"><span class="pre">stepsize</span></code>. Thus we can use NUTSda without any hand tuning at all.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pgmpy.sampling</span> <span class="kn">import</span> <span class="n">NoUTurnSamplerDA</span> <span class="k">as</span> <span class="n">NUTSda</span>
<span class="n">NUTSda_sampler</span> <span class="o">=</span> <span class="n">NUTSda</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">grad_log_pdf</span><span class="o">=</span><span class="n">GradLogPDFGaussian</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">NUTSda_sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">initial_pos</span><span class="o">=</span><span class="p">[</span><span class="mf">0.457420</span><span class="p">,</span> <span class="mf">0.500307</span><span class="p">,</span> <span class="mf">0.211056</span><span class="p">],</span> <span class="n">num_adapt</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
          x         y         z
0  0.457420  0.500307  0.211056
1  0.457420  0.500307  0.211056
2  0.457420  0.500307  0.211056
3  0.457420  0.500307  0.211056
4  1.822813  0.537422  0.005842
5 -0.195423  1.578560  1.047900
6  0.522322  0.176574  1.763822
7  0.124225  0.655759  4.003954
8  0.124225  0.655759  4.003954
9  0.337818  1.170382  4.146218
</pre></div></div>
</div>
<p>Apart from the <code class="docutils literal notranslate"><span class="pre">sample</span></code> method all the four algorithms (HMC, HMCda, NUTS, NUTSda) provides another method to sample from model named <code class="docutils literal notranslate"><span class="pre">generate_sample</span></code> method. <code class="docutils literal notranslate"><span class="pre">generate_sample</span></code> method returns a generator type object whose each iteration yields a sample. The sample returned is a simple numpy.array object. The arguments for <code class="docutils literal notranslate"><span class="pre">generate_sample</span></code> method and <code class="docutils literal notranslate"><span class="pre">sample</span></code> method for all algorithms are same</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">generate_samples</span> <span class="o">=</span> <span class="n">NUTSda_sampler</span><span class="o">.</span><span class="n">generate_sample</span><span class="p">(</span><span class="n">initial_pos</span><span class="o">=</span><span class="p">[</span><span class="mf">0.4574</span><span class="p">,</span> <span class="mf">0.503</span><span class="p">,</span> <span class="mf">0.211</span><span class="p">],</span> <span class="n">num_adapt</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">sample</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">generate_samples</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[  1.23158312e+00   2.08966925e+00   5.47064070e+00]
 [  1.23158312e+00   2.08966925e+00   5.47064070e+00]
 [  1.23158312e+00   2.08966925e+00   5.47064070e+00]
 [  2.42754370e-04  -9.07581018e-01   2.22786641e+00]
 [  3.80037176e+00   4.20666799e+00   2.93898094e+00]
 [  1.84557224e+00   3.03691158e+00   5.05047756e+00]
 [  1.84557224e+00   3.03691158e+00   5.05047756e+00]
 [  1.90819711e+00   3.83294495e+00   4.98059422e+00]
 [  9.22139874e-01   4.11755511e+00   4.50041160e+00]
 [  9.22139874e-01   4.11755511e+00   4.50041160e+00]]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/utgup/anaconda3/lib/python3.5/site-packages/pgmpy-0.1.6-py3.5.egg/pgmpy/sampling/NUTS.py:412: RuntimeWarning: invalid value encountered in true_divide
  if np.random.rand() &lt; candidate_set_size2 / (candidate_set_size2 + candidate_set_size):
</pre></div></div>
</div>
</section>
</section>
<section id="Support-for-coustom-Models">
<h2><span class="section-number">8.3. </span>Support for coustom Models<a class="headerlink" href="#Support-for-coustom-Models" title="Permalink to this headline">¶</a></h2>
<p>One can also use HMC, HMCda, NUTS and NUTSda to sample from a user defined model, all one has to do is create class for finding log of probability density function and gradient log of probability density function using base class provided by pgmpy, and give this class as a parameter to <code class="docutils literal notranslate"><span class="pre">grad_log_pdf</span></code> argument in all of these algorithms (HMC[da], NUTS[da]).</p>
<p>In this example we will define our own logisitcs distribution and use NUTSda to sample from it.</p>
<p>The probability density of logistic distribution is given by:</p>
<div class="math">
<p><img src="../_images/math/a7d68cc0ab2355f0eb34dd83f44bd35518a3eddd.png" alt="P(x; \mu, s) = \frac{e^{-\frac{x- \mu}{s}}}{s(1 + e^{-\frac{x - \mu}{s}})^2}"/></p>
</div><p>Thus the log of this probability density function (potential energy function) can be written as:</p>
<div class="math">
<p><img src="../_images/math/32ea0d0d0225ec155c481ab959a5a1230fd54e1e.png" alt="log(P(x; \mu, s)) = -\frac{x - \mu}{s} - log(s) - 2 log(1 + e^{-\frac{x - \mu}{s}})"/></p>
</div><p>And the gradient of potential energy :</p>
<div class="math">
<p><img src="../_images/math/fab34cee57229a69348cefd214e80c6dc815e777.png" alt="\frac{\partial log(P(x; \mu, s))}{\partial x} = - \frac{1}{s} + \frac{2e^{-\frac{x - \mu}{s}}}{s(1 + e^{-\frac{x - \mu}{s}})}"/></p>
</div><div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Importing th base class structure for log and gradient log of probability density function</span>
<span class="kn">from</span> <span class="nn">pgmpy.sampling</span> <span class="kn">import</span> <span class="n">BaseGradLogPDF</span>

<span class="c1"># Base class for user defined continuous factor</span>
<span class="kn">from</span> <span class="nn">pgmpy.factors.distributions</span> <span class="kn">import</span> <span class="n">CustomDistribution</span>


<span class="c1"># Defining pdf of a Logistic distribution with mu = 5, s = 2</span>
<span class="k">def</span> <span class="nf">logistic_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">power</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mf">5.0</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">power</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">power</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Calculating log of logistic pdf</span>
<span class="k">def</span> <span class="nf">log_logistic</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">power</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mf">5.0</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span>
    <span class="k">return</span> <span class="n">power</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">power</span><span class="p">))</span>

<span class="c1"># Calculating gradient log of logistic pdf</span>
<span class="k">def</span> <span class="nf">grad_log_logistic</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">power</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mf">5.0</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span>
    <span class="k">return</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">-</span> <span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">power</span><span class="p">)))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">power</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>

<span class="c1"># Creating a logistic model</span>
<span class="n">logistic_model</span> <span class="o">=</span> <span class="n">CustomDistribution</span><span class="p">([</span><span class="s1">&#39;x&#39;</span><span class="p">],</span> <span class="n">logistic_pdf</span><span class="p">)</span>

<span class="c1"># Creating a class using base class for gradient log and log probability density function</span>
<span class="k">class</span> <span class="nc">GradLogLogistic</span><span class="p">(</span><span class="n">BaseGradLogPDF</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable_assignments</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="n">BaseGradLogPDF</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable_assignments</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grad_log</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_pdf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_gradient_log_pdf</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_get_gradient_log_pdf</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">grad_log_logistic</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">variable_assignments</span><span class="p">),</span>
                <span class="n">log_logistic</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">variable_assignments</span><span class="p">))</span>

<span class="c1"># Generating samples using NUTS</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">NUTSda</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">logistic_model</span><span class="p">,</span> <span class="n">grad_log_pdf</span><span class="o">=</span><span class="n">GradLogLogistic</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">initial_pos</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]),</span> <span class="n">num_adapt</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
                         <span class="n">num_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">30</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">logistic_pdf</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hold</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;real logistic pdf&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">normed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;step&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Samples NUTSda&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hold</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/utgup/anaconda3/lib/python3.5/site-packages/pgmpy-0.1.6-py3.5.egg/pgmpy/sampling/NUTS.py:412: RuntimeWarning: invalid value encountered in true_divide
  if np.random.rand() &lt; candidate_set_size2 / (candidate_set_size2 + candidate_set_size):
/home/utgup/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:45: MatplotlibDeprecationWarning: pyplot.hold is deprecated.
    Future behavior will be consistent with the long-time default:
    plot commands add elements without first clearing the
    Axes and/or Figure.
/home/utgup/anaconda3/lib/python3.5/site-packages/matplotlib/__init__.py:917: UserWarning: axes.hold is deprecated. Please remove it from your matplotlibrc and/or style files.
  warnings.warn(self.msg_depr_set % key)
/home/utgup/anaconda3/lib/python3.5/site-packages/matplotlib/rcsetup.py:152: UserWarning: axes.hold is deprecated, will be removed in 3.0
  warnings.warn(&#34;axes.hold is deprecated, will be removed in 3.0&#34;)
/home/utgup/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:49: MatplotlibDeprecationWarning: pyplot.hold is deprecated.
    Future behavior will be consistent with the long-time default:
    plot commands add elements without first clearing the
    Axes and/or Figure.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/detailed_notebooks_8._Sampling_Algorithms_17_1.png" src="../_images/detailed_notebooks_8._Sampling_Algorithms_17_1.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
</section>
</section>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="9.%20Reading%20and%20Writing%20from%20pgmpy%20file%20formats.html" class="btn btn-neutral float-right" title="9. Reading and Writing from pgmpy file formats" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="7.%20Parameterizing%20with%20Continuous%20Variables.html" class="btn btn-neutral float-left" title="7. Parameterizing with Continuous Variables" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Ankur Ankan.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-177825880-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>