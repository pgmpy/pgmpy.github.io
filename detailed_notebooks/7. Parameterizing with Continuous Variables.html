<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>7. Parameterizing with Continuous Variables &mdash; pgmpy 0.1.19 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="8. Sampling In Continuous Graphical Models" href="8.%20Sampling%20Algorithms.html" />
    <link rel="prev" title="6. Approximate Inference in Graphical Models" href="6.%20Approximate%20Inference%20in%20Graphical%20Models.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> pgmpy
          </a>
              <div class="version">
                dev branch
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../started/install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../started/contributing.html">Contributing to pgmpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../started/license.html">License</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Base Structures</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../base/base.html">Directed Acyclic Graph (DAG)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../base/base.html#partial-directed-acyclic-graph-pdag">Partial Directed Acyclic Graph (PDAG)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../models/bayesiannetwork.html">Bayesian Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/dbn.html">Dynamic Bayesian Network (DBN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/sem.html">Structural Equation Models (SEM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/naive.html">Naive Bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/noisyor.html">NoisyOr Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/markovnetwork.html">Markov Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/junctiontree.html">Junction Tree</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/clustergraph.html">Cluster Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/factorgraph.html">Factor Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/markovchain.html">Markov Chain</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Parameterization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../factors/discrete.html">Discrete</a></li>
<li class="toctree-l1"><a class="reference internal" href="../factors/discretize.html">Discretizing Methods</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exact Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/ve.html">Variable Elimination</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/ve.html#module-pgmpy.inference.EliminationOrder">Elimination Ordering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/bp.html">Belief Propagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/causal.html">Causal Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/mplp.html">MPLP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/dbn_infer.html">Dynamic Bayesian Network Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/model_testing.html">Model Testing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Approximate Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../approx_infer/approx_infer.html">Approximate Inference Using Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../approx_infer/bn_sampling.html">Bayesian Model Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../approx_infer/gibbs.html">Gibbs Sampling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Parameter Estimation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../param_estimator/mle.html">Maximum Likelihood Estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../param_estimator/bayesian_est.html">Bayesian Estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../param_estimator/em.html">Expectation Maximization (EM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../param_estimator/sem_estimator.html">Structural Equation Model Estimators</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Structure Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/pc.html">PC (Constraint-Based Estimator)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/pc.html#module-pgmpy.estimators.CITests">Conditional Independence Tests for PC algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/hill.html">Hill Climb Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/hill.html#structure-score">Structure Score</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/tree.html">Tree Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/mmhc.html">Mmhc Estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/exhaustive.html">Exhaustive Search</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Testing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../metrics/metrics.html">Metrics for testing models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Input/Output</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/bif.html">BIF (Bayesian Interchange Format)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/uai.html">UAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/xmlbif.html">XMLBIF</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/pomdpx.html">PomdpX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/xmlbelief.html">XMLBeliefNetwork</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Example Notebooks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../examples/Earthquake.html">1. Example Using the Earthquake network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Monty%20Hall%20Problem.html">2. Monty Hall Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Creating%20a%20Discrete%20Bayesian%20Network.html">3. Creating discrete Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Inference%20in%20Discrete%20Bayesian%20Networks.html">4. Inference in Discrete Bayesian Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Causal%20Games.html">5. Causal Games</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Causal%20Inference.html">6. Causal Inference Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Learning%20Parameters%20in%20Discrete%20Bayesian%20Networks.html">7. Parameter Learning in Discrete Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Structure%20Learning%20in%20Bayesian%20Networks.html">8. Structure Learning in Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Structure%20Learning%20with%20Chow-Liu.html">9. Learning Tree Structure from Data using the Chow-Liu Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Structure%20Learning%20with%20TAN.html">10. Learning Tree-augmented Naive Bayes (TAN) Structure from Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Simulating%20Data.html">11. Normal Bayesian Network (no time variation)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Extending%20pgmpy.html">12. Extending pgmpy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorial Notebooks</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="1.%20Introduction%20to%20Probabilistic%20Graphical%20Models.html">1. Introduction to Probabilitic Graphical Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="2.%20Bayesian%20Networks.html">2. Bayesian Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.%20Causal%20Bayesian%20Networks.html">3. Causal Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.%20Markov%20Models.html">4. Markov Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="5.%20Exact%20Inference%20in%20Graphical%20Models.html">5. Exact Inference in Graphical Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="6.%20Approximate%20Inference%20in%20Graphical%20Models.html">6. Approximate Inference in Graphical Models</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">7. Parameterizing with Continuous Variables</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Continuous-Factors">7.1. Continuous Factors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Base-Class-for-Continuous-Factors">7.1.1. Base Class for Continuous Factors</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Joint-Gaussian-Distributions">7.1.2. Joint Gaussian Distributions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Canonical-Factors">7.1.3. Canonical Factors</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Linear-Gaussian-CPD">7.1.4. Linear Gaussian CPD</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="8.%20Sampling%20Algorithms.html">8. Sampling In Continuous Graphical Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="9.%20Reading%20and%20Writing%20from%20pgmpy%20file%20formats.html">9. Reading and Writing from pgmpy file formats</a></li>
<li class="toctree-l1"><a class="reference internal" href="10.%20Learning%20Bayesian%20Networks%20from%20Data.html">10. Learning Bayesian Networks from Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="11.%20A%20Bayesian%20Network%20to%20model%20the%20influence%20of%20energy%20consumption%20on%20greenhouse%20gases%20in%20Italy.html">11. A Bayesian Network to model the influence of energy consumption on greenhouse gases in Italy</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">pgmpy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active"><span class="section-number">7. </span>Parameterizing with Continuous Variables</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/detailed_notebooks/7. Parameterizing with Continuous Variables.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="Parameterizing-with-Continuous-Variables">
<h1><span class="section-number">7. </span>Parameterizing with Continuous Variables<a class="headerlink" href="#Parameterizing-with-Continuous-Variables" title="Permalink to this heading"></a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
</pre></div>
</div>
</div>
<section id="Continuous-Factors">
<h2><span class="section-number">7.1. </span>Continuous Factors<a class="headerlink" href="#Continuous-Factors" title="Permalink to this heading"></a></h2>
<ol class="arabic simple">
<li><p>Base Class for Continuous Factors</p></li>
<li><p>Joint Gaussian Distributions</p></li>
<li><p>Canonical Factors</p></li>
<li><p>Linear Gaussian CPD</p></li>
</ol>
<p>In many situations, some variables are best modeled as taking values in some continuous space. Examples include variables such as position, velocity, temperature, and pressure. Clearly, we cannot use a table representation in this case.</p>
<p>Nothing in the formulation of a Bayesian network requires that we restrict attention to discrete variables. The only requirement is that the CPD, <img class="math" src="_images/math/c8059a04c06842bae0ba643f9cd3566578e31a61.png" alt="P(X | Y_1, Y_2, \cdots Y_n)"/> represent, for every assignment of values <img class="math" src="_images/math/822264aae679394f594190c741872c129ddb7820.png" alt="y_1 \in Val(Y_1), y_2 \in Val(Y_2), \cdots, y_n \in val(Y_n)"/>, a distribution over <img class="math" src="_images/math/ed38fa24f1c94891bd312012aab3f6673be3eb83.png" alt="X"/>. In this case, <img class="math" src="_images/math/ed38fa24f1c94891bd312012aab3f6673be3eb83.png" alt="X"/> might be continuous, in which case the CPD would need to represent distributions over a continuum of values; we might also have <img class="math" src="_images/math/ed38fa24f1c94891bd312012aab3f6673be3eb83.png" alt="X"/>’s parents
continuous, so that the CPD would also need to represent a continuum of different probability distributions. There exists implicit representations for CPDs of this type, allowing us to apply all the network machinery for the continuous case as well.</p>
<section id="Base-Class-for-Continuous-Factors">
<h3><span class="section-number">7.1.1. </span>Base Class for Continuous Factors<a class="headerlink" href="#Base-Class-for-Continuous-Factors" title="Permalink to this heading"></a></h3>
<p>This class will behave as a base class for the continuous factor representations. All the present and future factor classes will be derived from this base class. We need to specify the variable names and a pdf function to initialize this class.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">beta</span>

<span class="c1"># Two variable drichlet ditribution with alpha = (1,2)</span>
<span class="k">def</span> <span class="nf">drichlet_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
     <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="n">beta</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">pgmpy.factors.continuous</span> <span class="kn">import</span> <span class="n">ContinuousFactor</span>
<span class="n">drichlet_factor</span> <span class="o">=</span> <span class="n">ContinuousFactor</span><span class="p">([</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">],</span> <span class="n">drichlet_pdf</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">drichlet_factor</span><span class="o">.</span><span class="n">scope</span><span class="p">(),</span> <span class="n">drichlet_factor</span><span class="o">.</span><span class="n">assignment</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
([&#39;x&#39;, &#39;y&#39;], 226800.0)
</pre></div></div>
</div>
<p>This class supports methods like <strong>marginalize, reduce, product and divide</strong> just like what we have with discrete classes. One caveat is that when there are a number of variables involved, these methods prove to be inefficient and hence we resort to certain Gaussian or some other approximations which are discussed later.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">custom_pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">z</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="n">beta</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">custom_factor</span> <span class="o">=</span> <span class="n">ContinuousFactor</span><span class="p">([</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;z&#39;</span><span class="p">],</span> <span class="n">custom_pdf</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">custom_factor</span><span class="o">.</span><span class="n">scope</span><span class="p">(),</span> <span class="n">custom_factor</span><span class="o">.</span><span class="n">assignment</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
([&#39;x&#39;, &#39;y&#39;, &#39;z&#39;], 24.0)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">custom_factor</span><span class="o">.</span><span class="n">reduce</span><span class="p">([(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)])</span>
<span class="n">custom_factor</span><span class="o">.</span><span class="n">scope</span><span class="p">(),</span> <span class="n">custom_factor</span><span class="o">.</span><span class="n">assignment</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
([&#39;x&#39;, &#39;z&#39;], 24.0)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multivariate_normal</span>

<span class="n">std_normal_pdf</span> <span class="o">=</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">x</span><span class="p">:</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">std_normal</span> <span class="o">=</span> <span class="n">ContinuousFactor</span><span class="p">([</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">],</span> <span class="n">std_normal_pdf</span><span class="p">)</span>
<span class="n">std_normal</span><span class="o">.</span><span class="n">scope</span><span class="p">(),</span> <span class="n">std_normal</span><span class="o">.</span><span class="n">assignment</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
([&#39;x1&#39;, &#39;x2&#39;], 0.058549831524319168)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">std_normal</span><span class="o">.</span><span class="n">marginalize</span><span class="p">([</span><span class="s1">&#39;x2&#39;</span><span class="p">])</span>
<span class="n">std_normal</span><span class="o">.</span><span class="n">scope</span><span class="p">(),</span> <span class="n">std_normal</span><span class="o">.</span><span class="n">assignment</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
([&#39;x1&#39;], 0.24197072451914328)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sn_pdf1</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">sn_pdf2</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">:</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">sn1</span> <span class="o">=</span> <span class="n">ContinuousFactor</span><span class="p">([</span><span class="s1">&#39;x2&#39;</span><span class="p">],</span> <span class="n">sn_pdf1</span><span class="p">)</span>
<span class="n">sn2</span> <span class="o">=</span> <span class="n">ContinuousFactor</span><span class="p">([</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">],</span> <span class="n">sn_pdf2</span><span class="p">)</span>
<span class="n">sn3</span> <span class="o">=</span> <span class="n">sn1</span> <span class="o">*</span> <span class="n">sn2</span>
<span class="n">sn4</span> <span class="o">=</span> <span class="n">sn2</span> <span class="o">/</span> <span class="n">sn1</span>
<span class="n">sn3</span><span class="o">.</span><span class="n">assignment</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">sn4</span><span class="o">.</span><span class="n">assignment</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(0.063493635934240983, 0.3989422804014327)
</pre></div></div>
</div>
<p>The ContinuousFactor class also has a method <strong>discretize</strong> that takes a pgmpy Discretizer class as input. It will output a list of discrete probability masses or a Factor or TabularCPD object depending upon the discretization method used. Although, we do not have inbuilt discretization algorithms for multivariate distributions for now, the users can always define their own Discretizer class by subclassing the pgmpy.BaseDiscretizer class.</p>
</section>
<section id="Joint-Gaussian-Distributions">
<h3><span class="section-number">7.1.2. </span>Joint Gaussian Distributions<a class="headerlink" href="#Joint-Gaussian-Distributions" title="Permalink to this heading"></a></h3>
<p>In its most common representation, a multivariate Gaussian distribution over <img class="math" src="_images/math/a9a376ad3aebf4b54e5c218193b3d23c74272060.png" alt="X_1 \cdots X_n"/> is characterized by an n-dimensional mean vector <img class="math" src="_images/math/4a3598141469c2555591e66606a1b86d4ec6dca9.png" alt="\mu"/>, and a symmetric <img class="math" src="_images/math/a093134f3fa86b4bc38a1634715b6a50c537ad3a.png" alt="n \times n"/> covariance matrix <img class="math" src="_images/math/6edc5c119344e25a06e6ac4cb56f2d5e2f09a2f1.png" alt="\Sigma"/>. The density function is most defined as -</p>
<div class="math">
<p><img src="_images/math/982dfc48a3c00e9aeea07cd521c5a5fccad81f0a.png" alt="p(x) = \dfrac{1}{(2\pi)^{n/2}| \Sigma |^{1/2}} \exp[-0.5*(x- \mu )^T \Sigma^{-1}(x- \mu)]"/></p>
</div><p>The class pgmpy.JointGaussianDistribution provides its representation. This is derived from the class pgmpy.ContinuousFactor. We need to specify the variable names, a mean vector and a covariance matrix for its inialization. It will automatically comute the pdf function given these parameters.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pgmpy.factors.distributions</span> <span class="kn">import</span> <span class="n">GaussianDistribution</span> <span class="k">as</span> <span class="n">JGD</span>
<span class="n">dis</span> <span class="o">=</span> <span class="n">JGD</span><span class="p">([</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">,</span> <span class="s1">&#39;x3&#39;</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">]]),</span>
          <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]))</span>
<span class="n">dis</span><span class="o">.</span><span class="n">variables</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;x1&#39;, &#39;x2&#39;, &#39;x3&#39;]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dis</span><span class="o">.</span><span class="n">mean</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[ 1.],
       [-3.],
       [ 4.]])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dis</span><span class="o">.</span><span class="n">covariance</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[ 4.,  2., -2.],
       [ 2.,  5., -5.],
       [-2., -5.,  8.]])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dis</span><span class="o">.</span><span class="n">pdf</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.0014805631279234139
</pre></div></div>
</div>
<p>This class overrides the basic operation methods <strong>(marginalize, reduce, normalize, product and divide)</strong> as these operations here are more efficient than the ones in its parent class. Most of these operation involve a matrix inversion which is <img class="math" src="_images/math/cbe7f1bf4cfffe31e0c2c8dd79afba3b5a481789.png" alt="\mathcal{O}(n^3)"/> with repect to the number of variables.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dis1</span> <span class="o">=</span> <span class="n">JGD</span><span class="p">([</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">,</span> <span class="s1">&#39;x3&#39;</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">]]),</span>
           <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]))</span>
<span class="n">dis2</span> <span class="o">=</span> <span class="n">JGD</span><span class="p">([</span><span class="s1">&#39;x3&#39;</span><span class="p">,</span> <span class="s1">&#39;x4&#39;</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">dis3</span> <span class="o">=</span> <span class="n">dis1</span> <span class="o">*</span> <span class="n">dis2</span>
<span class="n">dis3</span><span class="o">.</span><span class="n">variables</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;x1&#39;, &#39;x2&#39;, &#39;x3&#39;, &#39;x4&#39;]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dis3</span><span class="o">.</span><span class="n">mean</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[ 1.6],
       [-1.5],
       [ 1.6],
       [ 3.5]])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dis3</span><span class="o">.</span><span class="n">covariance</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[ 3.6,  1. , -0.4, -0.6],
       [ 1. ,  2.5, -1. , -1.5],
       [-0.4, -1. ,  1.6,  2.4],
       [-1. , -2.5,  4. ,  4.5]])
</pre></div></div>
</div>
<p>The others methods can also be used in a similar fashion.</p>
</section>
<section id="Canonical-Factors">
<h3><span class="section-number">7.1.3. </span>Canonical Factors<a class="headerlink" href="#Canonical-Factors" title="Permalink to this heading"></a></h3>
<p>While the Joint Gaussian representation is useful for certain sampling algorithms, a closer look reveals that it can also not be used directly in the sum-product algorithms. Why? Because operations like product and reduce, as mentioned above involve matrix inversions at each step.</p>
<p>So, in order to compactly describe the intermediate factors in a Gaussian network without the costly matrix inversions at each step, a simple parametric representation is used known as the Canonical Factor. This representation is closed under the basic operations used in inference: factor product, factor division, factor reduction, and marginalization. Thus, we can define a set of simple data structures that allow the inference process to be performed. Moreover, the integration operation
required by marginalization is always well defined, and it is guaranteed to produce a finite integral under certain conditions; when it is well defined, it has a simple analytical solution.</p>
<p>A canonical form <img class="math" src="_images/math/71bea00e4e74d492e436bb0f0943cc1a7778ea28.png" alt="C (X; K,h, g)"/> is defined as:</p>
<div class="math">
<p><img src="_images/math/a9d43f75f977e1e2eddd2f931bef9f9b7750c77d.png" alt="C(X; K,h,g) = \exp(-0.5X^TKX + h^TX + g)"/></p>
</div><p>We can represent every Gaussian as a canonical form. Rewriting the joint Gaussian pdf we obtain,</p>
<p><img class="math" src="_images/math/f2640819b402ecffe2d5c1dc7b0818313e608317.png" alt="N (\mu; \Sigma) = C (K, h, g)"/> where:</p>
<div class="math">
<p><img src="_images/math/8292b3aaf9bd318da0f15167ff050a391a409975.png" alt="K = \Sigma^{-1}"/></p>
</div><div class="math">
<p><img src="_images/math/415cc2041718915dedf92177c2e93af6668625a6.png" alt="h = \Sigma^{-1} \mu"/></p>
</div><div class="math">
<p><img src="_images/math/afa9bfb1e4857c61332363c0fc050c47e0fba849.png" alt="g = -0.5 \mu^T \Sigma^{-1} \mu - \log((2 \pi)^{n/2}| \Sigma |^{1/2}"/></p>
</div><p>Similar to the JointGaussainDistribution class, the CanonicalFactor class is also derived from the ContinuousFactor class but with its own implementations of the methods required for the sum-product algorithms that are much more efficient than its parent class methods. Let us have a look at the API of a few methods in this class.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pgmpy.factors.continuous</span> <span class="kn">import</span> <span class="n">CanonicalDistribution</span>

<span class="n">phi1</span> <span class="o">=</span> <span class="n">CanonicalDistribution</span><span class="p">([</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">,</span> <span class="s1">&#39;x3&#39;</span><span class="p">],</span>
                       <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span>
                       <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]),</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
<span class="n">phi2</span> <span class="o">=</span> <span class="n">CanonicalDistribution</span><span class="p">([</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span>
                       <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]),</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">phi3</span> <span class="o">=</span> <span class="n">phi1</span> <span class="o">*</span> <span class="n">phi2</span>
<span class="n">phi3</span><span class="o">.</span><span class="n">variables</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;x1&#39;, &#39;x2&#39;, &#39;x3&#39;]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">phi3</span><span class="o">.</span><span class="n">h</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[ 6.],
       [ 3.],
       [-1.]])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">phi3</span><span class="o">.</span><span class="n">K</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[ 4., -3.,  0.],
       [-3.,  8., -2.],
       [ 0., -2.,  4.]])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">phi3</span><span class="o">.</span><span class="n">g</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-1
</pre></div></div>
</div>
<p>This class also has a method, to_joint_gaussian to convert the canoncial representation back into the joint gaussian distribution.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">phi</span> <span class="o">=</span> <span class="n">CanonicalDistribution</span><span class="p">([</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span>
                      <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]),</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">jgd</span> <span class="o">=</span> <span class="n">phi</span><span class="o">.</span><span class="n">to_joint_gaussian</span><span class="p">()</span>
<span class="n">jgd</span><span class="o">.</span><span class="n">variables</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;x1&#39;, &#39;x2&#39;]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">jgd</span><span class="o">.</span><span class="n">covariance</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[ 0.5  ,  0.25 ],
       [ 0.25 ,  0.375]])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">jgd</span><span class="o">.</span><span class="n">mean</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[ 2.25 ],
       [ 0.875]])
</pre></div></div>
</div>
</section>
<section id="Linear-Gaussian-CPD">
<h3><span class="section-number">7.1.4. </span>Linear Gaussian CPD<a class="headerlink" href="#Linear-Gaussian-CPD" title="Permalink to this heading"></a></h3>
<p>A linear gaussian conditional probability distribution is defined on a continuous variable. All the parents of this variable are also continuous. The mean of this variable, is linearly dependent on the mean of its parent variables and the variance is independent.</p>
<p>For example,</p>
<div class="math">
<p><img src="_images/math/f6b03c49f3f4ab02302c26aa369763283d1d7d3c.png" alt="P(Y ; x_1, x_2, x_3) = N(\beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_0 ; \sigma^2)"/></p>
</div><p>Let <img class="math" src="_images/math/7daf0d4815e763eb90f0d5f1dc406f668c1e21db.png" alt="Y"/> be a linear Gaussian of its parents $X_1, <span class="math">\cdots</span>, X_k:</p>
<div class="math">
<p><img src="_images/math/b5e52dfeb71071abd45ce1712584efd3bbd1f132.png" alt="p(Y | x) = N(\beta_0 + \beta^T x ; \sigma^2)"/></p>
</div><p>The distribution of <img class="math" src="_images/math/7daf0d4815e763eb90f0d5f1dc406f668c1e21db.png" alt="Y"/> is a normal distribution <img class="math" src="_images/math/fc3a9065fa794bbd24266b4d96c847f7dbcd9c2d.png" alt="p(Y)"/> where:</p>
<div class="math">
<p><img src="_images/math/63f7b2eea310ba86e51157b12ce36efd69ac427d.png" alt="\mu_Y = \beta_0 + \beta^T \mu"/></p>
</div><div class="math">
<p><img src="_images/math/e8c4bf8343035472d9519f4ba21a2b9a3f093d51.png" alt="\sigma^2_Y = \sigma^2 + \beta^{T \Sigma \beta}"/></p>
</div><p>The joint distribution over <img class="math" src="_images/math/3140b7c2ae25fa983137bfeffc9a08d4b3a0159f.png" alt="\{X, Y\}"/> is a normal distribution where:</p>
<div class="math">
<p><img src="_images/math/46084dc187b8bdbde7f6b78280dc2350e173aad8.png" alt="Cov[X_i; Y] = {\sum_{j=1}^{k} \beta_j \Sigma_{i,j}}"/></p>
</div><p>Assume that <img class="math" src="_images/math/5027fe71f6d991ec754275225c59d10a25e89fbc.png" alt="X_1, \cdots, X_k"/> are jointly Gaussian with distribution <img class="math" src="_images/math/5ec96a186334ab9aec11aed077922a905aeaa0c4.png" alt="\mathcal{N}(\mu; \Sigma)"/>. Then: For its representation pgmpy has a class named LinearGaussianCPD in the module pgmpy.factors.continuous. To instantiate an object of this class, one needs to provide a variable name, the value of the <img class="math" src="_images/math/5ea7b1c66899158e4f0ae780d71d769270441d15.png" alt="\beta_0"/> term, the variance, a list of the parent variable names and a list of the coefficient values of the linear equation (beta_vector), where the list of parent variable
names and beta_vector list is optional and defaults to None.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># For P(Y| X1, X2, X3) = N(-2x1 + 3x2 + 7x3 + 0.2; 9.6)</span>
<span class="kn">from</span> <span class="nn">pgmpy.factors.continuous</span> <span class="kn">import</span> <span class="n">LinearGaussianCPD</span>
<span class="n">cpd</span> <span class="o">=</span> <span class="n">LinearGaussianCPD</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span>  <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="mf">9.6</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X1&#39;</span><span class="p">,</span> <span class="s1">&#39;X2&#39;</span><span class="p">,</span> <span class="s1">&#39;X3&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cpd</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
P(Y | X1, X2, X3) = N(-2*X1 + 3*X2 + 7*X3 + 0.2; 9.6)
</pre></div></div>
</div>
<p>A Gaussian Bayesian is defined as a network all of whose variables are continuous, and where all of the CPDs are linear Gaussians. These networks are of particular interest as these are an alternate form of representaion of the Joint Gaussian distribution.</p>
<p>These networks are implemented as the LinearGaussianBayesianNetwork class in the module, pgmpy.models.continuous. This class is a subclass of the BayesianModel class in pgmpy.models and will inherit most of the methods from it. It will have a special method known as to_joint_gaussian that will return an equivalent JointGuassianDistribution object for the model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pgmpy.models</span> <span class="kn">import</span> <span class="n">LinearGaussianBayesianNetwork</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LinearGaussianBayesianNetwork</span><span class="p">([(</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;x2&#39;</span><span class="p">,</span> <span class="s1">&#39;x3&#39;</span><span class="p">)])</span>
<span class="n">cpd1</span> <span class="o">=</span> <span class="n">LinearGaussianCPD</span><span class="p">(</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">cpd2</span> <span class="o">=</span> <span class="n">LinearGaussianCPD</span><span class="p">(</span><span class="s1">&#39;x2&#39;</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="mi">4</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;x1&#39;</span><span class="p">])</span>
<span class="n">cpd3</span> <span class="o">=</span> <span class="n">LinearGaussianCPD</span><span class="p">(</span><span class="s1">&#39;x3&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;x2&#39;</span><span class="p">])</span>
<span class="c1"># This is a hack due to a bug in pgmpy (LinearGaussianCPD</span>
<span class="c1"># doesn&#39;t have `variables` attribute but `add_cpds` function</span>
<span class="c1"># wants to check that...)</span>
<span class="n">cpd1</span><span class="o">.</span><span class="n">variables</span> <span class="o">=</span> <span class="p">[</span><span class="o">*</span><span class="n">cpd1</span><span class="o">.</span><span class="n">evidence</span><span class="p">,</span> <span class="n">cpd1</span><span class="o">.</span><span class="n">variable</span><span class="p">]</span>
<span class="n">cpd2</span><span class="o">.</span><span class="n">variables</span> <span class="o">=</span> <span class="p">[</span><span class="o">*</span><span class="n">cpd2</span><span class="o">.</span><span class="n">evidence</span><span class="p">,</span> <span class="n">cpd2</span><span class="o">.</span><span class="n">variable</span><span class="p">]</span>
<span class="n">cpd3</span><span class="o">.</span><span class="n">variables</span> <span class="o">=</span> <span class="p">[</span><span class="o">*</span><span class="n">cpd3</span><span class="o">.</span><span class="n">evidence</span><span class="p">,</span> <span class="n">cpd3</span><span class="o">.</span><span class="n">variable</span><span class="p">]</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_cpds</span><span class="p">(</span><span class="n">cpd1</span><span class="p">,</span> <span class="n">cpd2</span><span class="p">,</span> <span class="n">cpd3</span><span class="p">)</span>
<span class="n">jgd</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to_joint_gaussian</span><span class="p">()</span>
<span class="n">jgd</span><span class="o">.</span><span class="n">variables</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;x1&#39;, &#39;x2&#39;, &#39;x3&#39;]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">jgd</span><span class="o">.</span><span class="n">mean</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[ 1. ],
       [-4.5],
       [ 8.5]])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">jgd</span><span class="o">.</span><span class="n">covariance</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([[ 4.,  2., -2.],
       [ 2.,  5., -5.],
       [-2., -5.,  8.]])
</pre></div></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="6.%20Approximate%20Inference%20in%20Graphical%20Models.html" class="btn btn-neutral float-left" title="6. Approximate Inference in Graphical Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="8.%20Sampling%20Algorithms.html" class="btn btn-neutral float-right" title="8. Sampling In Continuous Graphical Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Ankur Ankan.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-177825880-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-177825880-1', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>