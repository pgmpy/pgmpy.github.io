<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Bayesian Network &#8212; pgmpy 0.1.23 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=7b53859b" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <script src="../_static/documentation_options.js?v=20522496"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Causal Bayesian Networks" href="3.%20Causal%20Bayesian%20Networks.html" />
    <link rel="prev" title="Introduction to Probabilitic Graphical Models" href="1.%20Introduction%20to%20Probabilistic%20Graphical%20Models.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="Bayesian-Network">
<h1>Bayesian Network<a class="headerlink" href="#Bayesian-Network" title="Link to this heading">¶</a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
</pre></div>
</div>
</div>
<section id="Bayesian-Models">
<h2>Bayesian Models<a class="headerlink" href="#Bayesian-Models" title="Link to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p>What are Bayesian Models</p></li>
<li><p>Independencies in Bayesian Networks</p></li>
<li><p>How is Bayesian Model encoding the Joint Distribution</p></li>
<li><p>How we do inference from Bayesian models</p></li>
<li><p>Types of methods for inference</p></li>
</ol>
<section id="1.-What-are-Bayesian-Models">
<h3>1. What are Bayesian Models<a class="headerlink" href="#1.-What-are-Bayesian-Models" title="Link to this heading">¶</a></h3>
<p>A Bayesian network, Bayes network, belief network, Bayes(ian) model or probabilistic directed acyclic graphical model is a probabilistic graphical model (a type of statistical model) that represents a set of random variables and their conditional dependencies via a directed acyclic graph (DAG). Bayesian networks are mostly used when we want to represent causal relationship between the random variables. Bayesian Networks are parameterized using Conditional Probability Distributions (CPD). Each
node in the network is parameterized using <img class="math" src="../_images/math/335b637cd8bdc6b7893ae296c08d30fd9b239d16.png" alt="P(node | Pa(node))"/> where <img class="math" src="../_images/math/cd8db92fc141682ba6fc068d541bed833a005fcb.png" alt="Pa(node)"/> represents the parents of node in the network.</p>
<p>We can take the example of the student model:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Image</span><span class="p">(</span><span class="s1">&#39;../images/2/student_full_param.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="../_images/detailed_notebooks_2._Bayesian_Networks_4_0.png" src="../_images/detailed_notebooks_2._Bayesian_Networks_4_0.png" />
</div>
</div>
<p>In pgmpy we define the network structure and the CPDs separately and then associate them with the structure. Here’s an example for defining the above model:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pgmpy.models</span> <span class="kn">import</span> <span class="n">BayesianModel</span>
<span class="kn">from</span> <span class="nn">pgmpy.factors.discrete</span> <span class="kn">import</span> <span class="n">TabularCPD</span>

<span class="c1"># Defining the model structure. We can define the network by just passing a list of edges.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BayesianModel</span><span class="p">([(</span><span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;I&#39;</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;G&#39;</span><span class="p">,</span> <span class="s1">&#39;L&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;I&#39;</span><span class="p">,</span> <span class="s1">&#39;S&#39;</span><span class="p">)])</span>

<span class="c1"># Defining individual CPDs.</span>
<span class="n">cpd_d</span> <span class="o">=</span> <span class="n">TabularCPD</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="n">variable_card</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">]])</span>
<span class="n">cpd_i</span> <span class="o">=</span> <span class="n">TabularCPD</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="s1">&#39;I&#39;</span><span class="p">,</span> <span class="n">variable_card</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.7</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">]])</span>

<span class="c1"># The representation of CPD in pgmpy is a bit different than the CPD shown in the above picture. In pgmpy the colums</span>
<span class="c1"># are the evidences and rows are the states of the variable. So the grade CPD is represented like this:</span>
<span class="c1">#</span>
<span class="c1">#    +---------+---------+---------+---------+---------+</span>
<span class="c1">#    | diff    | intel_0 | intel_0 | intel_1 | intel_1 |</span>
<span class="c1">#    +---------+---------+---------+---------+---------+</span>
<span class="c1">#    | intel   | diff_0  | diff_1  | diff_0  | diff_1  |</span>
<span class="c1">#    +---------+---------+---------+---------+---------+</span>
<span class="c1">#    | grade_0 | 0.3     | 0.05    | 0.9     | 0.5     |</span>
<span class="c1">#    +---------+---------+---------+---------+---------+</span>
<span class="c1">#    | grade_1 | 0.4     | 0.25    | 0.08    | 0.3     |</span>
<span class="c1">#    +---------+---------+---------+---------+---------+</span>
<span class="c1">#    | grade_2 | 0.3     | 0.7     | 0.02    | 0.2     |</span>
<span class="c1">#    +---------+---------+---------+---------+---------+</span>

<span class="n">cpd_g</span> <span class="o">=</span> <span class="n">TabularCPD</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="s1">&#39;G&#39;</span><span class="p">,</span> <span class="n">variable_card</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                   <span class="n">values</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span>  <span class="mf">0.5</span><span class="p">],</span>
                           <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
                           <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span>  <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]],</span>
                  <span class="n">evidence</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;I&#39;</span><span class="p">,</span> <span class="s1">&#39;D&#39;</span><span class="p">],</span>
                  <span class="n">evidence_card</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

<span class="n">cpd_l</span> <span class="o">=</span> <span class="n">TabularCPD</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="s1">&#39;L&#39;</span><span class="p">,</span> <span class="n">variable_card</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                   <span class="n">values</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">],</span>
                           <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">]],</span>
                   <span class="n">evidence</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;G&#39;</span><span class="p">],</span>
                   <span class="n">evidence_card</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>

<span class="n">cpd_s</span> <span class="o">=</span> <span class="n">TabularCPD</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="s1">&#39;S&#39;</span><span class="p">,</span> <span class="n">variable_card</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                   <span class="n">values</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
                           <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]],</span>
                   <span class="n">evidence</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;I&#39;</span><span class="p">],</span>
                   <span class="n">evidence_card</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="c1"># Associating the CPDs with the network</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_cpds</span><span class="p">(</span><span class="n">cpd_d</span><span class="p">,</span> <span class="n">cpd_i</span><span class="p">,</span> <span class="n">cpd_g</span><span class="p">,</span> <span class="n">cpd_l</span><span class="p">,</span> <span class="n">cpd_s</span><span class="p">)</span>

<span class="c1"># check_model checks for the network structure and CPDs and verifies that the CPDs are correctly</span>
<span class="c1"># defined and sum to 1.</span>
<span class="n">model</span><span class="o">.</span><span class="n">check_model</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
True
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># CPDs can also be defined using the state names of the variables. If the state names are not provided</span>
<span class="c1"># like in the previous example, pgmpy will automatically assign names as: 0, 1, 2, ....</span>

<span class="n">cpd_d_sn</span> <span class="o">=</span> <span class="n">TabularCPD</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="n">variable_card</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">]],</span> <span class="n">state_names</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;D&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Easy&#39;</span><span class="p">,</span> <span class="s1">&#39;Hard&#39;</span><span class="p">]})</span>
<span class="n">cpd_i_sn</span> <span class="o">=</span> <span class="n">TabularCPD</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="s1">&#39;I&#39;</span><span class="p">,</span> <span class="n">variable_card</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.7</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">]],</span> <span class="n">state_names</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;I&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Dumb&#39;</span><span class="p">,</span> <span class="s1">&#39;Intelligent&#39;</span><span class="p">]})</span>
<span class="n">cpd_g_sn</span> <span class="o">=</span> <span class="n">TabularCPD</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="s1">&#39;G&#39;</span><span class="p">,</span> <span class="n">variable_card</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                      <span class="n">values</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span>  <span class="mf">0.5</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span>  <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]],</span>
                      <span class="n">evidence</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;I&#39;</span><span class="p">,</span> <span class="s1">&#39;D&#39;</span><span class="p">],</span>
                      <span class="n">evidence_card</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
                      <span class="n">state_names</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;G&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">],</span>
                                   <span class="s1">&#39;I&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Dumb&#39;</span><span class="p">,</span> <span class="s1">&#39;Intelligent&#39;</span><span class="p">],</span>
                                   <span class="s1">&#39;D&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Easy&#39;</span><span class="p">,</span> <span class="s1">&#39;Hard&#39;</span><span class="p">]})</span>

<span class="n">cpd_l_sn</span> <span class="o">=</span> <span class="n">TabularCPD</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="s1">&#39;L&#39;</span><span class="p">,</span> <span class="n">variable_card</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                      <span class="n">values</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">]],</span>
                      <span class="n">evidence</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;G&#39;</span><span class="p">],</span>
                      <span class="n">evidence_card</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                      <span class="n">state_names</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;L&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Bad&#39;</span><span class="p">,</span> <span class="s1">&#39;Good&#39;</span><span class="p">],</span>
                                   <span class="s1">&#39;G&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">]})</span>

<span class="n">cpd_s_sn</span> <span class="o">=</span> <span class="n">TabularCPD</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="s1">&#39;S&#39;</span><span class="p">,</span> <span class="n">variable_card</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                      <span class="n">values</span><span class="o">=</span><span class="p">[[</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]],</span>
                      <span class="n">evidence</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;I&#39;</span><span class="p">],</span>
                      <span class="n">evidence_card</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                      <span class="n">state_names</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;S&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Bad&#39;</span><span class="p">,</span> <span class="s1">&#39;Good&#39;</span><span class="p">],</span>
                                   <span class="s1">&#39;I&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Dumb&#39;</span><span class="p">,</span> <span class="s1">&#39;Intelligent&#39;</span><span class="p">]})</span>

<span class="c1"># These defined CPDs can be added to the model. Since, the model already has CPDs associated to variables, it will</span>
<span class="c1"># show warning that pmgpy is now replacing those CPDs with the new ones.</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_cpds</span><span class="p">(</span><span class="n">cpd_d_sn</span><span class="p">,</span> <span class="n">cpd_i_sn</span><span class="p">,</span> <span class="n">cpd_g_sn</span><span class="p">,</span> <span class="n">cpd_l_sn</span><span class="p">,</span> <span class="n">cpd_s_sn</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">check_model</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
WARNING:root:Replacing existing CPD for D
WARNING:root:Replacing existing CPD for I
WARNING:root:Replacing existing CPD for G
WARNING:root:Replacing existing CPD for L
WARNING:root:Replacing existing CPD for S
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
True
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We can now call some methods on the BayesianModel object.</span>
<span class="n">model</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&lt;TabularCPD representing P(D:2) at 0x7f1585d3e278&gt;,
 &lt;TabularCPD representing P(I:2) at 0x7f1585d3e320&gt;,
 &lt;TabularCPD representing P(G:3 | I:2, D:2) at 0x7f1585d3e390&gt;,
 &lt;TabularCPD representing P(L:2 | G:3) at 0x7f1585d3e2b0&gt;,
 &lt;TabularCPD representing P(S:2 | I:2) at 0x7f1585d3e358&gt;]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[39]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Printing a CPD which doesn&#39;t have state names defined.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cpd_g</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
+------+------+------+------+------+
| I    | I(0) | I(0) | I(1) | I(1) |
+------+------+------+------+------+
| D    | D(0) | D(1) | D(0) | D(1) |
+------+------+------+------+------+
| G(0) | 0.3  | 0.05 | 0.9  | 0.5  |
+------+------+------+------+------+
| G(1) | 0.4  | 0.25 | 0.08 | 0.3  |
+------+------+------+------+------+
| G(2) | 0.3  | 0.7  | 0.02 | 0.2  |
+------+------+------+------+------+
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[40]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Printing a CPD with it&#39;s state names defined.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">(</span><span class="s1">&#39;G&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
+------+---------+---------+----------------+----------------+
| I    | I(Dumb) | I(Dumb) | I(Intelligent) | I(Intelligent) |
+------+---------+---------+----------------+----------------+
| D    | D(Easy) | D(Hard) | D(Easy)        | D(Hard)        |
+------+---------+---------+----------------+----------------+
| G(A) | 0.3     | 0.05    | 0.9            | 0.5            |
+------+---------+---------+----------------+----------------+
| G(B) | 0.4     | 0.25    | 0.08           | 0.3            |
+------+---------+---------+----------------+----------------+
| G(C) | 0.3     | 0.7     | 0.02           | 0.2            |
+------+---------+---------+----------------+----------------+
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[41]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">get_cardinality</span><span class="p">(</span><span class="s1">&#39;G&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[41]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
3
</pre></div></div>
</div>
</section>
<section id="2.-Independencies-in-Bayesian-Networks">
<h3>2. Independencies in Bayesian Networks<a class="headerlink" href="#2.-Independencies-in-Bayesian-Networks" title="Link to this heading">¶</a></h3>
<p>Independencies implied by the network structure of a Bayesian Network can be categorized in 2 types:</p>
<ol class="arabic">
<li><p><strong>Local Independencies:</strong> Any variable in the network is independent of its non-descendents given its parents. Mathematically it can be written as:</p>
<div class="math">
<p><img src="../_images/math/7b9b4eb30d1772f16fb63ce773c63a1e3261150f.png" alt="(X \perp NonDesc(X) | Pa(X)"/></p>
</div><p>where <img class="math" src="../_images/math/96f5ddb3f60f1a021cbd6915b2c9aea56329175c.png" alt="NonDesc(X)"/> is the set of variables which are not descendents of <img class="math" src="../_images/math/ed38fa24f1c94891bd312012aab3f6673be3eb83.png" alt="X"/> and <img class="math" src="../_images/math/b1bd8f322335a0176c22f3593ac312d261b0df3d.png" alt="Pa(X)"/> is the set of variables which are parents of <img class="math" src="../_images/math/ed38fa24f1c94891bd312012aab3f6673be3eb83.png" alt="X"/>.</p>
</li>
<li><p><strong>Global Independencies:</strong> For discussing global independencies in Bayesian Networks we need to look at the various network structures possible. Starting with the case of 2 nodes, there are only 2 possible ways for it to be connected:</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[42]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Image</span><span class="p">(</span><span class="s1">&#39;../images/2/two_nodes.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[42]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="../_images/detailed_notebooks_2._Bayesian_Networks_13_0.png" src="../_images/detailed_notebooks_2._Bayesian_Networks_13_0.png" />
</div>
</div>
<p>In the above two cases it is fairly obvious that change in any of the node will affect the other. For the first case we can take the example of <img class="math" src="../_images/math/d959b626eed2cbc2c5d476387fdc50021272ecc1.png" alt="difficulty \rightarrow grade"/>. If we increase the difficulty of the course the probability of getting a higher grade decreases. For the second case we can take the example of <img class="math" src="../_images/math/9fd7ef74a7f8ae3cbbfa4ac4e07ad5bba1bf159c.png" alt="SAT \leftarrow Intel"/>. Now if we increase the probability of getting a good score in SAT that would imply that the student is intelligent, hence increasing the
probability of <img class="math" src="../_images/math/1568503af3041c6eac4e2a670d46e25d9b8f3b73.png" alt="i_1"/>. Therefore in both the cases shown above any change in the variables leads to change in the other variable.</p>
<p>Now, there are four possible ways of connection between 3 nodes:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[43]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Image</span><span class="p">(</span><span class="s1">&#39;../images/2/three_nodes.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[43]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="../_images/detailed_notebooks_2._Bayesian_Networks_15_0.png" src="../_images/detailed_notebooks_2._Bayesian_Networks_15_0.png" />
</div>
</div>
<p>Now in the above cases we will see the flow of influence from <img class="math" src="../_images/math/211284f68205c3e66773eaf026f32a0acdd3dfb3.png" alt="A"/> to <img class="math" src="../_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.png" alt="C"/> under various cases.</p>
<ol class="arabic simple">
<li><p><strong>Causal:</strong> In the general case when we make any changes in the variable <img class="math" src="../_images/math/211284f68205c3e66773eaf026f32a0acdd3dfb3.png" alt="A"/>, it will have effect of variable <img class="math" src="../_images/math/4bc3e94a67870b41b7c20179693e889251e2c136.png" alt="B"/> (as we discussed above) and this change in <img class="math" src="../_images/math/4bc3e94a67870b41b7c20179693e889251e2c136.png" alt="B"/> will change the values in <img class="math" src="../_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.png" alt="C"/>. One other possible case can be when <img class="math" src="../_images/math/4bc3e94a67870b41b7c20179693e889251e2c136.png" alt="B"/> is observed i.e. we know the value of <img class="math" src="../_images/math/4bc3e94a67870b41b7c20179693e889251e2c136.png" alt="B"/>. So, in this case any change in <img class="math" src="../_images/math/211284f68205c3e66773eaf026f32a0acdd3dfb3.png" alt="A"/> won’t affect <img class="math" src="../_images/math/4bc3e94a67870b41b7c20179693e889251e2c136.png" alt="B"/> since we already know the value. And hence there won’t be any change in <img class="math" src="../_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.png" alt="C"/> as it depends only on <img class="math" src="../_images/math/4bc3e94a67870b41b7c20179693e889251e2c136.png" alt="B"/>.
Mathematically we can say that: <img class="math" src="../_images/math/804ca24d5efc37bccd5c9d4b2d2d16a6a0244e58.png" alt="(A \perp C | B)"/>.</p></li>
<li><p><strong>Evidential:</strong> Similarly in this case also observing <img class="math" src="../_images/math/4bc3e94a67870b41b7c20179693e889251e2c136.png" alt="B"/> renders <img class="math" src="../_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.png" alt="C"/> independent of <img class="math" src="../_images/math/211284f68205c3e66773eaf026f32a0acdd3dfb3.png" alt="A"/>. Otherwise when <img class="math" src="../_images/math/4bc3e94a67870b41b7c20179693e889251e2c136.png" alt="B"/> is not observed the influence flows from <img class="math" src="../_images/math/211284f68205c3e66773eaf026f32a0acdd3dfb3.png" alt="A"/> to <img class="math" src="../_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.png" alt="C"/>. Hence <img class="math" src="../_images/math/804ca24d5efc37bccd5c9d4b2d2d16a6a0244e58.png" alt="(A \perp C | B)"/>.</p></li>
<li><p><strong>Common Evidence:</strong> This case is a bit different from the others. When <img class="math" src="../_images/math/4bc3e94a67870b41b7c20179693e889251e2c136.png" alt="B"/> is not observed any change in <img class="math" src="../_images/math/211284f68205c3e66773eaf026f32a0acdd3dfb3.png" alt="A"/> reflects some change in <img class="math" src="../_images/math/4bc3e94a67870b41b7c20179693e889251e2c136.png" alt="B"/> but not in <img class="math" src="../_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.png" alt="C"/>. Let’s take the example of <img class="math" src="../_images/math/e3f78f1524a6156f60f906623ab76e0b05aa31ec.png" alt="D \rightarrow G \leftarrow I"/>. In this case if we increase the difficulty of the course the probability of getting a higher grade reduces but this has no effect on the intelligence of the student. But when <img class="math" src="../_images/math/4bc3e94a67870b41b7c20179693e889251e2c136.png" alt="B"/> is observed let’s say that the student got a good grade. Now if we
increase the difficulty of the course this will increase the probability of the student to be intelligent since we already know that he got a good grade. Hence in this case <img class="math" src="../_images/math/3aafac76efa120f4c16138c8acc877c8c4c5ca17.png" alt="(A \perp C)"/> and <img class="math" src="../_images/math/592cae77aa1e512603120dfe2670c0679cd38380.png" alt="( A \not\perp C | B)"/>. This structure is also commonly known as V structure.</p></li>
<li><p><strong>Common Cause:</strong> The influence flows from <img class="math" src="../_images/math/211284f68205c3e66773eaf026f32a0acdd3dfb3.png" alt="A"/> to <img class="math" src="../_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.png" alt="C"/> when <img class="math" src="../_images/math/4bc3e94a67870b41b7c20179693e889251e2c136.png" alt="B"/> is not observed. But when <img class="math" src="../_images/math/4bc3e94a67870b41b7c20179693e889251e2c136.png" alt="B"/> is observed and change in <img class="math" src="../_images/math/211284f68205c3e66773eaf026f32a0acdd3dfb3.png" alt="A"/> doesn’t affect <img class="math" src="../_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.png" alt="C"/> since it’s only dependent on <img class="math" src="../_images/math/4bc3e94a67870b41b7c20179693e889251e2c136.png" alt="B"/>. Hence here also <img class="math" src="../_images/math/30824d99dc274a991e391e3f0abef1be0e008d5b.png" alt="( A \perp C | B)"/>.</p></li>
</ol>
<p>Let’s not see a few examples for finding the independencies in a newtork using pgmpy:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[44]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Getting the local independencies of a variable.</span>
<span class="n">model</span><span class="o">.</span><span class="n">local_independencies</span><span class="p">(</span><span class="s1">&#39;G&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[44]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(G _|_ S | I, D)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[45]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Getting all the local independencies in the network.</span>
<span class="n">model</span><span class="o">.</span><span class="n">local_independencies</span><span class="p">([</span><span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="s1">&#39;I&#39;</span><span class="p">,</span> <span class="s1">&#39;S&#39;</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span><span class="p">,</span> <span class="s1">&#39;L&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[45]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(D _|_ I, S)
(I _|_ D)
(S _|_ G, L, D | I)
(G _|_ S | I, D)
(L _|_ I, D, S | G)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[48]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Active trail: For any two variables A and B in a network if any change in A influences the values of B then we say</span>
<span class="c1">#               that there is an active trail between A and B.</span>
<span class="c1"># In pgmpy active_trail_nodes gives a set of nodes which are affected (i.e. correlated) by any</span>
<span class="c1"># change in the node passed in the argument.</span>
<span class="n">model</span><span class="o">.</span><span class="n">active_trail_nodes</span><span class="p">(</span><span class="s1">&#39;D&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[48]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;D&#39;: {&#39;D&#39;, &#39;G&#39;, &#39;L&#39;}}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[49]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">active_trail_nodes</span><span class="p">(</span><span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="s1">&#39;G&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[49]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;D&#39;: {&#39;D&#39;, &#39;I&#39;, &#39;S&#39;}}
</pre></div></div>
</div>
</section>
<section id="3.-How-is-this-Bayesian-Network-representing-the-Joint-Distribution-over-the-variables-?">
<h3>3. How is this Bayesian Network representing the Joint Distribution over the variables ?<a class="headerlink" href="#3.-How-is-this-Bayesian-Network-representing-the-Joint-Distribution-over-the-variables-?" title="Link to this heading">¶</a></h3>
<p>Till now we just have been considering that the Bayesian Network can represent the Joint Distribution without any proof. Now let’s see how to compute the Joint Distribution from the Bayesian Network.</p>
<p>From the chain rule of probabiliy we know that:</p>
<p><img class="math" src="../_images/math/450c269d6c845537545dd959884402b387796026.png" alt="P(A, B) = P(A | B) * P(B)"/></p>
<p>Now in this case:</p>
<p><img class="math" src="../_images/math/73145d1c9f34a44c8345b173d43a86d60fb2fd83.png" alt="P(D, I, G, L, S) = P(L| S, G, D, I) * P(S | G, D, I) * P(G | D, I) * P(D | I) * P(I)"/></p>
<p>Applying the local independence conditions in the above equation we will get:</p>
<p><img class="math" src="../_images/math/ce65c955d312104eba537667c12b412f748ad0fc.png" alt="P(D, I, G, L, S) = P(L|G) * P(S|I) * P(G| D, I) * P(D) * P(I)"/></p>
<p>From the above equation we can clearly see that the Joint Distribution over all the variables is just the product of all the CPDs in the network. Hence encoding the independencies in the Joint Distribution in a graph structure helped us in reducing the number of parameters that we need to store.</p>
</section>
<section id="4.-Inference-in-Bayesian-Models">
<h3>4. Inference in Bayesian Models<a class="headerlink" href="#4.-Inference-in-Bayesian-Models" title="Link to this heading">¶</a></h3>
<p>Till now we discussed just about representing Bayesian Networks. Now let’s see how we can do inference in a Bayesian Model and use it to predict values over new data points for machine learning tasks. In this section we will consider that we already have our model. We will talk about constructing the models from data in later parts of this tutorial.</p>
<p>In inference we try to answer probability queries over the network given some other variables. So, we might want to know the probable grade of an intelligent student in a difficult class given that he scored good in SAT. So for computing these values from a Joint Distribution we will have to reduce over the given variables that is <img class="math" src="../_images/math/56638e7b194559cee95d15075181eb822168b3a2.png" alt="I = 1"/>, <img class="math" src="../_images/math/5374518f03c8d128ff8f24fbdfd5b7c9f1d4b620.png" alt="D = 1"/>, <img class="math" src="../_images/math/eb222ef3dc7369b0c714b6c54dd7b5b8fde532d6.png" alt="S = 1"/> and then marginalize over the other variables that is <img class="math" src="../_images/math/19eef1966f7c545af3ac8c0fa486974d873e3c65.png" alt="L"/> to get <img class="math" src="../_images/math/6860587a7759f58e9c25a8ff9e4292766d09adc2.png" alt="P(G | I=1, D=1, S=1)"/>. But carrying on
marginalize and reduce operation on the complete Joint Distribution is computationaly expensive since we need to iterate over the whole table for each operation and the table is exponential is size to the number of variables. But in Graphical Models we exploit the independencies to break these operations in smaller parts making it much faster.</p>
<p>One of the very basic methods of inference in Graphical Models is <strong>Variable Elimination</strong>.</p>
<section id="Variable-Elimination">
<h4>Variable Elimination<a class="headerlink" href="#Variable-Elimination" title="Link to this heading">¶</a></h4>
<p>We know that:</p>
<p><img class="math" src="../_images/math/9d45568f6d9843178bb9623abf8cfa32d70d7017.png" alt="P(D, I, G, L, S) = P(L|G) * P(S|I) * P(G|D, I) * P(D) * P(I)"/></p>
<p>Now let’s say we just want to compute the probability of G. For that we will need to marginalize over all the other variables.</p>
<p><img class="math" src="../_images/math/25efb2436d56df876a9b2a79fa67ff39d11b64c2.png" alt="P(G) = \sum_{D, I, L, S} P(D, I, G, L, S)"/></p>
<p><img class="math" src="../_images/math/e817758e2c4be953d3e567e2488a9db200624643.png" alt="P(G) = \sum_{D, I, L, S} P(L|G) * P(S|I) * P(G|D, I) * P(D) * P(I)"/></p>
<p><img class="math" src="../_images/math/6d05237bc63874a81b43e526991e4f8b60d1fec4.png" alt="P(G) = \sum_D \sum_I \sum_L \sum_S P(L|G) * P(S|I) * P(G|D, I) * P(D) * P(I)"/></p>
<p>Now since not all the conditional distributions depend on all the variables we can push the summations inside:</p>
<p><img class="math" src="../_images/math/6d05237bc63874a81b43e526991e4f8b60d1fec4.png" alt="P(G) = \sum_D \sum_I \sum_L \sum_S P(L|G) * P(S|I) * P(G|D, I) * P(D) * P(I)"/></p>
<p><img class="math" src="../_images/math/2ed151c5fa794cd5a7371b21a9fab6c2cd5ed9e6.png" alt="P(G) = \sum_D P(D) \sum_I P(G|D, I) * P(I) \sum_S P(S|I) \sum_L P(L|G)"/></p>
<p>So, by pushing the summations inside we have saved a lot of computation because we have to now iterate over much smaller tables.</p>
<p>Let’s take an example for inference using Variable Elimination in pgmpy:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[52]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pgmpy.inference</span> <span class="kn">import</span> <span class="n">VariableElimination</span>
<span class="n">infer</span> <span class="o">=</span> <span class="n">VariableElimination</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">g_dist</span> <span class="o">=</span> <span class="n">infer</span><span class="o">.</span><span class="n">query</span><span class="p">([</span><span class="s1">&#39;G&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g_dist</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Finding Elimination Order: : 100%|██████████| 4/4 [00:00&lt;00:00, 1210.13it/s]
Eliminating: I: 100%|██████████| 4/4 [00:00&lt;00:00, 240.56it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
+------+----------+
| G    |   phi(G) |
+======+==========+
| G(A) |   0.3620 |
+------+----------+
| G(B) |   0.2884 |
+------+----------+
| G(C) |   0.3496 |
+------+----------+
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<p>There can be cases in which we want to compute the conditional distribution let’s say <img class="math" src="../_images/math/b7980ba95b13192ee645bc39aa10c614ee4bace5.png" alt="P(G | D=0, I=1)"/>. In such cases we need to modify our equations a bit:</p>
<p><img class="math" src="../_images/math/3f4c9519a58dc10e05c1c18ab274505cbe592750.png" alt="P(G | D=0, I=1) = \sum_L \sum_S P(L|G) * P(S| I=1) * P(G| D=0, I=1) * P(D=0) * P(I=1)"/></p>
<p><img class="math" src="../_images/math/ea9afa2989d40bf6984dfbb44e70c2f2bd74a9a5.png" alt="P(G | D=0, I=1) = P(D=0) * P(I=1) * P(G | D=0, I=1) * \sum_L P(L | G) * \sum_S P(S | I=1)"/></p>
<p>In pgmpy we will just need to pass an extra argument in the case of conditional distributions:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[58]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">infer</span><span class="o">.</span><span class="n">query</span><span class="p">([</span><span class="s1">&#39;G&#39;</span><span class="p">],</span> <span class="n">evidence</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;D&#39;</span><span class="p">:</span> <span class="s1">&#39;Easy&#39;</span><span class="p">,</span> <span class="s1">&#39;I&#39;</span><span class="p">:</span> <span class="s1">&#39;Intelligent&#39;</span><span class="p">}))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Finding Elimination Order: : 100%|██████████| 2/2 [00:00&lt;00:00, 552.57it/s]
Eliminating: S: 100%|██████████| 2/2 [00:00&lt;00:00, 326.68it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
+------+----------+
| G    |   phi(G) |
+======+==========+
| G(A) |   0.9000 |
+------+----------+
| G(B) |   0.0800 |
+------+----------+
| G(C) |   0.0200 |
+------+----------+
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
</section>
<section id="Predicting-values-from-new-data-points">
<h4>Predicting values from new data points<a class="headerlink" href="#Predicting-values-from-new-data-points" title="Link to this heading">¶</a></h4>
<p>Predicting values from new data points is quite similar to computing the conditional probabilities. We need to query for the variable that we need to predict given all the other features. The only difference is that rather than getting the probabilitiy distribution we are interested in getting the most probable state of the variable.</p>
<p>In pgmpy this is known as MAP query. Here’s an example:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[59]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">infer</span><span class="o">.</span><span class="n">map_query</span><span class="p">([</span><span class="s1">&#39;G&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Finding Elimination Order: : 100%|██████████| 4/4 [00:00&lt;00:00, 1073.12it/s]
Eliminating: I: 100%|██████████| 4/4 [00:00&lt;00:00, 273.20it/s]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[59]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;G&#39;: &#39;A&#39;}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[60]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">infer</span><span class="o">.</span><span class="n">map_query</span><span class="p">([</span><span class="s1">&#39;G&#39;</span><span class="p">],</span> <span class="n">evidence</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;D&#39;</span><span class="p">:</span> <span class="s1">&#39;Easy&#39;</span><span class="p">,</span> <span class="s1">&#39;I&#39;</span><span class="p">:</span> <span class="s1">&#39;Intelligent&#39;</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Finding Elimination Order: : 100%|██████████| 2/2 [00:00&lt;00:00, 417.30it/s]
Eliminating: S: 100%|██████████| 2/2 [00:00&lt;00:00, 219.08it/s]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[60]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;G&#39;: &#39;A&#39;}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[61]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">infer</span><span class="o">.</span><span class="n">map_query</span><span class="p">([</span><span class="s1">&#39;G&#39;</span><span class="p">],</span> <span class="n">evidence</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;D&#39;</span><span class="p">:</span> <span class="s1">&#39;Easy&#39;</span><span class="p">,</span> <span class="s1">&#39;I&#39;</span><span class="p">:</span> <span class="s1">&#39;Intelligent&#39;</span><span class="p">,</span> <span class="s1">&#39;L&#39;</span><span class="p">:</span> <span class="s1">&#39;Good&#39;</span><span class="p">,</span> <span class="s1">&#39;S&#39;</span><span class="p">:</span> <span class="s1">&#39;Good&#39;</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Finding Elimination Order: : : 0it [00:00, ?it/s]
0it [00:00, ?it/s]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[61]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;G&#39;: &#39;A&#39;}
</pre></div></div>
</div>
</section>
</section>
<section id="5.-Other-methods-for-Inference">
<h3>5. Other methods for Inference<a class="headerlink" href="#5.-Other-methods-for-Inference" title="Link to this heading">¶</a></h3>
<p>Even though exact inference algorithms like Variable Elimination optimize the inference task, it is still computationally quite expensive in the case of large models. For such cases we can use approximate algorithms like Message Passing Algorithms, Sampling Algorithms etc. We will talk about a few other exact and approximate algorithms in later parts of the tutorial.</p>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/logo.png" alt="Logo" />
    
  </a>
</p>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../started/base.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../base/base.html">Base Model Structures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/base.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../factors/base.html">Parameterization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/base.html">Exact Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/model_testing.html">Model Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../approx_infer/base.html">Approximate Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../param_estimator/base.html">Parameter Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/base.html">Structure Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metrics/metrics.html">Metrics for testing models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/base.html">Reading/Writing to File</a></li>
<li class="toctree-l1"><a class="reference internal" href="../plotting.html">Plotting Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Example Notebooks</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../tutorial.html">Tutorial Notebooks</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="1.%20Introduction%20to%20Probabilistic%20Graphical%20Models.html">Introduction to Probabilitic Graphical Models</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Bayesian Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="3.%20Causal%20Bayesian%20Networks.html">Causal Bayesian Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.%20Markov%20Models.html">Markov Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="5.%20Exact%20Inference%20in%20Graphical%20Models.html">Exact Inference in Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="6.%20Approximate%20Inference%20in%20Graphical%20Models.html">Approximate Inference in Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="7.%20Parameterizing%20with%20Continuous%20Variables.html">Parameterizing with Continuous Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="8.%20Sampling%20Algorithms.html">Sampling In Continuous Graphical Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="9.%20Reading%20and%20Writing%20from%20pgmpy%20file%20formats.html">Reading and Writing from pgmpy file formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="10.%20Learning%20Bayesian%20Networks%20from%20Data.html">Learning Bayesian Networks from Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="11.%20A%20Bayesian%20Network%20to%20model%20the%20influence%20of%20energy%20consumption%20on%20greenhouse%20gases%20in%20Italy.html">A Bayesian Network to model the influence of energy consumption on greenhouse gases in Italy</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="../tutorial.html">Tutorial Notebooks</a><ul>
      <li>Previous: <a href="1.%20Introduction%20to%20Probabilistic%20Graphical%20Models.html" title="previous chapter">Introduction to Probabilitic Graphical Models</a></li>
      <li>Next: <a href="3.%20Causal%20Bayesian%20Networks.html" title="next chapter">Causal Bayesian Networks</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>







<script async src="https://media.ethicalads.io/media/client/ethicalads.min.js"></script>

<div data-ea-publisher="pgmpyorg" data-ea-type="image" data-ea-style="horizontal"></div><script async src="https://www.googletagmanager.com/gtag/js?id=G-HCFR07M31W"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-HCFR07M31W');
</script>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2023, Ankur Ankan.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.4.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="../_sources/detailed_notebooks/2. Bayesian Networks.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>