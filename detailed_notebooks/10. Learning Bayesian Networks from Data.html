

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>10. Learning Bayesian Networks from Data &mdash; pgmpy 0.1.15 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="11. A Bayesian Network to model the influence of energy consumption on greenhouse gases in Italy" href="11.%20A%20Bayesian%20Network%20to%20model%20the%20influence%20of%20energy%20consumption%20on%20greenhouse%20gases%20in%20Italy.html" />
    <link rel="prev" title="9. Reading and Writing from pgmpy file formats" href="9.%20Reading%20and%20Writing%20from%20pgmpy%20file%20formats.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> pgmpy
          

          
          </a>

          
            
            
              <div class="version">
                0.1.15
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../started/install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../started/contributing.html">Contributing to pgmpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../started/license.html">License</a></li>
</ul>
<p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../models/bayesiannetwork.html">Bayesian Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/dbn.html">Dynamic Bayesian Network (DBN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/sem.html">Structural Equation Models (SEM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/naive.html">Naive Bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/noisyor.html">NoisyOr Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/markovnetwork.html">Markov Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/junctiontree.html">Junction Tree</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/clustergraph.html">Cluster Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/factorgraph.html">Factor Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/markovchain.html">Markov Chain</a></li>
</ul>
<p class="caption"><span class="caption-text">Parameterization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../factors/discrete.html">Discrete</a></li>
<li class="toctree-l1"><a class="reference internal" href="../factors/continuous.html">Continuous</a></li>
<li class="toctree-l1"><a class="reference internal" href="../factors/discretize.html">Discretizing Methods</a></li>
</ul>
<p class="caption"><span class="caption-text">Exact Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/ve.html">Variable Elimination</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/ve.html#module-pgmpy.inference.EliminationOrder">Elimination Ordering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/bp.html">Belief Propagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/causal.html">Causal Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/mplp.html">MPLP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/dbn_infer.html">Dynamic Bayesian Network Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exact_infer/model_testing.html">Model Testing</a></li>
</ul>
<p class="caption"><span class="caption-text">Approximate Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../approx_infer/bn_sampling.html">Bayesian Model Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../approx_infer/gibbs.html">Gibbs Sampling</a></li>
</ul>
<p class="caption"><span class="caption-text">Parameter Estimation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../param_estimator/mle.html">Maximum Likelihood Estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../param_estimator/bayesian_est.html">Bayesian Estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../param_estimator/em.html">Expectation Maximization (EM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../param_estimator/sem_estimator.html">Structural Equation Model Estimators</a></li>
</ul>
<p class="caption"><span class="caption-text">Structure Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/pc.html">PC (Constraint-Based Estimator)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/pc.html#module-pgmpy.estimators.CITests">Conditional Independence Tests for PC algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/hill.html">Hill Climb Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/hill.html#structure-score">Structure Score</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/tree.html">Tree Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/mmhc.html">Mmhc Estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../structure_estimator/exhaustive.html">Exhaustive Search</a></li>
</ul>
<p class="caption"><span class="caption-text">Input/Output</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/bif.html">BIF (Bayesian Interchange Format)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/uai.html">UAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/xmlbif.html">XMLBIF</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/pomdpx.html">PomdpX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../readwrite/xmlbelief.html">XMLBeliefNetwork</a></li>
</ul>
<p class="caption"><span class="caption-text">Example Notebooks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../examples/Alarm.html">1. Example Using the Alarm network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Monty%20Hall%20Problem.html">2. Monty Hall Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Creating%20a%20Discrete%20Bayesian%20Network.html">3. Creating discrete Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Inference%20in%20Discrete%20Bayesian%20Networks.html">4. Inference in Discrete Bayesian Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Causal%20Games.html">5. Causal Games</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Causal%20Inference.html">6. Causal Inference Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Learning%20Parameters%20in%20Discrete%20Bayesian%20Networks.html">7. Parameter Learning in Discrete Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Structure%20Learning%20in%20Bayesian%20Networks.html">8. Structure Learning in Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Structure%20Learning%20with%20Chow-Liu.html">9. Learning Tree Structure from Data using the Chow-Liu Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Structure%20Learning%20with%20TAN.html">10. Learning Tree-augmented Naive Bayes (TAN) Structure from Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Extending%20pgmpy.html">11. Extending pgmpy</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorial Notebooks</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="1.%20Introduction%20to%20Probabilistic%20Graphical%20Models.html">1. Introduction to Probabilitic Graphical Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="2.%20Bayesian%20Networks.html">2. Bayesian Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.%20Causal%20Bayesian%20Networks.html">3. Causal Bayesian Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.%20Markov%20Models.html">4. Markov Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="5.%20Exact%20Inference%20in%20Graphical%20Models.html">5. Exact Inference in Graphical Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="6.%20Approximate%20Inference%20in%20Graphical%20Models.html">6. Approximate Inference in Graphical Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="7.%20Parameterizing%20with%20Continuous%20Variables.html">7. Parameterizing with Continuous Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="8.%20Sampling%20Algorithms.html">8. Sampling In Continuous Graphical Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="9.%20Reading%20and%20Writing%20from%20pgmpy%20file%20formats.html">9. Reading and Writing from pgmpy file formats</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">10. Learning Bayesian Networks from Data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Parameter-Learning">10.1. Parameter Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#State-counts">10.1.1. State counts</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Maximum-Likelihood-Estimation">10.1.2. Maximum Likelihood Estimation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Bayesian-Parameter-Estimation">10.1.3. Bayesian Parameter Estimation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Structure-Learning">10.2. Structure Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Scoring-functions">10.2.1. Scoring functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Search-strategies">10.2.2. Search strategies</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Constraint-based-Structure-Learning">10.2.2.1. Constraint-based Structure Learning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#(Conditional)-Independence-Tests">10.2.3. (Conditional) Independence Tests</a></li>
<li class="toctree-l3"><a class="reference internal" href="#DAG-(pattern)-construction">10.2.4. DAG (pattern) construction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Hybrid-Structure-Learning">10.2.4.1. Hybrid Structure Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Conclusion">10.2.4.2. Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="#References">10.2.4.3. References</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="11.%20A%20Bayesian%20Network%20to%20model%20the%20influence%20of%20energy%20consumption%20on%20greenhouse%20gases%20in%20Italy.html">11. A Bayesian Network to model the influence of energy consumption on greenhouse gases in Italy</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">pgmpy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li><span class="section-number">10. </span>Learning Bayesian Networks from Data</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/detailed_notebooks/10. Learning Bayesian Networks from Data.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="Learning-Bayesian-Networks-from-Data">
<h1><span class="section-number">10. </span>Learning Bayesian Networks from Data<a class="headerlink" href="#Learning-Bayesian-Networks-from-Data" title="Permalink to this headline">¶</a></h1>
<p>Previous notebooks showed how Bayesian networks economically encode a probability distribution over a set of variables, and how they can be used e.g. to predict variable states, or to generate new samples from the joint distribution. This section will be about obtaining a Bayesian network, given a set of sample data. Learning a Bayesian network can be split into two problems:</p>
<p><strong>Parameter learning:</strong> Given a set of data samples and a DAG that captures the dependencies between the variables, estimate the (conditional) probability distributions of the individual variables.</p>
<p><strong>Structure learning:</strong> Given a set of data samples, estimate a DAG that captures the dependencies between the variables.</p>
<p>This notebook aims to illustrate how parameter learning and structure learning can be done with pgmpy. Currently, the library supports: - Parameter learning for <em>discrete</em> nodes: - Maximum Likelihood Estimation - Bayesian Estimation - Structure learning for <em>discrete</em>, <em>fully observed</em> networks: - Score-based structure estimation (BIC/BDeu/K2 score; exhaustive search, hill climb/tabu search) - Constraint-based structure estimation (PC) - Hybrid structure estimation (MMHC)</p>
<section id="Parameter-Learning">
<h2><span class="section-number">10.1. </span>Parameter Learning<a class="headerlink" href="#Parameter-Learning" title="Permalink to this headline">¶</a></h2>
<p>Suppose we have the following data:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;fruit&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;banana&quot;</span><span class="p">,</span> <span class="s2">&quot;apple&quot;</span><span class="p">,</span> <span class="s2">&quot;banana&quot;</span><span class="p">,</span> <span class="s2">&quot;apple&quot;</span><span class="p">,</span> <span class="s2">&quot;banana&quot;</span><span class="p">,</span><span class="s2">&quot;apple&quot;</span><span class="p">,</span> <span class="s2">&quot;banana&quot;</span><span class="p">,</span>
                                    <span class="s2">&quot;apple&quot;</span><span class="p">,</span> <span class="s2">&quot;apple&quot;</span><span class="p">,</span> <span class="s2">&quot;apple&quot;</span><span class="p">,</span> <span class="s2">&quot;banana&quot;</span><span class="p">,</span> <span class="s2">&quot;banana&quot;</span><span class="p">,</span> <span class="s2">&quot;apple&quot;</span><span class="p">,</span> <span class="s2">&quot;banana&quot;</span><span class="p">,],</span>
                          <span class="s1">&#39;tasty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;yes&quot;</span><span class="p">,</span> <span class="s2">&quot;no&quot;</span><span class="p">,</span> <span class="s2">&quot;yes&quot;</span><span class="p">,</span> <span class="s2">&quot;yes&quot;</span><span class="p">,</span> <span class="s2">&quot;yes&quot;</span><span class="p">,</span> <span class="s2">&quot;yes&quot;</span><span class="p">,</span> <span class="s2">&quot;yes&quot;</span><span class="p">,</span>
                                    <span class="s2">&quot;yes&quot;</span><span class="p">,</span> <span class="s2">&quot;yes&quot;</span><span class="p">,</span> <span class="s2">&quot;yes&quot;</span><span class="p">,</span> <span class="s2">&quot;yes&quot;</span><span class="p">,</span> <span class="s2">&quot;no&quot;</span><span class="p">,</span> <span class="s2">&quot;no&quot;</span><span class="p">,</span> <span class="s2">&quot;no&quot;</span><span class="p">],</span>
                          <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;large&quot;</span><span class="p">,</span> <span class="s2">&quot;large&quot;</span><span class="p">,</span> <span class="s2">&quot;large&quot;</span><span class="p">,</span> <span class="s2">&quot;small&quot;</span><span class="p">,</span> <span class="s2">&quot;large&quot;</span><span class="p">,</span> <span class="s2">&quot;large&quot;</span><span class="p">,</span> <span class="s2">&quot;large&quot;</span><span class="p">,</span>
                                    <span class="s2">&quot;small&quot;</span><span class="p">,</span> <span class="s2">&quot;large&quot;</span><span class="p">,</span> <span class="s2">&quot;large&quot;</span><span class="p">,</span> <span class="s2">&quot;large&quot;</span><span class="p">,</span> <span class="s2">&quot;large&quot;</span><span class="p">,</span> <span class="s2">&quot;small&quot;</span><span class="p">,</span> <span class="s2">&quot;small&quot;</span><span class="p">]})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
     fruit tasty   size
0   banana   yes  large
1    apple    no  large
2   banana   yes  large
3    apple   yes  small
4   banana   yes  large
5    apple   yes  large
6   banana   yes  large
7    apple   yes  small
8    apple   yes  large
9    apple   yes  large
10  banana   yes  large
11  banana    no  large
12   apple    no  small
13  banana    no  small
</pre></div></div>
</div>
<p>We know that the variables relate as follows:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pgmpy.models</span> <span class="kn">import</span> <span class="n">BayesianModel</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">BayesianModel</span><span class="p">([(</span><span class="s1">&#39;fruit&#39;</span><span class="p">,</span> <span class="s1">&#39;tasty&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="s1">&#39;tasty&#39;</span><span class="p">)])</span>  <span class="c1"># fruit -&gt; tasty &lt;- size</span>
</pre></div>
</div>
</div>
<p>Parameter learning is the task to estimate the values of the conditional probability distributions (CPDs), for the variables <code class="docutils literal notranslate"><span class="pre">fruit</span></code>, <code class="docutils literal notranslate"><span class="pre">size</span></code>, and <code class="docutils literal notranslate"><span class="pre">tasty</span></code>.</p>
<section id="State-counts">
<h3><span class="section-number">10.1.1. </span>State counts<a class="headerlink" href="#State-counts" title="Permalink to this headline">¶</a></h3>
<p>To make sense of the given data, we can start by counting how often each state of the variable occurs. If the variable is dependent on parents, the counts are done conditionally on the parents states, i.e. for seperately for each parent configuration:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pgmpy.estimators</span> <span class="kn">import</span> <span class="n">ParameterEstimator</span>
<span class="n">pe</span> <span class="o">=</span> <span class="n">ParameterEstimator</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">pe</span><span class="o">.</span><span class="n">state_counts</span><span class="p">(</span><span class="s1">&#39;fruit&#39;</span><span class="p">))</span>  <span class="c1"># unconditional</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">pe</span><span class="o">.</span><span class="n">state_counts</span><span class="p">(</span><span class="s1">&#39;tasty&#39;</span><span class="p">))</span>  <span class="c1"># conditional on fruit and size</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

         fruit
apple       7
banana      7

 fruit apple       banana
size  large small  large small
tasty
no      1.0   1.0    1.0   1.0
yes     3.0   2.0    5.0   0.0
</pre></div></div>
</div>
<p>We can see, for example, that as many apples as bananas were observed and that <code class="docutils literal notranslate"><span class="pre">5</span></code> large bananas were tasty, while only <code class="docutils literal notranslate"><span class="pre">1</span></code> was not.</p>
</section>
<section id="Maximum-Likelihood-Estimation">
<h3><span class="section-number">10.1.2. </span>Maximum Likelihood Estimation<a class="headerlink" href="#Maximum-Likelihood-Estimation" title="Permalink to this headline">¶</a></h3>
<p>A natural estimate for the CPDs is to simply use the <em>relative frequencies</em>, with which the variable states have occured. We observed <code class="docutils literal notranslate"><span class="pre">7</span> <span class="pre">apples</span></code> among a total of <code class="docutils literal notranslate"><span class="pre">14</span> <span class="pre">fruits</span></code>, so we might guess that about <code class="docutils literal notranslate"><span class="pre">50%</span></code> of <code class="docutils literal notranslate"><span class="pre">fruits</span></code> are <code class="docutils literal notranslate"><span class="pre">apples</span></code>.</p>
<p>This approach is <em>Maximum Likelihood Estimation (MLE)</em>. According to MLE, we should fill the CPDs in such a way, that <img class="math" src="../_images/math/8fd1ecbd7acec74f610cb9286c255807885fe370.png" alt="P(\text{data}|\text{model})"/> is maximal. This is achieved when using the <em>relative frequencies</em>. See [1], section 17.1 for an introduction to ML parameter estimation. pgmpy supports MLE as follows:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pgmpy.estimators</span> <span class="kn">import</span> <span class="n">MaximumLikelihoodEstimator</span>
<span class="n">mle</span> <span class="o">=</span> <span class="n">MaximumLikelihoodEstimator</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mle</span><span class="o">.</span><span class="n">estimate_cpd</span><span class="p">(</span><span class="s1">&#39;fruit&#39;</span><span class="p">))</span>  <span class="c1"># unconditional</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mle</span><span class="o">.</span><span class="n">estimate_cpd</span><span class="p">(</span><span class="s1">&#39;tasty&#39;</span><span class="p">))</span>  <span class="c1"># conditional</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
+---------------+-----+
| fruit(apple)  | 0.5 |
+---------------+-----+
| fruit(banana) | 0.5 |
+---------------+-----+
+------------+--------------+--------------------+---------------------+---------------+
| fruit      | fruit(apple) | fruit(apple)       | fruit(banana)       | fruit(banana) |
+------------+--------------+--------------------+---------------------+---------------+
| size       | size(large)  | size(small)        | size(large)         | size(small)   |
+------------+--------------+--------------------+---------------------+---------------+
| tasty(no)  | 0.25         | 0.3333333333333333 | 0.16666666666666666 | 1.0           |
+------------+--------------+--------------------+---------------------+---------------+
| tasty(yes) | 0.75         | 0.6666666666666666 | 0.8333333333333334  | 0.0           |
+------------+--------------+--------------------+---------------------+---------------+
</pre></div></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">mle.estimate_cpd(variable)</span></code> computes the state counts and divides each cell by the (conditional) sample size. The <code class="docutils literal notranslate"><span class="pre">mle.get_parameters()</span></code>-method returns a list of CPDs for all variable of the model.</p>
<p>The built-in <code class="docutils literal notranslate"><span class="pre">fit()</span></code>-method of <code class="docutils literal notranslate"><span class="pre">BayesianModel</span></code> provides more convenient access to parameter estimators:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Calibrate all CPDs of `model` using MLE:</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">estimator</span><span class="o">=</span><span class="n">MaximumLikelihoodEstimator</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>While very straightforward, the ML estimator has the problem of <em>overfitting</em> to the data. In above CPD, the probability of a large banana being tasty is estimated at <code class="docutils literal notranslate"><span class="pre">0.833</span></code>, because <code class="docutils literal notranslate"><span class="pre">5</span></code> out of <code class="docutils literal notranslate"><span class="pre">6</span></code> observed large bananas were tasty. Fine. But note that the probability of a small banana being tasty is estimated at <code class="docutils literal notranslate"><span class="pre">0.0</span></code>, because we observed only one small banana and it happened to be not tasty. But that should hardly make us certain that small bananas aren’t tasty! We simply do not have
enough observations to rely on the observed frequencies. If the observed data is not representative for the underlying distribution, ML estimations will be extremly far off.</p>
<p>When estimating parameters for Bayesian networks, lack of data is a frequent problem. Even if the total sample size is very large, the fact that state counts are done conditionally for each parents configuration causes immense fragmentation. If a variable has 3 parents that can each take 10 states, then state counts will be done seperately for <code class="docutils literal notranslate"><span class="pre">10^3</span> <span class="pre">=</span> <span class="pre">1000</span></code> parents configurations. This makes MLE very fragile and unstable for learning Bayesian Network parameters. A way to mitigate MLE’s
overfitting is <em>Bayesian Parameter Estimation</em>.</p>
</section>
<section id="Bayesian-Parameter-Estimation">
<h3><span class="section-number">10.1.3. </span>Bayesian Parameter Estimation<a class="headerlink" href="#Bayesian-Parameter-Estimation" title="Permalink to this headline">¶</a></h3>
<p>The Bayesian Parameter Estimator starts with already existing prior CPDs, that express our beliefs about the variables <em>before</em> the data was observed. Those “priors” are then updated, using the state counts from the observed data. See [1], Section 17.3 for a general introduction to Bayesian estimators.</p>
<p>One can think of the priors as consisting in <em>pseudo state counts</em>, that are added to the actual counts before normalization. Unless one wants to encode specific beliefs about the distributions of the variables, one commonly chooses uniform priors, i.e. ones that deem all states equiprobable.</p>
<p>A very simple prior is the so-called <em>K2</em> prior, which simply adds <code class="docutils literal notranslate"><span class="pre">1</span></code> to the count of every single state. A somewhat more sensible choice of prior is <em>BDeu</em> (Bayesian Dirichlet equivalent uniform prior). For BDeu we need to specify an <em>equivalent sample size</em> <code class="docutils literal notranslate"><span class="pre">N</span></code> and then the pseudo-counts are the equivalent of having observed <code class="docutils literal notranslate"><span class="pre">N</span></code> uniform samples of each variable (and each parent configuration). In pgmpy:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pgmpy.estimators</span> <span class="kn">import</span> <span class="n">BayesianEstimator</span>
<span class="n">est</span> <span class="o">=</span> <span class="n">BayesianEstimator</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">estimate_cpd</span><span class="p">(</span><span class="s1">&#39;tasty&#39;</span><span class="p">,</span> <span class="n">prior_type</span><span class="o">=</span><span class="s1">&#39;BDeu&#39;</span><span class="p">,</span> <span class="n">equivalent_sample_size</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
+------------+---------------------+--------------------+--------------------+---------------------+
| fruit      | fruit(apple)        | fruit(apple)       | fruit(banana)      | fruit(banana)       |
+------------+---------------------+--------------------+--------------------+---------------------+
| size       | size(large)         | size(small)        | size(large)        | size(small)         |
+------------+---------------------+--------------------+--------------------+---------------------+
| tasty(no)  | 0.34615384615384615 | 0.4090909090909091 | 0.2647058823529412 | 0.6428571428571429  |
+------------+---------------------+--------------------+--------------------+---------------------+
| tasty(yes) | 0.6538461538461539  | 0.5909090909090909 | 0.7352941176470589 | 0.35714285714285715 |
+------------+---------------------+--------------------+--------------------+---------------------+
</pre></div></div>
</div>
<p>The estimated values in the CPDs are now more conservative. In particular, the estimate for a small banana being not tasty is now around <code class="docutils literal notranslate"><span class="pre">0.64</span></code> rather than <code class="docutils literal notranslate"><span class="pre">1.0</span></code>. Setting <code class="docutils literal notranslate"><span class="pre">equivalent_sample_size</span></code> to <code class="docutils literal notranslate"><span class="pre">10</span></code> means that for each parent configuration, we add the equivalent of 10 uniform samples (here: <code class="docutils literal notranslate"><span class="pre">+5</span></code> small bananas that are tasty and <code class="docutils literal notranslate"><span class="pre">+5</span></code> that aren’t).</p>
<p><code class="docutils literal notranslate"><span class="pre">BayesianEstimator</span></code>, too, can be used via the <code class="docutils literal notranslate"><span class="pre">fit()</span></code>-method. Full example:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">pgmpy.models</span> <span class="kn">import</span> <span class="n">BayesianModel</span>
<span class="kn">from</span> <span class="nn">pgmpy.estimators</span> <span class="kn">import</span> <span class="n">BayesianEstimator</span>

<span class="c1"># generate data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;D&#39;</span><span class="p">])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BayesianModel</span><span class="p">([(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;D&#39;</span><span class="p">)])</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">estimator</span><span class="o">=</span><span class="n">BayesianEstimator</span><span class="p">,</span> <span class="n">prior_type</span><span class="o">=</span><span class="s2">&quot;BDeu&quot;</span><span class="p">)</span> <span class="c1"># default equivalent_sample_size=5</span>
<span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">cpd</span><span class="p">)</span>

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
+------+----------+
| A(0) | 0.503996 |
+------+----------+
| A(1) | 0.496004 |
+------+----------+
+------+-------------------+---------------------+
| A    | A(0)              | A(1)                |
+------+-------------------+---------------------+
| B(0) | 0.499207135777998 | 0.49838872104733134 |
+------+-------------------+---------------------+
| B(1) | 0.500792864222002 | 0.5016112789526687  |
+------+-------------------+---------------------+
+------+---------------------+--------------------+--------------------+-------------------+
| A    | A(0)                | A(0)               | A(1)               | A(1)              |
+------+---------------------+--------------------+--------------------+-------------------+
| D    | D(0)                | D(1)               | D(0)               | D(1)              |
+------+---------------------+--------------------+--------------------+-------------------+
| C(0) | 0.5066810768323836  | 0.4908018396320736 | 0.4844929606202816 | 0.511135414595347 |
+------+---------------------+--------------------+--------------------+-------------------+
| C(1) | 0.49331892316761644 | 0.5091981603679264 | 0.5155070393797184 | 0.488864585404653 |
+------+---------------------+--------------------+--------------------+-------------------+
+------+---------------------+---------------------+
| B    | B(0)                | B(1)                |
+------+---------------------+---------------------+
| D(0) | 0.49959943921490085 | 0.49840542156667333 |
+------+---------------------+---------------------+
| D(1) | 0.5004005607850991  | 0.5015945784333267  |
+------+---------------------+---------------------+
</pre></div></div>
</div>
</section>
</section>
<section id="Structure-Learning">
<h2><span class="section-number">10.2. </span>Structure Learning<a class="headerlink" href="#Structure-Learning" title="Permalink to this headline">¶</a></h2>
<p>To learn model structure (a DAG) from a data set, there are two broad techniques:</p>
<ul class="simple">
<li><p>score-based structure learning</p></li>
<li><p>constraint-based structure learning</p></li>
</ul>
<p>The combination of both techniques allows further improvement: - hybrid structure learning</p>
<p>We briefly discuss all approaches and give examples.</p>
<p>This approach construes model selection as an optimization task. It has two building blocks:</p>
<ul class="simple">
<li><p>A <em>scoring function</em> <img class="math" src="../_images/math/aa63459009968b3faf2aa2f92426892298b69300.png" alt="s_D\colon M \to \mathbb R"/> that maps models to a numerical score, based on how well they fit to a given data set <img class="math" src="../_images/math/0fcab9067b50b87e868c4fd70f213a086addb964.png" alt="D"/>.</p></li>
<li><p>A <em>search strategy</em> to traverse the search space of possible models <img class="math" src="../_images/math/4abba779877abb276b98ccb2b4ba9bf2e41947ab.png" alt="M"/> and select a model with optimal score.</p></li>
</ul>
<section id="Scoring-functions">
<h3><span class="section-number">10.2.1. </span>Scoring functions<a class="headerlink" href="#Scoring-functions" title="Permalink to this headline">¶</a></h3>
<p>Commonly used scores to measure the fit between model and data are <em>Bayesian Dirichlet scores</em> such as <em>BDeu</em> or <em>K2</em> and the <em>Bayesian Information Criterion</em> (BIC, also called MDL). See [1], Section 18.3 for a detailed introduction on scores. As before, BDeu is dependent on an equivalent sample size.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">pgmpy.estimators</span> <span class="kn">import</span> <span class="n">BDeuScore</span><span class="p">,</span> <span class="n">K2Score</span><span class="p">,</span> <span class="n">BicScore</span>
<span class="kn">from</span> <span class="nn">pgmpy.models</span> <span class="kn">import</span> <span class="n">BayesianModel</span>

<span class="c1"># create random data sample with 3 variables, where Z is dependent on X, Y:</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;XY&#39;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;Z&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">]</span>

<span class="n">bdeu</span> <span class="o">=</span> <span class="n">BDeuScore</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">equivalent_sample_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">k2</span> <span class="o">=</span> <span class="n">K2Score</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">bic</span> <span class="o">=</span> <span class="n">BicScore</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">model1</span> <span class="o">=</span> <span class="n">BayesianModel</span><span class="p">([(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;Z&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;Z&#39;</span><span class="p">)])</span>  <span class="c1"># X -&gt; Z &lt;- Y</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">BayesianModel</span><span class="p">([(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;Z&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">)])</span>  <span class="c1"># Y &lt;- X -&gt; Z</span>


<span class="nb">print</span><span class="p">(</span><span class="n">bdeu</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">model1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">k2</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">model1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bic</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">model1</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">bdeu</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">model2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">k2</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">model2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bic</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">model2</span><span class="p">))</span>

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-13937.875339249586
-14328.68417117677
-14293.914012166675
-20904.92154575061
-20931.743864925047
-20948.966605351194
</pre></div></div>
</div>
<p>While the scores vary slightly, we can see that the correct <code class="docutils literal notranslate"><span class="pre">model1</span></code> has a much higher score than <code class="docutils literal notranslate"><span class="pre">model2</span></code>. Importantly, these scores <em>decompose</em>, i.e. they can be computed locally for each of the variables given their potential parents, independent of other parts of the network:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="n">bdeu</span><span class="o">.</span><span class="n">local_score</span><span class="p">(</span><span class="s1">&#39;Z&#39;</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="p">[]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bdeu</span><span class="o">.</span><span class="n">local_score</span><span class="p">(</span><span class="s1">&#39;Z&#39;</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bdeu</span><span class="o">.</span><span class="n">local_score</span><span class="p">(</span><span class="s1">&#39;Z&#39;</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-9191.675817737154
-6993.847644065196
-57.120187742958706
</pre></div></div>
</div>
</section>
<section id="Search-strategies">
<h3><span class="section-number">10.2.2. </span>Search strategies<a class="headerlink" href="#Search-strategies" title="Permalink to this headline">¶</a></h3>
<p>The search space of DAGs is super-exponential in the number of variables and the above scoring functions allow for local maxima. The first property makes exhaustive search intractable for all but very small networks, the second prohibits efficient local optimization algorithms to always find the optimal structure. Thus, identifiying the ideal structure is often not tractable. Despite these bad news, heuristic search strategies often yields good results.</p>
<p>If only few nodes are involved (read: less than 5), <code class="docutils literal notranslate"><span class="pre">ExhaustiveSearch</span></code> can be used to compute the score for every DAG and returns the best-scoring one:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pgmpy.estimators</span> <span class="kn">import</span> <span class="n">ExhaustiveSearch</span>

<span class="n">es</span> <span class="o">=</span> <span class="n">ExhaustiveSearch</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">scoring_method</span><span class="o">=</span><span class="n">bic</span><span class="p">)</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="n">es</span><span class="o">.</span><span class="n">estimate</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_model</span><span class="o">.</span><span class="n">edges</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">All DAGs by score:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">score</span><span class="p">,</span> <span class="n">dag</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">es</span><span class="o">.</span><span class="n">all_scores</span><span class="p">()):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">dag</span><span class="o">.</span><span class="n">edges</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[(&#39;X&#39;, &#39;Z&#39;), (&#39;Y&#39;, &#39;Z&#39;)]

All DAGs by score:
-14293.914012166677 [(&#39;X&#39;, &#39;Z&#39;), (&#39;Y&#39;, &#39;Z&#39;)]
-14328.333029363766 [(&#39;X&#39;, &#39;Y&#39;), (&#39;Z&#39;, &#39;X&#39;), (&#39;Z&#39;, &#39;Y&#39;)]
-14328.333029363768 [(&#39;Y&#39;, &#39;X&#39;), (&#39;Z&#39;, &#39;X&#39;), (&#39;Z&#39;, &#39;Y&#39;)]
-14328.33302936377 [(&#39;Y&#39;, &#39;Z&#39;), (&#39;Y&#39;, &#39;X&#39;), (&#39;Z&#39;, &#39;X&#39;)]
-14328.33302936377 [(&#39;X&#39;, &#39;Z&#39;), (&#39;Y&#39;, &#39;Z&#39;), (&#39;Y&#39;, &#39;X&#39;)]
-14328.33302936377 [(&#39;X&#39;, &#39;Y&#39;), (&#39;X&#39;, &#39;Z&#39;), (&#39;Z&#39;, &#39;Y&#39;)]
-14328.33302936377 [(&#39;X&#39;, &#39;Y&#39;), (&#39;X&#39;, &#39;Z&#39;), (&#39;Y&#39;, &#39;Z&#39;)]
-16494.429647593526 [(&#39;X&#39;, &#39;Y&#39;), (&#39;Z&#39;, &#39;Y&#39;)]
-16497.214254274455 [(&#39;Y&#39;, &#39;X&#39;), (&#39;Z&#39;, &#39;X&#39;)]
-18745.666363243407 [(&#39;Z&#39;, &#39;X&#39;), (&#39;Z&#39;, &#39;Y&#39;)]
-18745.66636324341 [(&#39;Y&#39;, &#39;Z&#39;), (&#39;Z&#39;, &#39;X&#39;)]
-18745.666363243414 [(&#39;X&#39;, &#39;Z&#39;), (&#39;Z&#39;, &#39;Y&#39;)]
-20911.76298147317 [(&#39;Z&#39;, &#39;Y&#39;)]
-20911.76298147317 [(&#39;Y&#39;, &#39;Z&#39;)]
-20914.5475881541 [(&#39;Z&#39;, &#39;X&#39;)]
-20914.5475881541 [(&#39;X&#39;, &#39;Z&#39;)]
-20946.18199867026 [(&#39;Y&#39;, &#39;X&#39;), (&#39;Z&#39;, &#39;Y&#39;)]
-20946.181998670265 [(&#39;Y&#39;, &#39;Z&#39;), (&#39;Y&#39;, &#39;X&#39;)]
-20946.181998670265 [(&#39;X&#39;, &#39;Y&#39;), (&#39;Y&#39;, &#39;Z&#39;)]
-20948.96660535119 [(&#39;X&#39;, &#39;Y&#39;), (&#39;Z&#39;, &#39;X&#39;)]
-20948.966605351194 [(&#39;X&#39;, &#39;Z&#39;), (&#39;Y&#39;, &#39;X&#39;)]
-20948.966605351194 [(&#39;X&#39;, &#39;Y&#39;), (&#39;X&#39;, &#39;Z&#39;)]
-23080.64420638386 []
-23115.063223580953 [(&#39;Y&#39;, &#39;X&#39;)]
-23115.063223580953 [(&#39;X&#39;, &#39;Y&#39;)]
</pre></div></div>
</div>
<p>Once more nodes are involved, one needs to switch to heuristic search. <code class="docutils literal notranslate"><span class="pre">HillClimbSearch</span></code> implements a greedy local search that starts from the DAG <code class="docutils literal notranslate"><span class="pre">start</span></code> (default: disconnected DAG) and proceeds by iteratively performing single-edge manipulations that maximally increase the score. The search terminates once a local maximum is found.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pgmpy.estimators</span> <span class="kn">import</span> <span class="n">HillClimbSearch</span>

<span class="c1"># create some data with dependencies</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2500</span><span class="p">,</span> <span class="mi">8</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;ABCDEFGH&#39;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">]</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;H&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;G&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span>

<span class="n">hc</span> <span class="o">=</span> <span class="n">HillClimbSearch</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">scoring_method</span><span class="o">=</span><span class="n">BicScore</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="n">hc</span><span class="o">.</span><span class="n">estimate</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_model</span><span class="o">.</span><span class="n">edges</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[(&#39;A&#39;, &#39;B&#39;), (&#39;A&#39;, &#39;C&#39;), (&#39;B&#39;, &#39;C&#39;), (&#39;G&#39;, &#39;A&#39;), (&#39;G&#39;, &#39;H&#39;), (&#39;H&#39;, &#39;A&#39;)]
</pre></div></div>
</div>
<p>The search correctly identifies e.g. that <code class="docutils literal notranslate"><span class="pre">B</span></code> and <code class="docutils literal notranslate"><span class="pre">C</span></code> do not influnce <code class="docutils literal notranslate"><span class="pre">H</span></code> directly, only through <code class="docutils literal notranslate"><span class="pre">A</span></code> and of course that <code class="docutils literal notranslate"><span class="pre">D</span></code>, <code class="docutils literal notranslate"><span class="pre">E</span></code>, <code class="docutils literal notranslate"><span class="pre">F</span></code> are independent.</p>
<p>To enforce a wider exploration of the search space, the search can be enhanced with a tabu list. The list keeps track of the last <code class="docutils literal notranslate"><span class="pre">n</span></code> modfications; those are then not allowed to be reversed, regardless of the score. Additionally a <code class="docutils literal notranslate"><span class="pre">white_list</span></code> or <code class="docutils literal notranslate"><span class="pre">black_list</span></code> can be supplied to restrict the search to a particular subset or to exclude certain edges. The parameter <code class="docutils literal notranslate"><span class="pre">max_indegree</span></code> allows to restrict the maximum number of parents for each node.</p>
<section id="Constraint-based-Structure-Learning">
<h4><span class="section-number">10.2.2.1. </span>Constraint-based Structure Learning<a class="headerlink" href="#Constraint-based-Structure-Learning" title="Permalink to this headline">¶</a></h4>
<p>A different, but quite straightforward approach to build a DAG from data is this:</p>
<ol class="arabic simple">
<li><p>Identify independencies in the data set using hypothesis tests</p></li>
<li><p>Construct DAG (pattern) according to identified independencies</p></li>
</ol>
</section>
</section>
<section id="(Conditional)-Independence-Tests">
<h3><span class="section-number">10.2.3. </span>(Conditional) Independence Tests<a class="headerlink" href="#(Conditional)-Independence-Tests" title="Permalink to this headline">¶</a></h3>
<p>Independencies in the data can be identified using chi2 conditional independence tests. To this end, constraint-based estimators in pgmpy have a <code class="docutils literal notranslate"><span class="pre">test_conditional_independence(X,</span> <span class="pre">Y,</span> <span class="pre">Zs)</span></code>-method, that performs a hypothesis test on the data sample. It allows to check if <code class="docutils literal notranslate"><span class="pre">X</span></code> is independent from <code class="docutils literal notranslate"><span class="pre">Y</span></code> given a set of variables <code class="docutils literal notranslate"><span class="pre">Zs</span></code>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pgmpy.estimators</span> <span class="kn">import</span> <span class="n">ConstraintBasedEstimator</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2500</span><span class="p">,</span> <span class="mi">8</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;ABCDEFGH&#39;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">]</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;H&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;G&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;E&#39;</span><span class="p">]</span> <span class="o">*=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;F&#39;</span><span class="p">]</span>

<span class="n">est</span> <span class="o">=</span> <span class="n">ConstraintBasedEstimator</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">test_conditional_independence</span><span class="p">(</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;H&#39;</span><span class="p">))</span>          <span class="c1"># dependent</span>
<span class="nb">print</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">test_conditional_independence</span><span class="p">(</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;E&#39;</span><span class="p">))</span>          <span class="c1"># independent</span>
<span class="nb">print</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">test_conditional_independence</span><span class="p">(</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;H&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]))</span>   <span class="c1"># independent</span>
<span class="nb">print</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">test_conditional_independence</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span><span class="p">))</span>          <span class="c1"># independent</span>
<span class="nb">print</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">test_conditional_independence</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span><span class="p">,</span>  <span class="p">[</span><span class="s1">&#39;H&#39;</span><span class="p">]))</span>  <span class="c1"># dependent</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
False
True
True
True
False
</pre></div></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">test_conditional_independence()</span></code> returns a tripel <code class="docutils literal notranslate"><span class="pre">(chi2,</span> <span class="pre">p_value,</span> <span class="pre">sufficient_data)</span></code>, consisting in the computed chi2 test statistic, the <code class="docutils literal notranslate"><span class="pre">p_value</span></code> of the test, and a heuristig flag that indicates if the sample size was sufficient. The <code class="docutils literal notranslate"><span class="pre">p_value</span></code> is the probability of observing the computed chi2 statistic (or an even higher chi2 value), given the null hypothesis that X and Y are independent given Zs.</p>
<p>This can be used to make independence judgements, at a given level of significance:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">is_independent</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Zs</span><span class="o">=</span><span class="p">[],</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">est</span><span class="o">.</span><span class="n">test_conditional_independence</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Zs</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">is_independent</span><span class="p">(</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;H&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">is_independent</span><span class="p">(</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;E&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">is_independent</span><span class="p">(</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;H&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">is_independent</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">is_independent</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;H&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
False
True
True
True
False
</pre></div></div>
</div>
</section>
<section id="DAG-(pattern)-construction">
<h3><span class="section-number">10.2.4. </span>DAG (pattern) construction<a class="headerlink" href="#DAG-(pattern)-construction" title="Permalink to this headline">¶</a></h3>
<p>With a method for independence testing at hand, we can construct a DAG from the data set in three steps: 1. Construct an undirected skeleton - <code class="docutils literal notranslate"><span class="pre">estimate_skeleton()</span></code> 2. Orient compelled edges to obtain partially directed acyclid graph (PDAG; I-equivalence class of DAGs) - <code class="docutils literal notranslate"><span class="pre">skeleton_to_pdag()</span></code> 3. Extend DAG pattern to a DAG by conservatively orienting the remaining edges in some way - <code class="docutils literal notranslate"><span class="pre">pdag_to_dag()</span></code></p>
<p>Step 1.&amp;2. form the so-called PC algorithm, see [2], page 550. PDAGs are <code class="docutils literal notranslate"><span class="pre">DirectedGraph</span></code>s, that may contain both-way edges, to indicate that the orientation for the edge is not determined.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">skel</span><span class="p">,</span> <span class="n">seperating_sets</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">estimate_skeleton</span><span class="p">(</span><span class="n">significance_level</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Undirected edges: &quot;</span><span class="p">,</span> <span class="n">skel</span><span class="o">.</span><span class="n">edges</span><span class="p">())</span>

<span class="n">pdag</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">skeleton_to_pdag</span><span class="p">(</span><span class="n">skel</span><span class="p">,</span> <span class="n">seperating_sets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PDAG edges:       &quot;</span><span class="p">,</span> <span class="n">pdag</span><span class="o">.</span><span class="n">edges</span><span class="p">())</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">pdag_to_dag</span><span class="p">(</span><span class="n">pdag</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DAG edges:        &quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">edges</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Undirected edges:  [(&#39;A&#39;, &#39;B&#39;), (&#39;A&#39;, &#39;C&#39;), (&#39;A&#39;, &#39;H&#39;), (&#39;E&#39;, &#39;F&#39;), (&#39;G&#39;, &#39;H&#39;)]
PDAG edges:        [(&#39;A&#39;, &#39;H&#39;), (&#39;B&#39;, &#39;A&#39;), (&#39;C&#39;, &#39;A&#39;), (&#39;E&#39;, &#39;F&#39;), (&#39;F&#39;, &#39;E&#39;), (&#39;G&#39;, &#39;H&#39;)]
DAG edges:         [(&#39;A&#39;, &#39;H&#39;), (&#39;B&#39;, &#39;A&#39;), (&#39;C&#39;, &#39;A&#39;), (&#39;F&#39;, &#39;E&#39;), (&#39;G&#39;, &#39;H&#39;)]
</pre></div></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">estimate()</span></code>-method provides a shorthand for the three steps above and directly returns a <code class="docutils literal notranslate"><span class="pre">BayesianModel</span></code>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">estimate</span><span class="p">(</span><span class="n">significance_level</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span><span class="o">.</span><span class="n">edges</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[(&#39;A&#39;, &#39;H&#39;), (&#39;B&#39;, &#39;A&#39;), (&#39;C&#39;, &#39;A&#39;), (&#39;F&#39;, &#39;E&#39;), (&#39;G&#39;, &#39;H&#39;)]
</pre></div></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">estimate_from_independencies()</span></code>-method can be used to construct a <code class="docutils literal notranslate"><span class="pre">BayesianModel</span></code> from a provided <em>set of independencies</em> (see class documentation for further features &amp; methods):</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pgmpy.independencies</span> <span class="kn">import</span> <span class="n">Independencies</span>

<span class="n">ind</span> <span class="o">=</span> <span class="n">Independencies</span><span class="p">([</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">],</span>
                     <span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">],</span> <span class="s1">&#39;D&#39;</span><span class="p">])</span>
<span class="n">ind</span> <span class="o">=</span> <span class="n">ind</span><span class="o">.</span><span class="n">closure</span><span class="p">()</span>  <span class="c1"># required (!) for faithfulness</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ConstraintBasedEstimator</span><span class="o">.</span><span class="n">estimate_from_independencies</span><span class="p">(</span><span class="s2">&quot;ABCD&quot;</span><span class="p">,</span> <span class="n">ind</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">edges</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[(&#39;A&#39;, &#39;D&#39;), (&#39;B&#39;, &#39;D&#39;), (&#39;C&#39;, &#39;D&#39;)]
</pre></div></div>
</div>
<p>PC PDAG construction is only guaranteed to work under the assumption that the identified set of independencies is <em>faithful</em>, i.e. there exists a DAG that exactly corresponds to it. Spurious dependencies in the data set can cause the reported independencies to violate faithfulness. It can happen that the estimated PDAG does not have any faithful completions (i.e. edge orientations that do not introduce new v-structures). In that case a warning is issued.</p>
<section id="Hybrid-Structure-Learning">
<h4><span class="section-number">10.2.4.1. </span>Hybrid Structure Learning<a class="headerlink" href="#Hybrid-Structure-Learning" title="Permalink to this headline">¶</a></h4>
<p>The MMHC algorithm [3] combines the constraint-based and score-based method. It has two parts:</p>
<ol class="arabic simple">
<li><p>Learn undirected graph skeleton using the constraint-based construction procedure MMPC</p></li>
<li><p>Orient edges using score-based optimization (BDeu score + modified hill-climbing)</p></li>
</ol>
<p>We can perform the two steps seperately, more or less as follows:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pgmpy.estimators</span> <span class="kn">import</span> <span class="n">MmhcEstimator</span>
<span class="kn">from</span> <span class="nn">pgmpy.estimators</span> <span class="kn">import</span> <span class="n">BDeuScore</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2500</span><span class="p">,</span> <span class="mi">8</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="s1">&#39;ABCDEFGH&#39;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">]</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;H&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;G&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;E&#39;</span><span class="p">]</span> <span class="o">*=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;F&#39;</span><span class="p">]</span>

<span class="n">mmhc</span> <span class="o">=</span> <span class="n">MmhcEstimator</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">skeleton</span> <span class="o">=</span> <span class="n">mmhc</span><span class="o">.</span><span class="n">mmpc</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Part 1) Skeleton: &quot;</span><span class="p">,</span> <span class="n">skeleton</span><span class="o">.</span><span class="n">edges</span><span class="p">())</span>

<span class="c1"># use hill climb search to orient the edges:</span>
<span class="n">hc</span> <span class="o">=</span> <span class="n">HillClimbSearch</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">scoring_method</span><span class="o">=</span><span class="n">BDeuScore</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">hc</span><span class="o">.</span><span class="n">estimate</span><span class="p">(</span><span class="n">tabu_length</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">white_list</span><span class="o">=</span><span class="n">skeleton</span><span class="o">.</span><span class="n">to_directed</span><span class="p">()</span><span class="o">.</span><span class="n">edges</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Part 2) Model:    &quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">edges</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing A _|_ G | [&#39;B&#39;, &#39;C&#39;, &#39;H&#39;]. At least 4860 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing A _|_ F | [&#39;B&#39;, &#39;C&#39;, &#39;H&#39;]. At least 4860 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing A _|_ E | [&#39;B&#39;, &#39;C&#39;, &#39;H&#39;]. At least 7290 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing A _|_ D | [&#39;B&#39;, &#39;C&#39;, &#39;H&#39;]. At least 4860 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing A _|_ F | [&#39;B&#39;, &#39;H&#39;, &#39;G&#39;]. At least 4860 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing A _|_ F | [&#39;C&#39;, &#39;H&#39;, &#39;G&#39;]. At least 4860 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing A _|_ F | [&#39;B&#39;, &#39;C&#39;, &#39;H&#39;, &#39;G&#39;]. At least 14580 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing A _|_ E | [&#39;B&#39;, &#39;H&#39;, &#39;G&#39;]. At least 7290 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing A _|_ E | [&#39;C&#39;, &#39;H&#39;, &#39;G&#39;]. At least 7290 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing A _|_ E | [&#39;B&#39;, &#39;C&#39;, &#39;H&#39;, &#39;G&#39;]. At least 21870 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing A _|_ D | [&#39;B&#39;, &#39;H&#39;, &#39;G&#39;]. At least 4860 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing A _|_ D | [&#39;C&#39;, &#39;H&#39;, &#39;G&#39;]. At least 4860 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing A _|_ D | [&#39;B&#39;, &#39;C&#39;, &#39;H&#39;, &#39;G&#39;]. At least 14580 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing B _|_ G | [&#39;A&#39;, &#39;H&#39;, &#39;C&#39;]. At least 3780 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing B _|_ F | [&#39;A&#39;, &#39;H&#39;, &#39;C&#39;]. At least 3780 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing B _|_ E | [&#39;A&#39;, &#39;H&#39;, &#39;C&#39;]. At least 5670 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing B _|_ D | [&#39;A&#39;, &#39;H&#39;, &#39;C&#39;]. At least 3780 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing C _|_ G | [&#39;A&#39;, &#39;H&#39;, &#39;B&#39;]. At least 3780 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing C _|_ F | [&#39;A&#39;, &#39;H&#39;, &#39;B&#39;]. At least 3780 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing C _|_ E | [&#39;A&#39;, &#39;H&#39;, &#39;B&#39;]. At least 5670 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing C _|_ D | [&#39;A&#39;, &#39;H&#39;, &#39;B&#39;]. At least 3780 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing D _|_ A | [&#39;E&#39;, &#39;H&#39;, &#39;B&#39;]. At least 6480 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing E _|_ H | [&#39;F&#39;, &#39;C&#39;, &#39;D&#39;]. At least 3240 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing E _|_ A | [&#39;F&#39;, &#39;C&#39;, &#39;H&#39;]. At least 7290 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing E _|_ A | [&#39;F&#39;, &#39;D&#39;, &#39;H&#39;]. At least 7290 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing E _|_ A | [&#39;C&#39;, &#39;D&#39;, &#39;H&#39;]. At least 7290 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing E _|_ A | [&#39;F&#39;, &#39;C&#39;, &#39;D&#39;, &#39;H&#39;]. At least 21870 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing E _|_ B | [&#39;F&#39;, &#39;C&#39;, &#39;D&#39;, &#39;H&#39;]. At least 7290 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing E _|_ G | [&#39;F&#39;, &#39;C&#39;, &#39;D&#39;, &#39;H&#39;]. At least 7290 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing F _|_ H | [&#39;E&#39;, &#39;C&#39;, &#39;D&#39;]. At least 2880 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing G _|_ B | [&#39;H&#39;, &#39;C&#39;, &#39;A&#39;]. At least 3780 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing G _|_ F | [&#39;H&#39;, &#39;C&#39;, &#39;A&#39;]. At least 3780 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing G _|_ E | [&#39;H&#39;, &#39;C&#39;, &#39;A&#39;]. At least 5670 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing G _|_ D | [&#39;H&#39;, &#39;C&#39;, &#39;A&#39;]. At least 3780 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing H _|_ C | [&#39;G&#39;, &#39;B&#39;, &#39;A&#39;]. At least 5040 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing H _|_ F | [&#39;G&#39;, &#39;B&#39;, &#39;A&#39;]. At least 5040 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing H _|_ E | [&#39;G&#39;, &#39;A&#39;]. At least 2520 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing H _|_ E | [&#39;B&#39;, &#39;A&#39;]. At least 2520 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing H _|_ E | [&#39;G&#39;, &#39;B&#39;, &#39;A&#39;]. At least 7560 samples recommended, 2500 present.
  5 * num_params, len(data)
/home/ankur/pgmpy_notebook/notebooks/pgmpy/estimators/CITests.py:95: UserWarning: Insufficient data for testing H _|_ D | [&#39;G&#39;, &#39;B&#39;, &#39;A&#39;]. At least 5040 samples recommended, 2500 present.
  5 * num_params, len(data)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Part 1) Skeleton:  [(&#39;A&#39;, &#39;C&#39;), (&#39;A&#39;, &#39;H&#39;), (&#39;B&#39;, &#39;C&#39;), (&#39;E&#39;, &#39;F&#39;), (&#39;G&#39;, &#39;H&#39;)]
Part 2) Model:     [(&#39;A&#39;, &#39;H&#39;), (&#39;C&#39;, &#39;A&#39;), (&#39;F&#39;, &#39;E&#39;), (&#39;G&#39;, &#39;H&#39;)]
</pre></div></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">MmhcEstimator.estimate()</span></code> is a shorthand for both steps and directly estimates a <code class="docutils literal notranslate"><span class="pre">BayesianModel</span></code>.</p>
</section>
<section id="Conclusion">
<h4><span class="section-number">10.2.4.2. </span>Conclusion<a class="headerlink" href="#Conclusion" title="Permalink to this headline">¶</a></h4>
<p>This notebook aimed to give an overview of pgmpy’s estimators for learning Bayesian network structure and parameters. For more information about the individual functions see their docstring documentation. If you used pgmpy’s structure learning features to satisfactorily learn a non-trivial network from real data, feel free to drop us an eMail via the mailing list or just open a Github issue. We’d like to put your network in the examples-section!</p>
</section>
<section id="References">
<h4><span class="section-number">10.2.4.3. </span>References<a class="headerlink" href="#References" title="Permalink to this headline">¶</a></h4>
<p>[1] Koller &amp; Friedman, Probabilistic Graphical Models - Principles and Techniques, 2009</p>
<p>[2] Neapolitan, <a class="reference external" href="http://www.cs.technion.ac.il/~dang/books/Learning%20Bayesian%20Networks(Neapolitan,%20Richard).pdf">Learning Bayesian Networks</a>, 2003</p>
<p>[3] Tsamardinos et al., <a class="reference external" href="http://www.dsl-lab.org/supplements/mmhc_paper/paper_online.pdf">The max-min hill-climbing BN structure learning algorithm</a>, 2005</p>
</section>
</section>
</section>
</section>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="11.%20A%20Bayesian%20Network%20to%20model%20the%20influence%20of%20energy%20consumption%20on%20greenhouse%20gases%20in%20Italy.html" class="btn btn-neutral float-right" title="11. A Bayesian Network to model the influence of energy consumption on greenhouse gases in Italy" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="9.%20Reading%20and%20Writing%20from%20pgmpy%20file%20formats.html" class="btn btn-neutral float-left" title="9. Reading and Writing from pgmpy file formats" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Ankur Ankan.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-177825880-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>