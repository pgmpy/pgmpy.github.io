<!DOCTYPE html>

<html lang="en" data-content_root="../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>pgmpy.models.LinearGaussianBayesianNetwork &#8212; 1.0.0 | pgmpy docs</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/alabaster.css?v=7b53859b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <script src="../../../_static/documentation_options.js?v=8d563738"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://pgmpy.org/_modules/pgmpy/models/LinearGaussianBayesianNetwork.html" />
    <link rel="icon" href="../../../_static/logo_favi.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for pgmpy.models.LinearGaussianBayesianNetwork</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Hashable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Set</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="kn">from</span> <span class="nn">pgmpy.base</span> <span class="kn">import</span> <span class="n">DAG</span>
<span class="kn">from</span> <span class="nn">pgmpy.factors.continuous</span> <span class="kn">import</span> <span class="n">LinearGaussianCPD</span>
<span class="kn">from</span> <span class="nn">pgmpy.global_vars</span> <span class="kn">import</span> <span class="n">logger</span>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork">[docs]</a>
<span class="k">class</span> <span class="nc">LinearGaussianBayesianNetwork</span><span class="p">(</span><span class="n">DAG</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A linear Gaussian Bayesian Network is a Bayesian Network, all</span>
<span class="sd">    of whose variables are continuous, and where all of the CPDs</span>
<span class="sd">    are linear Gaussians.</span>

<span class="sd">    An important result is that the linear Gaussian Bayesian Networks</span>
<span class="sd">    are an alternative representation for the class of multivariate</span>
<span class="sd">    Gaussian distributions.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">ebunch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Hashable</span><span class="p">,</span> <span class="n">Hashable</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">latents</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Hashable</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(),</span>
        <span class="n">lavaan_str</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dagitty_str</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearGaussianBayesianNetwork</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">ebunch</span><span class="o">=</span><span class="n">ebunch</span><span class="p">,</span>
            <span class="n">latents</span><span class="o">=</span><span class="n">latents</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span> <span class="o">=</span> <span class="p">[]</span>

<div class="viewcode-block" id="LinearGaussianBayesianNetwork.add_cpds">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.add_cpds">[docs]</a>
    <span class="k">def</span> <span class="nf">add_cpds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">cpds</span><span class="p">:</span> <span class="n">LinearGaussianCPD</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add linear Gaussian CPD (Conditional Probability Distribution)</span>
<span class="sd">        to the Bayesian Network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        cpds  :  instances of LinearGaussianCPD</span>
<span class="sd">            List of LinearGaussianCPDs which will be associated with the model</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.continuous import LinearGaussianCPD</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork([(&quot;x1&quot;, &quot;x2&quot;), (&quot;x2&quot;, &quot;x3&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; cpd1 = LinearGaussianCPD(&quot;x1&quot;, [1], 4)</span>
<span class="sd">        &gt;&gt;&gt; cpd2 = LinearGaussianCPD(&quot;x2&quot;, [-5, 0.5], 4, [&quot;x1&quot;])</span>
<span class="sd">        &gt;&gt;&gt; cpd3 = LinearGaussianCPD(&quot;x3&quot;, [4, -1], 3, [&quot;x2&quot;])</span>
<span class="sd">        &gt;&gt;&gt; model.add_cpds(cpd1, cpd2, cpd3)</span>
<span class="sd">        &gt;&gt;&gt; for cpd in model.cpds:</span>
<span class="sd">        ...     print(cpd)</span>
<span class="sd">        ...</span>
<span class="sd">        P(x1) = N(1; 4)</span>
<span class="sd">        P(x2| x1) = N(0.5*x1_mu); -5)</span>
<span class="sd">        P(x3| x2) = N(-1*x2_mu); 4)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="n">cpds</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cpd</span><span class="p">,</span> <span class="n">LinearGaussianCPD</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only LinearGaussianCPD can be added.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">cpd</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">cpd</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;CPD defined on variable not in the model&quot;</span><span class="p">,</span> <span class="n">cpd</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">prev_cpd_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cpds</span><span class="p">)):</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span><span class="p">[</span><span class="n">prev_cpd_index</span><span class="p">]</span><span class="o">.</span><span class="n">variable</span> <span class="o">==</span> <span class="n">cpd</span><span class="o">.</span><span class="n">variable</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Replacing existing CPD for </span><span class="si">{</span><span class="n">cpd</span><span class="o">.</span><span class="n">variable</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span><span class="p">[</span><span class="n">prev_cpd_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">cpd</span>
                    <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cpd</span><span class="p">)</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.get_cpds">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.get_cpds">[docs]</a>
    <span class="k">def</span> <span class="nf">get_cpds</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Hashable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">LinearGaussianCPD</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">LinearGaussianCPD</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the cpd of the node. If node is not specified returns all the CPDs</span>
<span class="sd">        that have been added till now to the graph</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        node: any hashable python object (optional)</span>
<span class="sd">            The node whose CPD we want. If node not specified returns all the</span>
<span class="sd">            CPDs added to the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        A list of linear Gaussian CPDs.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.continuous import LinearGaussianCPD</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork([(&quot;x1&quot;, &quot;x2&quot;), (&quot;x2&quot;, &quot;x3&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; cpd1 = LinearGaussianCPD(&quot;x1&quot;, [1], 4)</span>
<span class="sd">        &gt;&gt;&gt; cpd2 = LinearGaussianCPD(&quot;x2&quot;, [-5, 0.5], 4, [&quot;x1&quot;])</span>
<span class="sd">        &gt;&gt;&gt; cpd3 = LinearGaussianCPD(&quot;x3&quot;, [4, -1], 3, [&quot;x2&quot;])</span>
<span class="sd">        &gt;&gt;&gt; model.add_cpds(cpd1, cpd2, cpd3)</span>
<span class="sd">        &gt;&gt;&gt; model.get_cpds()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">node</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">node</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Node not present in the Directed Graph&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">cpd</span><span class="o">.</span><span class="n">variable</span> <span class="o">==</span> <span class="n">node</span><span class="p">:</span>
                        <span class="k">return</span> <span class="n">cpd</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.remove_cpds">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.remove_cpds">[docs]</a>
    <span class="k">def</span> <span class="nf">remove_cpds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">cpds</span><span class="p">:</span> <span class="n">LinearGaussianCPD</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Removes the cpds that are provided in the argument.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        *cpds: LinearGaussianCPD object</span>
<span class="sd">            A LinearGaussianCPD object on any subset of the variables</span>
<span class="sd">            of the model which is to be associated with the model.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.continuous import LinearGaussianCPD</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork([(&quot;x1&quot;, &quot;x2&quot;), (&quot;x2&quot;, &quot;x3&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; cpd1 = LinearGaussianCPD(&quot;x1&quot;, [1], 4)</span>
<span class="sd">        &gt;&gt;&gt; cpd2 = LinearGaussianCPD(&quot;x2&quot;, [-5, 0.5], 4, [&quot;x1&quot;])</span>
<span class="sd">        &gt;&gt;&gt; cpd3 = LinearGaussianCPD(&quot;x3&quot;, [4, -1], 3, [&quot;x2&quot;])</span>
<span class="sd">        &gt;&gt;&gt; model.add_cpds(cpd1, cpd2, cpd3)</span>
<span class="sd">        &gt;&gt;&gt; for cpd in model.get_cpds():</span>
<span class="sd">        ...     print(cpd)</span>
<span class="sd">        ...</span>

<span class="sd">        P(x1) = N(1; 4)</span>
<span class="sd">        P(x2| x1) = N(0.5*x1_mu); -5)</span>
<span class="sd">        P(x3| x2) = N(-1*x2_mu); 4)</span>

<span class="sd">        &gt;&gt;&gt; model.remove_cpds(cpd2, cpd3)</span>
<span class="sd">        &gt;&gt;&gt; for cpd in model.get_cpds():</span>
<span class="sd">        ...     print(cpd)</span>
<span class="sd">        ...</span>

<span class="sd">        P(x1) = N(1; 4)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="n">cpds</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cpd</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
                <span class="n">cpd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">(</span><span class="n">cpd</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">cpd</span><span class="p">)</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.get_random_cpds">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.get_random_cpds">[docs]</a>
    <span class="k">def</span> <span class="nf">get_random_cpds</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">loc</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">LinearGaussianCPD</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates random Linear Gaussian CPDs for the model. The coefficients</span>
<span class="sd">        are sampled from a normal distribution with mean `loc` and standard</span>
<span class="sd">        deviation `scale`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        loc: float</span>
<span class="sd">            The mean of the normal distribution from which the coefficients are</span>
<span class="sd">            sampled.</span>

<span class="sd">        scale: float</span>
<span class="sd">            The standard deviation of the normal distribution from which the</span>
<span class="sd">            coefficients are sampled.</span>

<span class="sd">        inplace: bool (default: False)</span>
<span class="sd">            If inplace=True, adds the generated LinearGaussianCPDs to `model` itself,</span>
<span class="sd">            else creates a copy of the model.</span>

<span class="sd">        seed: int</span>
<span class="sd">            The seed for the random number generator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># We want to provide a different seed for each cpd, therefore we force it to be integer and increment in a loop.</span>
        <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span> <span class="k">if</span> <span class="n">seed</span> <span class="k">else</span> <span class="mi">42</span>

        <span class="n">cpds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">()):</span>
            <span class="n">parents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_parents</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
            <span class="n">cpds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">LinearGaussianCPD</span><span class="o">.</span><span class="n">get_random</span><span class="p">(</span>
                    <span class="n">variable</span><span class="o">=</span><span class="n">var</span><span class="p">,</span>
                    <span class="n">evidence</span><span class="o">=</span><span class="n">parents</span><span class="p">,</span>
                    <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span>
                    <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span>
                    <span class="n">seed</span><span class="o">=</span><span class="p">(</span><span class="n">seed</span> <span class="o">+</span> <span class="n">i</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_cpds</span><span class="p">(</span><span class="o">*</span><span class="n">cpds</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">cpds</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.to_joint_gaussian">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.to_joint_gaussian">[docs]</a>
    <span class="k">def</span> <span class="nf">to_joint_gaussian</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Linear Gaussian Bayesian Networks can be represented using a joint</span>
<span class="sd">        Gaussian distribution over all the variables. This method gives</span>
<span class="sd">        the mean and covariance of this equivalent joint gaussian distribution.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        mean, cov: np.ndarray, np.ndarray</span>
<span class="sd">            The mean and the covariance matrix of the joint gaussian distribution.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.continuous import LinearGaussianCPD</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork([(&quot;x1&quot;, &quot;x2&quot;), (&quot;x2&quot;, &quot;x3&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; cpd1 = LinearGaussianCPD(&quot;x1&quot;, [1], 4)</span>
<span class="sd">        &gt;&gt;&gt; cpd2 = LinearGaussianCPD(&quot;x2&quot;, [-5, 0.5], 4, [&quot;x1&quot;])</span>
<span class="sd">        &gt;&gt;&gt; cpd3 = LinearGaussianCPD(&quot;x3&quot;, [4, -1], 3, [&quot;x2&quot;])</span>
<span class="sd">        &gt;&gt;&gt; model.add_cpds(cpd1, cpd2, cpd3)</span>
<span class="sd">        &gt;&gt;&gt; mean, cov = model.to_joint_gaussian()</span>
<span class="sd">        &gt;&gt;&gt; mean</span>
<span class="sd">        array([ 1. ], [-4.5], [ 8.5])</span>
<span class="sd">        &gt;&gt;&gt; cov</span>
<span class="sd">        array([[ 4.,  2., -2.],</span>
<span class="sd">               [ 2.,  5., -5.],</span>
<span class="sd">               [-2., -5.,  8.]])</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">variables</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">topological_sort</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="n">var_to_index</span> <span class="o">=</span> <span class="p">{</span><span class="n">var</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">variables</span><span class="p">)}</span>
        <span class="n">n_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>

        <span class="c1"># Step 1: Compute the mean for each variable.</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">:</span>
            <span class="n">cpd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">(</span><span class="n">node</span><span class="o">=</span><span class="n">var</span><span class="p">)</span>
            <span class="n">mean</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">cpd</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">mean</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">cpd</span><span class="o">.</span><span class="n">evidence</span><span class="p">]))</span>
            <span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">mean</span><span class="p">[</span><span class="n">u</span><span class="p">]</span> <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">])</span>

        <span class="c1"># Step 2: Populate the adjacency matrix, and variance matrix</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">))</span>
        <span class="n">omega</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">:</span>
            <span class="n">cpd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">(</span><span class="n">node</span><span class="o">=</span><span class="n">var</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">evidence_var</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cpd</span><span class="o">.</span><span class="n">evidence</span><span class="p">):</span>
                <span class="n">B</span><span class="p">[</span><span class="n">var_to_index</span><span class="p">[</span><span class="n">evidence_var</span><span class="p">],</span> <span class="n">var_to_index</span><span class="p">[</span><span class="n">var</span><span class="p">]]</span> <span class="o">=</span> <span class="n">cpd</span><span class="o">.</span><span class="n">beta</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">omega</span><span class="p">[</span><span class="n">var_to_index</span><span class="p">[</span><span class="n">var</span><span class="p">],</span> <span class="n">var_to_index</span><span class="p">[</span><span class="n">var</span><span class="p">]]</span> <span class="o">=</span> <span class="n">cpd</span><span class="o">.</span><span class="n">std</span>

        <span class="c1"># Step 3: Compute the implied covariance matrix</span>
        <span class="n">identity_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">)</span>
        <span class="n">inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">((</span><span class="n">identity_matrix</span> <span class="o">-</span> <span class="n">B</span><span class="p">))</span>
        <span class="n">implied_cov</span> <span class="o">=</span> <span class="n">inv</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">omega</span> <span class="o">@</span> <span class="n">inv</span>

        <span class="c1"># Round because numerical errors can lead to non-symmetric cov matrix.</span>
        <span class="k">return</span> <span class="n">mean</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">decimals</span><span class="o">=</span><span class="mi">8</span><span class="p">),</span> <span class="n">implied_cov</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">decimals</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.copy">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.copy">[docs]</a>
    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a copy of the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Model&#39;s copy: pgmpy.models.LinearGaussianBayesianNetwork</span>
<span class="sd">            Copy of the model on which the method was called.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.continuous import LinearGaussianCPD</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork([(&quot;A&quot;, &quot;B&quot;), (&quot;B&quot;, &quot;C&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; cpd_a = LinearGaussianCPD(variable=&quot;A&quot;, beta=[1], std=4)</span>
<span class="sd">        &gt;&gt;&gt; cpd_b = LinearGaussianCPD(</span>
<span class="sd">        ...     variable=&quot;B&quot;, beta=[-5, 0.5], std=4, evidence=[&quot;A&quot;]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; cpd_c = LinearGaussianCPD(</span>
<span class="sd">        ...     variable=&quot;C&quot;, beta=[4, -1], std=3, evidence=[&quot;x2&quot;]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; model.add_cpds(cpd_a, cpd_b, cpd_c)</span>
<span class="sd">        &gt;&gt;&gt; copy_model = model.copy()</span>
<span class="sd">        &gt;&gt;&gt; copy_model.nodes()</span>
<span class="sd">        NodeView((&#39;A&#39;, &#39;B&#39;, &#39;C&#39;))</span>
<span class="sd">        &gt;&gt;&gt; copy_model.edges()</span>
<span class="sd">        OutEdgeView([(&#39;A&#39;, &#39;B&#39;), (&#39;B&#39;, &#39;C&#39;)])</span>
<span class="sd">        &gt;&gt;&gt; len(copy_model.get_cpds())</span>
<span class="sd">        3</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model_copy</span> <span class="o">=</span> <span class="n">LinearGaussianBayesianNetwork</span><span class="p">()</span>
        <span class="n">model_copy</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
        <span class="n">model_copy</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="p">())</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span><span class="p">:</span>
            <span class="n">model_copy</span><span class="o">.</span><span class="n">add_cpds</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">cpd</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpds</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">model_copy</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.simulate">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.simulate">[docs]</a>
    <span class="k">def</span> <span class="nf">simulate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">do</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">evidence</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">virtual_intervention</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">LinearGaussianCPD</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">include_latents</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Simulates data from the given model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_samples: int</span>
<span class="sd">            The number of samples to draw from the model.</span>

<span class="sd">        do: dict (default: None)</span>
<span class="sd">            The interventions to apply to the model. dict should be of the form</span>
<span class="sd">            {variable_name: value}</span>

<span class="sd">        evidence: dict (default: None)</span>
<span class="sd">            Observed evidence to apply to the model. dict should be of the form</span>
<span class="sd">            {variable_name: value}</span>

<span class="sd">        virtual_intervention: list</span>
<span class="sd">            Also known as soft intervention. `virtual_intervention` should be a list</span>
<span class="sd">            of `pgmpy.factors.discrete.LinearGaussianCPD` objects specifying the virtual/soft</span>
<span class="sd">            intervention probabilities.</span>

<span class="sd">        include_latents: boolean</span>
<span class="sd">            Whether to include the latent variable values in the generated samples.</span>

<span class="sd">        seed: int (default: None)</span>
<span class="sd">            Seed for the random number generator.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        pandas.DataFrame: generated samples</span>
<span class="sd">            A pandas data frame with the generated samples.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.factors.continuous import LinearGaussianCPD</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork([(&quot;x1&quot;, &quot;x2&quot;), (&quot;x2&quot;, &quot;x3&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; cpd1 = LinearGaussianCPD(&quot;x1&quot;, [1], 4)</span>
<span class="sd">        &gt;&gt;&gt; cpd2 = LinearGaussianCPD(&quot;x2&quot;, [-5, 0.5], 4, [&quot;x1&quot;])</span>
<span class="sd">        &gt;&gt;&gt; cpd3 = LinearGaussianCPD(&quot;x3&quot;, [4, -1], 3, [&quot;x2&quot;])</span>
<span class="sd">        &gt;&gt;&gt; model.add_cpds(cpd1, cpd2, cpd3)</span>

<span class="sd">        Simple forward sampling</span>
<span class="sd">        &gt;&gt;&gt; model.simulate(n_samples=3, seed=42)</span>

<span class="sd">        Sampling with intervention (do)</span>
<span class="sd">        &gt;&gt;&gt; model.simulate(n_samples=3, seed=42, do={&quot;x2&quot;: 0.0})</span>

<span class="sd">        Sampling with evidence</span>
<span class="sd">        &gt;&gt;&gt; model.simulate(n_samples=3, seed=42, evidence={&quot;x1&quot;: 2.0})</span>

<span class="sd">        Sampling with both intervention and evidence</span>
<span class="sd">        &gt;&gt;&gt; model.simulate(n_samples=3, seed=42, do={&quot;x2&quot;: 1.0}, evidence={&quot;x1&quot;: 0.0})</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Step 1: Check if all arguments are specified and valid</span>
        <span class="n">evidence</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">evidence</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">evidence</span>

        <span class="n">do</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">do</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">do</span>

        <span class="n">virtual_intervention</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">[]</span> <span class="k">if</span> <span class="n">virtual_intervention</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">virtual_intervention</span>
        <span class="p">)</span>

        <span class="n">do_nodes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">do</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">evidence_nodes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">evidence</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

        <span class="n">invalid_nodes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">do_nodes</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="n">do_nodes</span><span class="p">)</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The following do-nodes are not present in the model: </span><span class="si">{</span><span class="n">invalid_nodes</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;do argument contains: </span><span class="si">{</span><span class="n">do_nodes</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="n">invalid_nodes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">evidence_nodes</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="n">evidence_nodes</span><span class="p">)</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The following evidence-nodes are not present in the model: </span><span class="si">{</span><span class="n">invalid_nodes</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;evidence argument contains: </span><span class="si">{</span><span class="n">evidence_nodes</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">check_model</span><span class="p">()</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">common_vars</span> <span class="o">:=</span> <span class="nb">set</span><span class="p">(</span><span class="n">do</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">&amp;</span> <span class="nb">set</span><span class="p">(</span><span class="n">evidence</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Variable(s) can&#39;t be in both do and evidence: </span><span class="si">{</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">common_vars</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">virtual_intervention</span> <span class="o">!=</span> <span class="p">[]:</span>
            <span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="n">virtual_intervention</span><span class="p">:</span>
                <span class="n">var</span> <span class="o">=</span> <span class="n">cpd</span><span class="o">.</span><span class="n">variable</span>
                <span class="k">if</span> <span class="n">var</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">():</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Virtual intervention provided for variable which is not in the model: </span><span class="si">{</span><span class="n">var</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;The following nodes are present in the model: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

        <span class="c1"># Step 2: If do is specified, modify the network structure.</span>
        <span class="k">if</span> <span class="n">do</span> <span class="o">!=</span> <span class="p">{}:</span>
            <span class="k">for</span> <span class="n">var</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">do</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="c1"># Step 2.1: Remove incoming edges to the intervened</span>
                <span class="c1">#  node as well as remove the CPD&#39;s of the intervened nodes.</span>
                <span class="k">for</span> <span class="n">parent</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_parents</span><span class="p">(</span><span class="n">var</span><span class="p">)):</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">remove_edge</span><span class="p">(</span><span class="n">parent</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>

                <span class="n">model</span><span class="o">.</span><span class="n">remove_cpds</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">(</span><span class="n">var</span><span class="p">))</span>

                <span class="c1"># Step 2.2 : For each children of an intervened node, change its CPD to remove</span>
                <span class="c1">#  the parent (intervened node) from the evidence and update its intercept accordingly</span>
                <span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">get_children</span><span class="p">(</span><span class="n">var</span><span class="p">):</span>
                    <span class="n">child_cpd</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">(</span><span class="n">child</span><span class="p">)</span>

                    <span class="n">new_evidence</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">child_cpd</span><span class="o">.</span><span class="n">evidence</span><span class="p">)</span>
                    <span class="n">new_beta</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">child_cpd</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>

                    <span class="n">parent_idx</span> <span class="o">=</span> <span class="n">child_cpd</span><span class="o">.</span><span class="n">evidence</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
                    <span class="n">new_beta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">new_beta</span><span class="p">[</span><span class="n">parent_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">val</span>

                    <span class="k">del</span> <span class="n">new_evidence</span><span class="p">[</span><span class="n">parent_idx</span><span class="p">]</span>
                    <span class="k">del</span> <span class="n">new_beta</span><span class="p">[</span><span class="n">parent_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>

                    <span class="n">new_cpd</span> <span class="o">=</span> <span class="n">LinearGaussianCPD</span><span class="p">(</span>
                        <span class="n">variable</span><span class="o">=</span><span class="n">child_cpd</span><span class="o">.</span><span class="n">variable</span><span class="p">,</span>
                        <span class="n">beta</span><span class="o">=</span><span class="n">new_beta</span><span class="p">,</span>
                        <span class="n">std</span><span class="o">=</span><span class="n">child_cpd</span><span class="o">.</span><span class="n">std</span><span class="p">,</span>
                        <span class="n">evidence</span><span class="o">=</span><span class="n">new_evidence</span><span class="p">,</span>
                    <span class="p">)</span>

                    <span class="n">model</span><span class="o">.</span><span class="n">remove_cpds</span><span class="p">(</span><span class="n">child_cpd</span><span class="p">)</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">add_cpds</span><span class="p">(</span><span class="n">new_cpd</span><span class="p">)</span>

                <span class="n">model</span><span class="o">.</span><span class="n">remove_node</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>

        <span class="c1"># Step 3: If virtual_interventions are specified, change the CPD&#39;s of intervened variables</span>
        <span class="c1"># to specified ones and remove the incoming nodes</span>
        <span class="k">for</span> <span class="n">cpd</span> <span class="ow">in</span> <span class="n">virtual_intervention</span><span class="p">:</span>
            <span class="n">var</span> <span class="o">=</span> <span class="n">cpd</span><span class="o">.</span><span class="n">variable</span>
            <span class="n">old_cpd</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">remove_cpds</span><span class="p">(</span><span class="n">old_cpd</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add_cpds</span><span class="p">(</span><span class="n">cpd</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">parent</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_parents</span><span class="p">(</span><span class="n">var</span><span class="p">)):</span>
                <span class="n">model</span><span class="o">.</span><span class="n">remove_edge</span><span class="p">(</span><span class="n">parent</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>

        <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to_joint_gaussian</span><span class="p">()</span>
        <span class="n">variables</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">topological_sort</span><span class="p">(</span><span class="n">model</span><span class="p">))</span>

        <span class="c1"># Step 4: Sample according to evidence</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">evidence</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="n">rng</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_samples</span><span class="p">),</span>
                <span class="n">columns</span><span class="o">=</span><span class="n">variables</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">df_evidence</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">evidence</span><span class="p">])</span>
            <span class="n">missing_vars</span><span class="p">,</span> <span class="n">mean_cond</span><span class="p">,</span> <span class="n">cov_cond</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_evidence</span><span class="p">)</span>

            <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">missing_vars</span><span class="p">)</span>
            <span class="n">missing_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">missing_vars</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sorted_indices</span><span class="p">]</span>
            <span class="n">mean_cond</span> <span class="o">=</span> <span class="n">mean_cond</span><span class="p">[:,</span> <span class="n">sorted_indices</span><span class="p">]</span>
            <span class="n">cov_cond</span> <span class="o">=</span> <span class="n">cov_cond</span><span class="p">[</span><span class="n">sorted_indices</span><span class="p">][:,</span> <span class="n">sorted_indices</span><span class="p">]</span>

            <span class="n">samples_missing</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span>
                <span class="n">mean</span><span class="o">=</span><span class="n">mean_cond</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov_cond</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_samples</span>
            <span class="p">)</span>
            <span class="n">df_missing</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">samples_missing</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">missing_vars</span><span class="p">)</span>

            <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">variables</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">ev_var</span><span class="p">,</span> <span class="n">ev_val</span> <span class="ow">in</span> <span class="n">evidence</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">df</span><span class="p">[</span><span class="n">ev_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">ev_val</span>

            <span class="k">for</span> <span class="n">mv</span> <span class="ow">in</span> <span class="n">missing_vars</span><span class="p">:</span>
                <span class="n">df</span><span class="p">[</span><span class="n">mv</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_missing</span><span class="p">[</span><span class="n">mv</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">variables</span><span class="p">]</span>

        <span class="c1"># Step 5: Add do variables to the final dataframe</span>
        <span class="k">for</span> <span class="n">do_var</span><span class="p">,</span> <span class="n">do_val</span> <span class="ow">in</span> <span class="n">do</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">df</span><span class="p">[</span><span class="n">do_var</span><span class="p">]</span> <span class="o">=</span> <span class="n">do_val</span>

        <span class="c1"># Step 6: Remove latent variables if specified</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">include_latents</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">latents</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">df</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.check_model">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.check_model">[docs]</a>
    <span class="k">def</span> <span class="nf">check_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks the model for various errors. This method checks for the following</span>
<span class="sd">        error -</span>

<span class="sd">        * Checks if the CPDs associated with nodes are consistent with their parents.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        check: boolean</span>
<span class="sd">            True if all the checks pass.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">():</span>
            <span class="n">cpd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_cpds</span><span class="p">(</span><span class="n">node</span><span class="o">=</span><span class="n">node</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cpd</span><span class="p">,</span> <span class="n">LinearGaussianCPD</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">cpd</span><span class="o">.</span><span class="n">evidence</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_parents</span><span class="p">(</span><span class="n">node</span><span class="p">)):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;CPD associated with </span><span class="si">%s</span><span class="s2"> doesn&#39;t have &quot;</span>
                        <span class="s2">&quot;proper parents associated with it.&quot;</span> <span class="o">%</span> <span class="n">node</span>
                    <span class="p">)</span>
        <span class="k">return</span> <span class="kc">True</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.get_cardinality">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.get_cardinality">[docs]</a>
    <span class="k">def</span> <span class="nf">get_cardinality</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Cardinality is not defined for continuous variables.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cardinality is not defined for continuous variables.&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.fit">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.fit">[docs]</a>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;mle&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;LinearGaussianBayesianNetwork&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Estimates the parameters of the model using the given `data`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data: pd.DataFrame</span>
<span class="sd">            A pandas DataFrame with the data to which to fit the model</span>
<span class="sd">            structure. All variables must be continuous valued.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        None: The estimated LinearGaussianCPDs are added to the model. They can</span>
<span class="sd">            be accessed using `model.cpds`.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; df = pd.DataFrame(</span>
<span class="sd">        ...     np.random.normal(0, 1, (100, 3)), columns=[&quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;]</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork([(&quot;x1&quot;, &quot;x2&quot;), (&quot;x2&quot;, &quot;x3&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; model.fit(df)</span>
<span class="sd">        &gt;&gt;&gt; model.cpds</span>
<span class="sd">        [&lt;LinearGaussianCPD: P(x1) = N(-0.114; 0.911) at 0x7eb77d30cec0,</span>
<span class="sd">         &lt;LinearGaussianCPD: P(x2 | x1) = N(0.07*x1 + -0.075; 1.172) at 0x7eb77171fb60,</span>
<span class="sd">         &lt;LinearGaussianCPD: P(x3 | x2) = N(0.006*x2 + -0.1; 0.922) at 0x7eb6abbdba10]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Step 1: Check the input</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">missing_vars</span> <span class="o">:=</span> <span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">)))</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Following variables are missing in the data: </span><span class="si">{</span><span class="n">missing_vars</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Step 2: Estimate the LinearGaussianCPDs</span>
        <span class="n">cpds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">():</span>
            <span class="n">parents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_parents</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

            <span class="c1"># Step 2.1: If node doesn&#39;t have any parents (i.e. root node),</span>
            <span class="c1">#           simply take the mean and variance.</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">cpds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">LinearGaussianCPD</span><span class="p">(</span>
                        <span class="n">variable</span><span class="o">=</span><span class="n">node</span><span class="p">,</span>
                        <span class="n">beta</span><span class="o">=</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">node</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()],</span>
                        <span class="n">std</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">node</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">(),</span>
                    <span class="p">)</span>
                <span class="p">)</span>

            <span class="c1"># Step 2.2: Else, fit a linear regression model and take the coefficients and intercept.</span>
            <span class="c1">#           Compute error variance using predicted values.</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">lm</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">parents</span><span class="p">],</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">node</span><span class="p">])</span>
                <span class="n">error_var</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">node</span><span class="p">]</span> <span class="o">-</span> <span class="n">lm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">parents</span><span class="p">]))</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
                <span class="n">cpds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">LinearGaussianCPD</span><span class="p">(</span>
                        <span class="n">variable</span><span class="o">=</span><span class="n">node</span><span class="p">,</span>
                        <span class="n">beta</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">lm</span><span class="o">.</span><span class="n">intercept_</span><span class="p">],</span> <span class="n">lm</span><span class="o">.</span><span class="n">coef_</span><span class="p">),</span>
                        <span class="n">std</span><span class="o">=</span><span class="n">error_var</span><span class="p">,</span>
                        <span class="n">evidence</span><span class="o">=</span><span class="n">parents</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>

        <span class="c1"># Step 3: Add the estimated CPDs to the model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_cpds</span><span class="p">(</span><span class="o">*</span><span class="n">cpds</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.predict">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.predict">[docs]</a>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">distribution</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;joint&quot;</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predicts the distribution of the missing variable (i.e. missing columns) in the given dataset.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data: pandas.DataFrame</span>
<span class="sd">            The dataframe with missing variable which to predict.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        variables: list</span>
<span class="sd">            The list of variables on which the returned conditional distribution is defined on.</span>

<span class="sd">        mu: np.array</span>
<span class="sd">            The mean array of the conditional joint distribution over</span>
<span class="sd">              the missing variables corresponding to each row of data.</span>

<span class="sd">        cov: np.array</span>
<span class="sd">            The covariance of the conditional joint distribution over the missing variables.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.utils import get_example_model</span>
<span class="sd">        &gt;&gt;&gt; model = get_example_model(&quot;ecoli70&quot;)</span>
<span class="sd">        &gt;&gt;&gt; df = model.simulate(n_samples=5)</span>
<span class="sd">        &gt;&gt;&gt; # Drop a column that we want to predict.</span>
<span class="sd">        &gt;&gt;&gt; df = df.drop(columns=[&quot;folK&quot;], axis=1, inplace=True)</span>
<span class="sd">        &gt;&gt;&gt; model.predict(df)</span>
<span class="sd">        ([&#39;folK&#39;], array([[0.38194262], [3.06014724], [1.36829103], [0.89197438], [2.98887488]]),</span>
<span class="sd">                   array([[0.13440001]]))</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Step 0: Check the inputs</span>
        <span class="n">missing_vars</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">missing_vars</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No missing variables in the data&quot;</span><span class="p">)</span>

        <span class="c1"># Step 1: Create separate mean and cov matrices for missing and known variables.</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_joint_gaussian</span><span class="p">()</span>
        <span class="n">variable_order</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">topological_sort</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="n">missing_indexes</span> <span class="o">=</span> <span class="p">[</span><span class="n">variable_order</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">missing_vars</span><span class="p">]</span>
        <span class="n">remain_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">variable_order</span> <span class="k">if</span> <span class="n">var</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">missing_vars</span><span class="p">]</span>

        <span class="n">mu_a</span> <span class="o">=</span> <span class="n">mu</span><span class="p">[</span><span class="n">missing_indexes</span><span class="p">]</span>
        <span class="n">mu_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">missing_indexes</span><span class="p">)</span>

        <span class="n">cov_aa</span> <span class="o">=</span> <span class="n">cov</span><span class="p">[</span><span class="n">missing_indexes</span><span class="p">,</span> <span class="n">missing_indexes</span><span class="p">]</span>
        <span class="n">cov_bb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">missing_indexes</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">missing_indexes</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">cov_ab</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">cov</span><span class="p">[</span><span class="n">missing_indexes</span><span class="p">,</span> <span class="p">:],</span> <span class="n">missing_indexes</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Step 2: Compute the conditional distributions</span>
        <span class="n">cov_bb_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">cov_bb</span><span class="p">)</span>
        <span class="n">mu_cond</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">mu_a</span><span class="p">)</span>
            <span class="o">+</span> <span class="p">(</span>
                <span class="n">cov_ab</span>
<div class="viewcode-block" id="LinearGaussianBayesianNetwork.to_markov_model">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.to_markov_model">[docs]</a>
                <span class="o">@</span> <span class="n">cov_bb_inv</span>
                <span class="o">@</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">remain_vars</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">mu_b</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
            <span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="p">)</span>
        <span class="n">cov_cond</span> <span class="o">=</span> <span class="n">cov_aa</span> <span class="o">-</span> <span class="n">cov_ab</span> <span class="o">@</span> <span class="n">cov_bb_inv</span> <span class="o">@</span> <span class="n">cov_ab</span><span class="o">.</span><span class="n">T</span>

        <span class="c1"># Step 3: Return values</span>
        <span class="k">return</span> <span class="p">([</span><span class="n">variable_order</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">missing_indexes</span><span class="p">],</span> <span class="n">mu_cond</span><span class="p">,</span> <span class="n">cov_cond</span><span class="p">)</span></div>


    <span class="k">def</span> <span class="nf">to_markov_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        For now, to_markov_model method has not been implemented for LinearGaussianBayesianNetwork.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;to_markov_model method has not been implemented for LinearGaussianBayesianNetwork.&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.is_imap">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.is_imap">[docs]</a>
    <span class="k">def</span> <span class="nf">is_imap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">JPD</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        For now, is_imap method has not been implemented for LinearGaussianBayesianNetwork.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s2">&quot;is_imap method has not been implemented for LinearGaussianBayesianNetwork.&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="LinearGaussianBayesianNetwork.get_random">
<a class="viewcode-back" href="../../../models/gaussianbn.html#pgmpy.models.LinearGaussianBayesianNetwork.LinearGaussianBayesianNetwork.get_random">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">get_random</span><span class="p">(</span>
        <span class="n">n_nodes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">edge_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">node_names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">latents</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">loc</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;LinearGaussianBayesianNetwork&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a randomly generated Linear Gaussian Bayesian Network on `n_nodes` variables</span>
<span class="sd">        with edge probabiliy of `edge_prob` between variables.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_nodes: int</span>
<span class="sd">            The number of nodes in the randomly generated DAG.</span>

<span class="sd">        edge_prob: float</span>
<span class="sd">            The probability of edge between any two nodes in the topologically</span>
<span class="sd">            sorted DAG.</span>

<span class="sd">        node_names: list (default: None)</span>
<span class="sd">            A list of variables names to use in the random graph.</span>
<span class="sd">            If None, the node names are integer values starting from 0.</span>

<span class="sd">        latents: bool (default: False)</span>
<span class="sd">            If True, also creates latent variables.</span>

<span class="sd">        loc: float</span>
<span class="sd">            The mean of the normal distribution from which the coefficients are</span>
<span class="sd">            sampled.</span>

<span class="sd">        scale: float</span>
<span class="sd">            The standard deviation of the normal distribution from which the</span>
<span class="sd">            coefficients are sampled.</span>

<span class="sd">        seed: int</span>
<span class="sd">            The seed for the random number generator.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Random DAG: pgmpy.base.DAG</span>
<span class="sd">            The randomly generated DAG.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import LinearGaussianBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; model = LinearGaussianBayesianNetwork.get_random(n_nodes=5)</span>
<span class="sd">        &gt;&gt;&gt; model.nodes()</span>
<span class="sd">        NodeView((0, 3, 1, 2, 4))</span>
<span class="sd">        &gt;&gt;&gt; model.edges()</span>
<span class="sd">        OutEdgeView([(0, 3), (3, 4), (1, 3), (2, 4)])</span>
<span class="sd">        &gt;&gt;&gt; model.cpds</span>
<span class="sd">        [&lt;LinearGaussianCPD: P(0) = N(1.764; 1.613) at 0x2732f41aae0,</span>
<span class="sd">        &lt;LinearGaussianCPD: P(3 | 0, 1) = N(-0.721*0 + -0.079*1 + 0.943; 0.12) at 0x2732f16db20,</span>
<span class="sd">        &lt;LinearGaussianCPD: P(1) = N(-0.534; 0.208) at 0x2732f320b30,</span>
<span class="sd">        &lt;LinearGaussianCPD: P(2) = N(-0.023; 0.166) at 0x2732d8d5f40,</span>
<span class="sd">        &lt;LinearGaussianCPD: P(4 | 2, 3) = N(-0.24*2 + -0.907*3 + 0.625; 0.48) at 0x2737fecdaf0]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dag</span> <span class="o">=</span> <span class="n">DAG</span><span class="o">.</span><span class="n">get_random</span><span class="p">(</span>
            <span class="n">n_nodes</span><span class="o">=</span><span class="n">n_nodes</span><span class="p">,</span> <span class="n">edge_prob</span><span class="o">=</span><span class="n">edge_prob</span><span class="p">,</span> <span class="n">node_names</span><span class="o">=</span><span class="n">node_names</span><span class="p">,</span> <span class="n">latents</span><span class="o">=</span><span class="n">latents</span>
        <span class="p">)</span>
        <span class="n">lgbn_model</span> <span class="o">=</span> <span class="n">LinearGaussianBayesianNetwork</span><span class="p">(</span><span class="n">dag</span><span class="o">.</span><span class="n">edges</span><span class="p">(),</span> <span class="n">latents</span><span class="o">=</span><span class="n">dag</span><span class="o">.</span><span class="n">latents</span><span class="p">)</span>
        <span class="n">lgbn_model</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">(</span><span class="n">dag</span><span class="o">.</span><span class="n">nodes</span><span class="p">())</span>

        <span class="n">cpds</span> <span class="o">=</span> <span class="n">lgbn_model</span><span class="o">.</span><span class="n">get_random_cpds</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

        <span class="n">lgbn_model</span><span class="o">.</span><span class="n">add_cpds</span><span class="p">(</span><span class="o">*</span><span class="n">cpds</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lgbn_model</span></div>
</div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../../../index.html">
    <img class="logo" src="../../../_static/logo.png" alt="Logo" />
    
  </a>
</p>









<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../started/base.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/base.html">Supported Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../factors/base.html">Parameterization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../infer/base.html">Probabilistic Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../causal_infer/base.html">Causal Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../param_estimator/base.html">Parameter Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../structure_estimator/base.html">Causal Discovery / Structure Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../metrics/metrics.html">Metrics for Testing Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../readwrite/base.html">Reading/Writing to File</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../plotting.html">Plotting Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial.html">Tutorial Notebooks</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  <li><a href="../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div><script async src="https://media.ethicalads.io/media/client/ethicalads.min.js"></script>

<div data-ea-publisher="pgmpyorg" data-ea-type="image" data-ea-style="horizontal"></div><script async src="https://www.googletagmanager.com/gtag/js?id=G-HCFR07M31W"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-HCFR07M31W');
</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2025, Ankur Ankan.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.2.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
    </div>

    

    
  </body>
</html>