<!DOCTYPE html>

<html lang="en" data-content_root="../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>pgmpy.estimators.StructureScore &#8212; 1.0.0 | pgmpy docs</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/alabaster.css?v=7b53859b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <script src="../../../_static/documentation_options.js?v=8d563738"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://pgmpy.org/_modules/pgmpy/estimators/StructureScore.html" />
    <link rel="icon" href="../../../_static/logo_favi.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for pgmpy.estimators.StructureScore</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">lgamma</span><span class="p">,</span> <span class="n">log</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">gammaln</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multivariate_normal</span>

<span class="kn">from</span> <span class="nn">pgmpy.estimators</span> <span class="kn">import</span> <span class="n">BaseEstimator</span>
<span class="kn">from</span> <span class="nn">pgmpy.utils</span> <span class="kn">import</span> <span class="n">get_dataset_type</span>


<span class="k">def</span> <span class="nf">get_scoring_method</span><span class="p">(</span>
    <span class="n">scoring_method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;StructureScore&quot;</span><span class="p">]],</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">use_cache</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="s2">&quot;StructureScore&quot;</span><span class="p">,</span> <span class="s2">&quot;StructureScore&quot;</span><span class="p">]:</span>
    <span class="n">available_methods</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;continuous&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;ll-g&quot;</span><span class="p">:</span> <span class="n">LogLikelihoodGauss</span><span class="p">,</span>
            <span class="s2">&quot;aic-g&quot;</span><span class="p">:</span> <span class="n">AICGauss</span><span class="p">,</span>
            <span class="s2">&quot;bic-g&quot;</span><span class="p">:</span> <span class="n">BICGauss</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;discrete&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;k2&quot;</span><span class="p">:</span> <span class="n">K2</span><span class="p">,</span>
            <span class="s2">&quot;bdeu&quot;</span><span class="p">:</span> <span class="n">BDeu</span><span class="p">,</span>
            <span class="s2">&quot;bds&quot;</span><span class="p">:</span> <span class="n">BDs</span><span class="p">,</span>
            <span class="s2">&quot;bic-d&quot;</span><span class="p">:</span> <span class="n">BIC</span><span class="p">,</span>
            <span class="s2">&quot;aic-d&quot;</span><span class="p">:</span> <span class="n">AIC</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;mixed&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;ll-cg&quot;</span><span class="p">:</span> <span class="n">LogLikelihoodCondGauss</span><span class="p">,</span>
            <span class="s2">&quot;aic-cg&quot;</span><span class="p">:</span> <span class="n">AICCondGauss</span><span class="p">,</span>
            <span class="s2">&quot;bic-cg&quot;</span><span class="p">:</span> <span class="n">BICCondGauss</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">}</span>
    <span class="n">all_available_methods</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">key</span> <span class="k">for</span> <span class="n">subdict</span> <span class="ow">in</span> <span class="n">available_methods</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">subdict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
    <span class="p">]</span>

    <span class="n">var_type</span> <span class="o">=</span> <span class="n">get_dataset_type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">supported_methods</span> <span class="o">=</span> <span class="n">available_methods</span><span class="p">[</span><span class="n">var_type</span><span class="p">]</span> <span class="o">|</span> <span class="n">available_methods</span><span class="p">[</span><span class="s2">&quot;mixed&quot;</span><span class="p">]</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scoring_method</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">scoring_method</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="s2">&quot;k2score&quot;</span><span class="p">,</span>
            <span class="s2">&quot;bdeuscore&quot;</span><span class="p">,</span>
            <span class="s2">&quot;bdsscore&quot;</span><span class="p">,</span>
            <span class="s2">&quot;bicscore&quot;</span><span class="p">,</span>
            <span class="s2">&quot;aicscore&quot;</span><span class="p">,</span>
        <span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The scoring method names have been changed. Please refer the documentation.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">scoring_method</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">all_available_methods</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Unknown scoring method. Please refer documentation for a list of supported score metrics.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">scoring_method</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">supported_methods</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Incorrect scoring method for </span><span class="si">{</span><span class="n">var_type</span><span class="si">}</span><span class="s2">, scoring_method should be one of&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">supported_methods</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">, received </span><span class="si">{</span><span class="n">scoring_method</span><span class="si">}</span><span class="s2">. </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scoring_method</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">)):</span>
        <span class="c1"># automatically determine scoring method, pick first one</span>
        <span class="n">scoring_method</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">available_methods</span><span class="p">[</span><span class="n">var_type</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scoring_method</span><span class="p">,</span> <span class="n">StructureScore</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;scoring_method should either be one of </span><span class="si">{</span><span class="n">all_available_methods</span><span class="si">}</span><span class="s2"> or an instance of StructureScore&quot;</span>
        <span class="p">)</span>

    <span class="n">score</span><span class="p">:</span> <span class="n">StructureScore</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scoring_method</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">supported_methods</span><span class="p">[</span><span class="n">scoring_method</span><span class="o">.</span><span class="n">lower</span><span class="p">()](</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">scoring_method</span>

    <span class="k">if</span> <span class="n">use_cache</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">pgmpy.estimators.ScoreCache</span> <span class="kn">import</span> <span class="n">ScoreCache</span>

        <span class="n">score_c</span> <span class="o">=</span> <span class="n">ScoreCache</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">score_c</span> <span class="o">=</span> <span class="n">score</span>

    <span class="k">return</span> <span class="n">score</span><span class="p">,</span> <span class="n">score_c</span>


<span class="k">class</span> <span class="nc">StructureScore</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract base class for structure scoring in pgmpy.</span>

<span class="sd">    Structure scores are used to evaluate how well a given Bayesian network structure</span>
<span class="sd">    fits observed data. This class should not be used directly. Use one of the derived</span>
<span class="sd">    classes such as `K2`, `BDeu`, `BIC`, or `AIC` for concrete scoring methods.</span>

<span class="sd">    Structure scores are central to model selection in Bayesian networks and are</span>
<span class="sd">    particularly useful when comparing candidate network structures in discrete data scenarios.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame in which each column represents a variable. Missing values should</span>
<span class="sd">        be marked as `numpy.nan`. Note: Columns with `numpy.nan` will have dtype `float`.</span>

<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping each variable name to the set of its discrete states.</span>
<span class="sd">        If not specified, the observed values in the data are used as possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import K2</span>
<span class="sd">    &gt;&gt;&gt; # Create random data sample with 3 variables, where B and C are identical:</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(np.random.randint(0, 5, size=(5000, 2)), columns=list(&quot;AB&quot;))</span>
<span class="sd">    &gt;&gt;&gt; data[&quot;C&quot;] = data[&quot;B&quot;]</span>
<span class="sd">    &gt;&gt;&gt; model1 = DiscreteBayesianNetwork([[&quot;A&quot;, &quot;B&quot;], [&quot;A&quot;, &quot;C&quot;]])</span>
<span class="sd">    &gt;&gt;&gt; model2 = DiscreteBayesianNetwork([[&quot;A&quot;, &quot;B&quot;], [&quot;B&quot;, &quot;C&quot;]])</span>
<span class="sd">    &gt;&gt;&gt; K2(data).score(model1)</span>
<span class="sd">    -24242.367348745247</span>
<span class="sd">    &gt;&gt;&gt; K2(data).score(model2)</span>
<span class="sd">    -16273.793897051042</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - Use this class as a base for implementing custom structure scores.</span>
<span class="sd">    - Use derived classes (`K2`, `BDeu`, `BIC`, `AIC`) for standard scoring approaches.</span>
<span class="sd">    - If you provide data with continuous variables or incompatible states, a `ValueError` may be raised.</span>
<span class="sd">    - For best results, ensure all variables are discrete and states are correctly specified.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If data contains unsupported (non-discrete) types, or if the variables</span>
<span class="sd">        in the model do not match the data columns.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Koller &amp; Friedman, Probabilistic Graphical Models: Principles and Techniques, 2009, Section 18.3.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StructureScore</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes a structure score for a given Bayesian network model.</span>

<span class="sd">        This method evaluates how well the specified `DiscreteBayesianNetwork`</span>
<span class="sd">        fits the observed data, using the structure score metric implemented in the subclass.</span>
<span class="sd">        The higher (or less negative) the score, the better the fit between the model and the data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : DiscreteBayesianNetwork</span>
<span class="sd">            The Bayesian network whose structure is to be scored. All nodes in the</span>
<span class="sd">            model must correspond to columns in the input data.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The computed structure score representing the model&#39;s fit to the data.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.estimators import K2</span>
<span class="sd">        &gt;&gt;&gt; # create random data sample with 3 variables, where B and C are identical:</span>
<span class="sd">        &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">        ...     np.random.randint(0, 5, size=(5000, 2)), columns=list(&quot;AB&quot;)</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; data[&quot;C&quot;] = data[&quot;B&quot;]</span>
<span class="sd">        &gt;&gt;&gt; K2(data).score(DiscreteBayesianNetwork([[&quot;A&quot;, &quot;B&quot;], [&quot;A&quot;, &quot;C&quot;]]))</span>
<span class="sd">        -24242.367348745247</span>
<span class="sd">        &gt;&gt;&gt; K2(data).score(DiscreteBayesianNetwork([[&quot;A&quot;, &quot;B&quot;], [&quot;B&quot;, &quot;C&quot;]]))</span>
<span class="sd">        -16273.793897051042</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the model contains nodes not present in the data columns, or if the</span>
<span class="sd">            data contains unsupported variable types.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">score</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">nodes</span><span class="p">():</span>
            <span class="n">score</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">local_score</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predecessors</span><span class="p">(</span><span class="n">node</span><span class="p">)))</span>
        <span class="n">score</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">structure_prior</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">score</span>

    <span class="k">def</span> <span class="nf">structure_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the (log) prior distribution over Bayesian network structures.</span>

<span class="sd">        This method returns a uniform prior by default and is currently unused in scoring.</span>
<span class="sd">        Override this method in subclasses to implement custom prior distributions</span>
<span class="sd">        over network structures.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : DiscreteBayesianNetwork</span>
<span class="sd">            The Bayesian network model for which the structure prior is to be computed.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        prior : float</span>
<span class="sd">            The log prior probability of the given model structure. By default, returns 0.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.estimators import K2</span>
<span class="sd">        &gt;&gt;&gt; model = DiscreteBayesianNetwork([(&quot;A&quot;, &quot;B&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; score = K2(data)</span>
<span class="sd">        &gt;&gt;&gt; prior = score.structure_prior(model)</span>
<span class="sd">        &gt;&gt;&gt; print(prior)</span>
<span class="sd">        0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">structure_prior_ratio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">operation</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the log ratio of prior probabilities for a proposed change to the model structure.</span>

<span class="sd">        This method returns the log prior probability ratio for a structural operation</span>
<span class="sd">        (e.g., adding, removing, or reversing an edge) in the Bayesian network. By default,</span>
<span class="sd">        it assumes a uniform prior and returns 0, meaning no structural operation is favored.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        operation : tuple or object</span>
<span class="sd">            The proposed operation on the Directed Acyclic Graph (DAG), typically represented as a tuple</span>
<span class="sd">            describing the change (such as (&#39;add&#39;, &#39;A&#39;, &#39;B&#39;) for adding an edge from A to B).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        prior_ratio : float</span>
<span class="sd">            The log ratio of the prior probabilities for the proposed operation. By default, returns 0.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.estimators import K2</span>
<span class="sd">        &gt;&gt;&gt; op = (&quot;add&quot;, &quot;A&quot;, &quot;B&quot;)  # Example operation</span>
<span class="sd">        &gt;&gt;&gt; score = K2(data)</span>
<span class="sd">        &gt;&gt;&gt; ratio = score.structure_prior_ratio(op)</span>
<span class="sd">        &gt;&gt;&gt; print(ratio)</span>
<span class="sd">        0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">0</span>


<div class="viewcode-block" id="K2">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.K2">[docs]</a>
<span class="k">class</span> <span class="nc">K2</span><span class="p">(</span><span class="n">StructureScore</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    K2 structure score for discrete Bayesian networks using Dirichlet priors.</span>

<span class="sd">    The K2 score is commonly used to evaluate the fit of a Bayesian network structure</span>
<span class="sd">    on fully discrete data, assuming all Dirichlet hyperparameters (pseudo-counts) are set to 1.</span>
<span class="sd">    This metric is suitable for structure learning when variables are categorical and no</span>
<span class="sd">    prior preference for particular parameterizations is assumed.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where each column represents a discrete variable. Missing values</span>
<span class="sd">        should be set to `numpy.nan`. (Note: pandas will convert columns with `numpy.nan` to dtype float.)</span>
<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping each variable to its discrete states. If not specified, the unique</span>
<span class="sd">        values observed in the data are used as possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import K2</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame({&quot;A&quot;: [0, 1, 1, 0], &quot;B&quot;: [1, 0, 1, 0], &quot;C&quot;: [1, 1, 1, 0]})</span>
<span class="sd">    &gt;&gt;&gt; model = DiscreteBayesianNetwork([(&quot;A&quot;, &quot;B&quot;), (&quot;A&quot;, &quot;C&quot;)])</span>
<span class="sd">    &gt;&gt;&gt; k2_score = K2(data)</span>
<span class="sd">    &gt;&gt;&gt; print(k2_score.score(model))</span>
<span class="sd">    -356.1785</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the data contains continuous variables, or if the model variables are not present in the data.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Koller &amp; Friedman, Probabilistic Graphical Models - Principles and Techniques, 2009,</span>
<span class="sd">        Section 18.3.4–18.3.6 (esp. page 806).</span>
<span class="sd">    [2] AM Carvalho, Scoring functions for learning Bayesian networks,</span>
<span class="sd">        http://www.lx.it.pt/~asmc/pub/talks/09-TA/ta_pres.pdf</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">K2</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="K2.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.K2.local_score">[docs]</a>
    <span class="k">def</span> <span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local K2 score for a discrete variable and its parent variables.</span>

<span class="sd">        The K2 local score measures how well the conditional probability distribution</span>
<span class="sd">        of `variable` given its parents fits the observed data, assuming uniform Dirichlet</span>
<span class="sd">        priors (all hyperparameters set to 1). The calculation is based on marginal and</span>
<span class="sd">        conditional counts, and is suitable for fully discrete Bayesian networks.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the target variable (child node).</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of parent variable names (categorical/discrete).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local K2 score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; variable = &quot;B&quot;</span>
<span class="sd">        &gt;&gt;&gt; parents = [&quot;A&quot;]</span>
<span class="sd">        &gt;&gt;&gt; s = k2_score.local_score(variable, parents)</span>
<span class="sd">        &gt;&gt;&gt; print(s)</span>
<span class="sd">        -42.18</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If `variable` or any parent is not present in `state_names` or data, or if the data</span>
<span class="sd">            is not fully discrete.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Koller &amp; Friedman, Probabilistic Graphical Models - Principles and Techniques, 2009,</span>
<span class="sd">            Section 18.3.4–18.3.6 (esp. page 806).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">var_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span>
        <span class="n">var_cardinality</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">var_states</span><span class="p">)</span>
        <span class="n">parents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span>
        <span class="n">state_counts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_counts</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">,</span> <span class="n">reindex</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">num_parents_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">var</span><span class="p">])</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">parents</span><span class="p">])</span>

        <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">state_counts</span><span class="p">)</span>
        <span class="n">log_gamma_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

        <span class="c1"># Compute log(gamma(counts + 1))</span>
        <span class="n">gammaln</span><span class="p">(</span><span class="n">counts</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_gamma_counts</span><span class="p">)</span>

        <span class="c1"># Compute the log-gamma conditional sample size</span>
        <span class="n">log_gamma_conds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">gammaln</span><span class="p">(</span><span class="n">log_gamma_conds</span> <span class="o">+</span> <span class="n">var_cardinality</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_gamma_conds</span><span class="p">)</span>

        <span class="c1"># TODO: Check why is this needed</span>
        <span class="c1">#</span>
        <span class="c1"># Adjustments when using reindex=False as it drops columns of 0 state counts</span>
        <span class="c1"># gamma_counts_adj = (</span>
        <span class="c1">#     (num_parents_states - counts.shape[1]) * var_cardinality * gammaln(1)</span>
        <span class="c1"># )</span>
        <span class="c1"># gamma_conds_adj = (num_parents_states - counts.shape[1]) * gammaln(</span>
        <span class="c1">#     var_cardinality</span>
        <span class="c1"># )</span>
        <span class="c1"># log_gamma_counts += gamma_counts_adj</span>
        <span class="c1"># log_gamma_conds += gamma_conds_adj</span>

        <span class="n">score</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_gamma_counts</span><span class="p">)</span>
            <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_gamma_conds</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">num_parents_states</span> <span class="o">*</span> <span class="n">lgamma</span><span class="p">(</span><span class="n">var_cardinality</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">score</span></div>
</div>



<div class="viewcode-block" id="BDeu">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BDeu">[docs]</a>
<span class="k">class</span> <span class="nc">BDeu</span><span class="p">(</span><span class="n">StructureScore</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BDeu structure score for discrete Bayesian networks with Dirichlet priors.</span>

<span class="sd">    The BDeu score evaluates Bayesian network structures using an &quot;equivalent sample size&quot;</span>
<span class="sd">    to define Dirichlet prior hyperparameters, making it flexible for various data sizes</span>
<span class="sd">    and uncertainty levels. Use this score when you want to control the influence of your prior</span>
<span class="sd">    belief through the equivalent sample size.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where each column represents a discrete variable.</span>
<span class="sd">        Missing values should be set as `numpy.nan`.</span>
<span class="sd">        Note: pandas converts such columns to dtype float.</span>
<span class="sd">    equivalent_sample_size : int, optional (default: 10)</span>
<span class="sd">        The equivalent (imaginary) sample size for the Dirichlet hyperparameters.</span>
<span class="sd">        The score is sensitive to this value; experiment with different values as needed.</span>
<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping variable names to their discrete states.</span>
<span class="sd">        If not specified, unique values observed in the data are used as possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import BDeu</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame({&quot;A&quot;: [0, 1, 1, 0], &quot;B&quot;: [1, 0, 1, 0], &quot;C&quot;: [1, 1, 1, 0]})</span>
<span class="sd">    &gt;&gt;&gt; model = DiscreteBayesianNetwork([(&quot;A&quot;, &quot;B&quot;), (&quot;A&quot;, &quot;C&quot;)])</span>
<span class="sd">    &gt;&gt;&gt; bdeu_score = BDeu(data, equivalent_sample_size=5)</span>
<span class="sd">    &gt;&gt;&gt; print(bdeu_score.score(model))</span>
<span class="sd">    -241.872</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the data contains continuous variables, or if the model variables are not present in the data.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Koller &amp; Friedman, Probabilistic Graphical Models - Principles and Techniques, 2009,</span>
<span class="sd">        Section 18.3.4–18.3.6 (esp. page 806).</span>
<span class="sd">    [2] AM Carvalho, Scoring functions for learning Bayesian networks,</span>
<span class="sd">        http://www.lx.it.pt/~asmc/pub/talks/09-TA/ta_pres.pdf</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">equivalent_sample_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">equivalent_sample_size</span> <span class="o">=</span> <span class="n">equivalent_sample_size</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BDeu</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="BDeu.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BDeu.local_score">[docs]</a>
    <span class="k">def</span> <span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local BDeu score for a given variable and its parent variables.</span>

<span class="sd">        This method calculates how well a given variable is explained by its parents</span>
<span class="sd">        according to the BDeu scoring metric, incorporating the equivalent sample size</span>
<span class="sd">        as the Dirichlet prior.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local BDeu score for the specified variable and parent configuration.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If `variable` or any parent is not found in state_names or data.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">parents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span>
        <span class="n">state_counts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_counts</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">,</span> <span class="n">reindex</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">num_parents_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">var</span><span class="p">])</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">parents</span><span class="p">])</span>

        <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">state_counts</span><span class="p">)</span>
        <span class="c1"># The counts_size reflects the full possible table, including dropped zero-count columns.</span>
        <span class="n">counts_size</span> <span class="o">=</span> <span class="n">num_parents_states</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">variable</span><span class="p">])</span>
        <span class="n">log_gamma_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">equivalent_sample_size</span> <span class="o">/</span> <span class="n">num_parents_states</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">equivalent_sample_size</span> <span class="o">/</span> <span class="n">counts_size</span>
        <span class="c1"># Compute log(gamma(counts + beta)) for the observed state counts.</span>
        <span class="n">gammaln</span><span class="p">(</span><span class="n">counts</span> <span class="o">+</span> <span class="n">beta</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_gamma_counts</span><span class="p">)</span>

        <span class="c1"># Compute the log-gamma of the conditional sample size.</span>
        <span class="n">log_gamma_conds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">gammaln</span><span class="p">(</span><span class="n">log_gamma_conds</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_gamma_conds</span><span class="p">)</span>

        <span class="c1"># Adjustment for missing zero-count columns (when using reindex=False to save memory).</span>
        <span class="n">gamma_counts_adj</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">num_parents_states</span> <span class="o">-</span> <span class="n">counts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">variable</span><span class="p">])</span>
            <span class="o">*</span> <span class="n">gammaln</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">gamma_conds_adj</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_parents_states</span> <span class="o">-</span> <span class="n">counts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">gammaln</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>

        <span class="c1"># Final BDeu local score calculation.</span>
        <span class="n">score</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_gamma_counts</span><span class="p">)</span> <span class="o">+</span> <span class="n">gamma_counts_adj</span><span class="p">)</span>
            <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_gamma_conds</span><span class="p">)</span> <span class="o">+</span> <span class="n">gamma_conds_adj</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">num_parents_states</span> <span class="o">*</span> <span class="n">lgamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
            <span class="o">-</span> <span class="n">counts_size</span> <span class="o">*</span> <span class="n">lgamma</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">score</span></div>
</div>



<div class="viewcode-block" id="BDs">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BDs">[docs]</a>
<span class="k">class</span> <span class="nc">BDs</span><span class="p">(</span><span class="n">BDeu</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BDs (Bayesian Dirichlet sparse) structure score for discrete Bayesian networks.</span>

<span class="sd">    The BDs score is a variant of the BDeu score that sets Dirichlet hyperparameters</span>
<span class="sd">    (pseudo-counts) proportional to the number of observed parent configurations,</span>
<span class="sd">    leading to improved scoring in sparse or partially observed data scenarios.</span>

<span class="sd">    Use this score when you expect many possible parent configurations in your data</span>
<span class="sd">    to be unobserved (common in sparse or high-dimensional discrete datasets).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where each column represents a discrete variable.</span>
<span class="sd">        Missing values should be set as `numpy.nan`.</span>
<span class="sd">        Note: pandas converts such columns to dtype float.</span>
<span class="sd">    equivalent_sample_size : int, optional (default: 10)</span>
<span class="sd">        The equivalent (imaginary) sample size for the Dirichlet hyperparameters.</span>
<span class="sd">        The score is sensitive to this value; try different values if needed.</span>
<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping variable names to their discrete states.</span>
<span class="sd">        If not specified, unique values observed in the data are used as possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import BDs</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame({&quot;A&quot;: [0, 1, 1, 0], &quot;B&quot;: [1, 0, 1, 0], &quot;C&quot;: [1, 1, 1, 0]})</span>
<span class="sd">    &gt;&gt;&gt; model = DiscreteBayesianNetwork([(&quot;A&quot;, &quot;B&quot;), (&quot;A&quot;, &quot;C&quot;)])</span>
<span class="sd">    &gt;&gt;&gt; bds_score = BDs(data, equivalent_sample_size=5)</span>
<span class="sd">    &gt;&gt;&gt; print(bds_score.score(model))</span>
<span class="sd">    -210.314</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the data contains continuous variables, or if the model variables are not present in the data.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Scutari, Marco. An Empirical-Bayes Score for Discrete Bayesian Networks.</span>
<span class="sd">        Journal of Machine Learning Research, 2016, pp. 438–48</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">equivalent_sample_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BDs</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">equivalent_sample_size</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="BDs.structure_prior_ratio">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BDs.structure_prior_ratio">[docs]</a>
    <span class="k">def</span> <span class="nf">structure_prior_ratio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">operation</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the log ratio of prior probabilities for a proposed change to the DAG structure.</span>

<span class="sd">        This method implements the marginal uniform prior for the graph structure, where the</span>
<span class="sd">        log prior probability ratio is -log(2) for adding an edge, log(2) for removing an edge,</span>
<span class="sd">        and 0 otherwise.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        operation : str</span>
<span class="sd">            The proposed operation on the Directed Acyclic Graph (DAG).</span>
<span class="sd">            Use &quot;+&quot; for adding an edge, &quot;-&quot; for removing an edge, or other values for no change.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        prior_ratio : float</span>
<span class="sd">            The log ratio of the prior probabilities for the proposed operation.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.estimators import BDs</span>
<span class="sd">        &gt;&gt;&gt; score = BDs(data)</span>
<span class="sd">        &gt;&gt;&gt; score.structure_prior_ratio(&quot;+&quot;)</span>
<span class="sd">        -0.6931471805599453</span>
<span class="sd">        &gt;&gt;&gt; score.structure_prior_ratio(&quot;-&quot;)</span>
<span class="sd">        0.6931471805599453</span>
<span class="sd">        &gt;&gt;&gt; score.structure_prior_ratio(&quot;noop&quot;)</span>
<span class="sd">        0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;+&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">operation</span> <span class="o">==</span> <span class="s2">&quot;-&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
        <span class="k">return</span> <span class="mi">0</span></div>


<div class="viewcode-block" id="BDs.structure_prior">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BDs.structure_prior">[docs]</a>
    <span class="k">def</span> <span class="nf">structure_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the marginal uniform prior for a Bayesian network structure.</span>

<span class="sd">        This method assigns a marginal uniform prior to the graph structure, where</span>
<span class="sd">        the probability of an arc (edge) between any two nodes (in either direction) is 1/4,</span>
<span class="sd">        and the probability of no arc between any two nodes is 1/2. The returned value</span>
<span class="sd">        is the log prior probability for the given model structure.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : DiscreteBayesianNetwork</span>
<span class="sd">            The Bayesian network model for which to compute the structure prior.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The log prior probability of the given network structure under the marginal uniform prior.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.estimators import BDs</span>
<span class="sd">        &gt;&gt;&gt; model = DiscreteBayesianNetwork([(&quot;A&quot;, &quot;B&quot;), (&quot;C&quot;, &quot;D&quot;)])</span>
<span class="sd">        &gt;&gt;&gt; score = BDs(data)</span>
<span class="sd">        &gt;&gt;&gt; prior = score.structure_prior(model)</span>
<span class="sd">        &gt;&gt;&gt; print(prior)</span>
<span class="sd">        -4.1588830833596715</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nedges</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">edges</span><span class="p">()))</span>
        <span class="n">nnodes</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">nodes</span><span class="p">()))</span>
        <span class="n">possible_edges</span> <span class="o">=</span> <span class="n">nnodes</span> <span class="o">*</span> <span class="p">(</span><span class="n">nnodes</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span>
        <span class="n">score</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">nedges</span> <span class="o">+</span> <span class="n">possible_edges</span><span class="p">)</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">score</span></div>


<div class="viewcode-block" id="BDs.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BDs.local_score">[docs]</a>
    <span class="k">def</span> <span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local BDs score for a variable and its parent variables.</span>

<span class="sd">        The BDs local score quantifies how well the given variable is explained by its</span>
<span class="sd">        specified parent set, using a Bayesian Dirichlet sparse prior. The hyperparameters</span>
<span class="sd">        are adjusted based on the number of observed parent configurations, making the score</span>
<span class="sd">        more robust in sparse data scenarios.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local BDs score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; variable = &quot;B&quot;</span>
<span class="sd">        &gt;&gt;&gt; parents = [&quot;A&quot;]</span>
<span class="sd">        &gt;&gt;&gt; score = bds_score.local_score(variable, parents)</span>
<span class="sd">        &gt;&gt;&gt; print(score)</span>
<span class="sd">        -38.215</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If `variable` or any parent is not present in `state_names` or data, or if</span>
<span class="sd">            the data contains unsupported types (e.g., continuous values).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">parents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span>
        <span class="n">state_counts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_counts</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">,</span> <span class="n">reindex</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">num_parents_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">var</span><span class="p">])</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">parents</span><span class="p">])</span>

        <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">state_counts</span><span class="p">)</span>
        <span class="c1"># counts size is different because reindex=False is dropping columns.</span>
        <span class="n">counts_size</span> <span class="o">=</span> <span class="n">num_parents_states</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">variable</span><span class="p">])</span>
        <span class="n">log_gamma_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">equivalent_sample_size</span> <span class="o">/</span> <span class="n">state_counts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">equivalent_sample_size</span> <span class="o">/</span> <span class="n">counts_size</span>
        <span class="c1"># Compute log(gamma(counts + beta))</span>
        <span class="n">gammaln</span><span class="p">(</span><span class="n">counts</span> <span class="o">+</span> <span class="n">beta</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_gamma_counts</span><span class="p">)</span>

        <span class="c1"># Compute the log-gamma conditional sample size</span>
        <span class="n">log_gamma_conds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">gammaln</span><span class="p">(</span><span class="n">log_gamma_conds</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_gamma_conds</span><span class="p">)</span>

        <span class="c1"># Adjustment because of missing 0 columns when using reindex=False for computing state_counts to save memory.</span>
        <span class="n">gamma_counts_adj</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">num_parents_states</span> <span class="o">-</span> <span class="n">counts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">variable</span><span class="p">])</span>
            <span class="o">*</span> <span class="n">gammaln</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">gamma_conds_adj</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_parents_states</span> <span class="o">-</span> <span class="n">counts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">gammaln</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>

        <span class="n">score</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_gamma_counts</span><span class="p">)</span> <span class="o">+</span> <span class="n">gamma_counts_adj</span><span class="p">)</span>
            <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_gamma_conds</span><span class="p">)</span> <span class="o">+</span> <span class="n">gamma_conds_adj</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">state_counts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">lgamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
            <span class="o">-</span> <span class="n">counts_size</span> <span class="o">*</span> <span class="n">lgamma</span><span class="p">(</span><span class="n">beta</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">score</span></div>
</div>



<div class="viewcode-block" id="BIC">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BIC">[docs]</a>
<span class="k">class</span> <span class="nc">BIC</span><span class="p">(</span><span class="n">StructureScore</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BIC (Bayesian Information Criterion) structure score for discrete Bayesian networks.</span>

<span class="sd">    The BIC score, also known as the Minimal Descriptive Length (MDL) score, evaluates</span>
<span class="sd">    Bayesian network structures using a log-likelihood term with a complexity penalty to</span>
<span class="sd">    discourage overfitting. Use this score for structure learning when you want to balance</span>
<span class="sd">    model fit with simplicity.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where each column represents a discrete variable.</span>
<span class="sd">        Missing values should be set as `numpy.nan`.</span>
<span class="sd">        Note: pandas converts such columns to dtype float.</span>
<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping variable names to their discrete states.</span>
<span class="sd">        If not specified, unique values observed in the data are used as possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import BIC</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame({&quot;A&quot;: [0, 1, 1, 0], &quot;B&quot;: [1, 0, 1, 0], &quot;C&quot;: [1, 1, 1, 0]})</span>
<span class="sd">    &gt;&gt;&gt; model = DiscreteBayesianNetwork([(&quot;A&quot;, &quot;B&quot;), (&quot;A&quot;, &quot;C&quot;)])</span>
<span class="sd">    &gt;&gt;&gt; bic_score = BIC(data)</span>
<span class="sd">    &gt;&gt;&gt; print(bic_score.score(model))</span>
<span class="sd">    -151.47</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the data contains continuous variables, or if the model variables are not present in the data.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Koller &amp; Friedman, Probabilistic Graphical Models - Principles and Techniques, 2009,</span>
<span class="sd">        Section 18.3.4–18.3.6 (esp. page 802).</span>
<span class="sd">    [2] AM Carvalho, Scoring functions for learning Bayesian networks,</span>
<span class="sd">        http://www.lx.it.pt/~asmc/pub/talks/09-TA/ta_pres.pdf</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BIC</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="BIC.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BIC.local_score">[docs]</a>
    <span class="k">def</span> <span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local BIC/MDL score for a variable and its parent variables.</span>

<span class="sd">        This method quantifies the fit of a variable to its parent set in the network,</span>
<span class="sd">        balancing log-likelihood with a complexity penalty to discourage overfitting.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local BIC score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; variable = &quot;B&quot;</span>
<span class="sd">        &gt;&gt;&gt; parents = [&quot;A&quot;]</span>
<span class="sd">        &gt;&gt;&gt; score = bic_score.local_score(variable, parents)</span>
<span class="sd">        &gt;&gt;&gt; print(score)</span>
<span class="sd">        -19.315</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If `variable` or any parent is not present in `state_names` or data, or if</span>
<span class="sd">            the data contains unsupported types (e.g., continuous values).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">var_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span>
        <span class="n">var_cardinality</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">var_states</span><span class="p">)</span>
        <span class="n">parents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span>
        <span class="n">state_counts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_counts</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">,</span> <span class="n">reindex</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">sample_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="n">num_parents_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">var</span><span class="p">])</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">parents</span><span class="p">])</span>

        <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">state_counts</span><span class="p">)</span>
        <span class="n">log_likelihoods</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

        <span class="c1"># Compute the log-counts</span>
        <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_likelihoods</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="n">counts</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Compute the log-conditional sample size</span>
        <span class="n">log_conditionals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">log_conditionals</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_conditionals</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="n">log_conditionals</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Compute the log-likelihoods</span>
        <span class="n">log_likelihoods</span> <span class="o">-=</span> <span class="n">log_conditionals</span>
        <span class="n">log_likelihoods</span> <span class="o">*=</span> <span class="n">counts</span>

        <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_likelihoods</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">-=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="n">sample_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_parents_states</span> <span class="o">*</span> <span class="p">(</span><span class="n">var_cardinality</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">score</span></div>
</div>



<div class="viewcode-block" id="AIC">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.AIC">[docs]</a>
<span class="k">class</span> <span class="nc">AIC</span><span class="p">(</span><span class="n">StructureScore</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    AIC (Akaike Information Criterion) structure score for discrete Bayesian networks.</span>

<span class="sd">    The AIC score evaluates Bayesian network structures using a log-likelihood term</span>
<span class="sd">    with a penalty for model complexity to discourage overfitting. Unlike BIC,</span>
<span class="sd">    the penalty term is independent of sample size, making AIC more sensitive to</span>
<span class="sd">    goodness of fit in smaller datasets.</span>

<span class="sd">    Use this score when you want to select a network structure that balances model</span>
<span class="sd">    fit with simplicity, especially in contexts with moderate or small sample sizes.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where each column represents a discrete variable.</span>
<span class="sd">        Missing values should be set as `numpy.nan`.</span>
<span class="sd">        Note: pandas converts such columns to dtype float.</span>
<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping variable names to their discrete states.</span>
<span class="sd">        If not specified, unique values observed in the data are used as possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.models import DiscreteBayesianNetwork</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import AIC</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame({&quot;A&quot;: [0, 1, 1, 0], &quot;B&quot;: [1, 0, 1, 0], &quot;C&quot;: [1, 1, 1, 0]})</span>
<span class="sd">    &gt;&gt;&gt; model = DiscreteBayesianNetwork([(&quot;A&quot;, &quot;B&quot;), (&quot;A&quot;, &quot;C&quot;)])</span>
<span class="sd">    &gt;&gt;&gt; aic_score = AIC(data)</span>
<span class="sd">    &gt;&gt;&gt; print(aic_score.score(model))</span>
<span class="sd">    -140.12</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the data contains continuous variables, or if the model variables are not present in the data.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Koller &amp; Friedman, Probabilistic Graphical Models - Principles and Techniques, 2009,</span>
<span class="sd">        Section 18.3.4–18.3.6 (esp. page 802).</span>
<span class="sd">    [2] AM Carvalho, Scoring functions for learning Bayesian networks,</span>
<span class="sd">        http://www.lx.it.pt/~asmc/pub/talks/09-TA/ta_pres.pdf</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AIC</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="AIC.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.AIC.local_score">[docs]</a>
    <span class="k">def</span> <span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local AIC score for a variable and its parent variables.</span>

<span class="sd">        This method quantifies the fit of a variable to its parent set in the network,</span>
<span class="sd">        balancing log-likelihood with a complexity penalty to avoid overfitting.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local AIC score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; variable = &quot;B&quot;</span>
<span class="sd">        &gt;&gt;&gt; parents = [&quot;A&quot;]</span>
<span class="sd">        &gt;&gt;&gt; score = aic_score.local_score(variable, parents)</span>
<span class="sd">        &gt;&gt;&gt; print(score)</span>
<span class="sd">        -17.032</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If `variable` or any parent is not present in `state_names` or data, or if</span>
<span class="sd">            the data contains unsupported types (e.g., continuous values).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">var_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span>
        <span class="n">var_cardinality</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">var_states</span><span class="p">)</span>
        <span class="n">parents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span>
        <span class="n">state_counts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_counts</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">,</span> <span class="n">reindex</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">num_parents_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="p">[</span><span class="n">var</span><span class="p">])</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">parents</span><span class="p">])</span>

        <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">state_counts</span><span class="p">)</span>
        <span class="n">log_likelihoods</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

        <span class="c1"># Compute the log-counts</span>
        <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_likelihoods</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="n">counts</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Compute the log-conditional sample size</span>
        <span class="n">log_conditionals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">log_conditionals</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">log_conditionals</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="n">log_conditionals</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Compute the log-likelihoods</span>
        <span class="n">log_likelihoods</span> <span class="o">-=</span> <span class="n">log_conditionals</span>
        <span class="n">log_likelihoods</span> <span class="o">*=</span> <span class="n">counts</span>

        <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_likelihoods</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">-=</span> <span class="n">num_parents_states</span> <span class="o">*</span> <span class="p">(</span><span class="n">var_cardinality</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">score</span></div>
</div>



<div class="viewcode-block" id="LogLikelihoodGauss">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.LogLikelihoodGauss">[docs]</a>
<span class="k">class</span> <span class="nc">LogLikelihoodGauss</span><span class="p">(</span><span class="n">StructureScore</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Log-likelihood structure score for Gaussian Bayesian networks.</span>

<span class="sd">    This score evaluates the fit of a continuous (Gaussian) Bayesian network structure</span>
<span class="sd">    by computing the (unpenalized) log-likelihood of the observed data given the model,</span>
<span class="sd">    using generalized linear modeling. It is suitable for networks with continuous variables.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where each column represents a continuous variable.</span>

<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping variable names to possible states. Not typically used for Gaussian networks.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import LogLikelihoodGauss</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">    ...     {</span>
<span class="sd">    ...         &quot;A&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;B&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;C&quot;: np.random.randn(100),</span>
<span class="sd">    ...     }</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; score = LogLikelihoodGauss(data)</span>
<span class="sd">    &gt;&gt;&gt; ll = score.local_score(&quot;B&quot;, [&quot;A&quot;, &quot;C&quot;])</span>
<span class="sd">    &gt;&gt;&gt; print(ll)</span>
<span class="sd">    -142.125</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the data contains discrete or non-numeric variables.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LogLikelihoodGauss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the log-likelihood and degrees of freedom for a Gaussian model.</span>

<span class="sd">        This internal method fits a generalized linear model (GLM) for the specified variable</span>
<span class="sd">        as a function of its parent variables, using the statsmodels library, and returns the</span>
<span class="sd">        log-likelihood and degrees of freedom of the fitted model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) to be predicted.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names to be used as predictors (parents). If empty, fits an intercept-only model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        llf : float</span>
<span class="sd">            The log-likelihood of the fitted model.</span>
<span class="sd">        df_model : int</span>
<span class="sd">            The degrees of freedom of the fitted model (number of model parameters estimated).</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; llf, df = score._log_likelihood(&quot;B&quot;, [&quot;A&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; print(llf, df)</span>
<span class="sd">        -142.125 2</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the GLM cannot be fitted due to missing or non-numeric data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">glm_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">glm</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">variable</span><span class="si">}</span><span class="s2"> ~ 1&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">glm_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">glm</span><span class="p">(</span>
                <span class="n">formula</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">variable</span><span class="si">}</span><span class="s2"> ~ </span><span class="si">{</span><span class="s1">&#39; + &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span>
            <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">glm_model</span><span class="o">.</span><span class="n">llf</span><span class="p">,</span> <span class="n">glm_model</span><span class="o">.</span><span class="n">df_model</span><span class="p">)</span>

<div class="viewcode-block" id="LogLikelihoodGauss.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.LogLikelihoodGauss.local_score">[docs]</a>
    <span class="k">def</span> <span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the log-likelihood score for a variable given its parent variables.</span>

<span class="sd">        Fits a generalized linear model (GLM) for the variable as a function of its parents,</span>
<span class="sd">        and returns the resulting log-likelihood as the structure score.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The log-likelihood score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; ll = score.local_score(&quot;B&quot;, [&quot;A&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; print(ll)</span>
<span class="sd">        -142.125</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the GLM cannot be fitted due to non-numeric data or missing columns.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ll</span><span class="p">,</span> <span class="n">df_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ll</span></div>
</div>



<div class="viewcode-block" id="BICGauss">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BICGauss">[docs]</a>
<span class="k">class</span> <span class="nc">BICGauss</span><span class="p">(</span><span class="n">LogLikelihoodGauss</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BIC (Bayesian Information Criterion) structure score for Gaussian Bayesian networks.</span>

<span class="sd">    The BICGauss score evaluates continuous Bayesian network structures by penalizing</span>
<span class="sd">    the log-likelihood with a term proportional to the number of model parameters,</span>
<span class="sd">    discouraging overfitting. This is the Gaussian version of the BIC/MDL score,</span>
<span class="sd">    suitable for networks where all variables are continuous.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where each column represents a continuous variable.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import BICGauss</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">    ...     {</span>
<span class="sd">    ...         &quot;A&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;B&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;C&quot;: np.random.randn(100),</span>
<span class="sd">    ...     }</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; score = BICGauss(data)</span>
<span class="sd">    &gt;&gt;&gt; s = score.local_score(&quot;B&quot;, [&quot;A&quot;, &quot;C&quot;])</span>
<span class="sd">    &gt;&gt;&gt; print(s)</span>
<span class="sd">    -111.42</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the GLM cannot be fitted due to missing or non-numeric data.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BICGauss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="BICGauss.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BICGauss.local_score">[docs]</a>
    <span class="k">def</span> <span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local BIC/MDL score for a variable and its parent variables</span>
<span class="sd">        in a Gaussian Bayesian network.</span>

<span class="sd">        The score is the log-likelihood minus a penalty term that increases</span>
<span class="sd">        with the number of model parameters and sample size.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local BICGauss score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; s = score.local_score(&quot;B&quot;, [&quot;A&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; print(s)</span>
<span class="sd">        -111.42</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the GLM cannot be fitted due to missing or non-numeric data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ll</span><span class="p">,</span> <span class="n">df_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>

        <span class="c1"># Adding +2 to model df to compute the likelihood df.</span>
        <span class="k">return</span> <span class="n">ll</span> <span class="o">-</span> <span class="p">(((</span><span class="n">df_model</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span></div>
</div>



<div class="viewcode-block" id="AICGauss">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.AICGauss">[docs]</a>
<span class="k">class</span> <span class="nc">AICGauss</span><span class="p">(</span><span class="n">LogLikelihoodGauss</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    AIC (Akaike Information Criterion) structure score for Gaussian Bayesian networks.</span>

<span class="sd">    The AICGauss score evaluates continuous Bayesian network structures by penalizing</span>
<span class="sd">    the log-likelihood with a term proportional to the number of model parameters.</span>
<span class="sd">    The penalty is less severe than BIC and does not depend on sample size, making AIC</span>
<span class="sd">    preferable for model selection with smaller datasets.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where each column represents a continuous variable.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import AICGauss</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">    ...     {</span>
<span class="sd">    ...         &quot;A&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;B&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;C&quot;: np.random.randn(100),</span>
<span class="sd">    ...     }</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; score = AICGauss(data)</span>
<span class="sd">    &gt;&gt;&gt; s = score.local_score(&quot;B&quot;, [&quot;A&quot;, &quot;C&quot;])</span>
<span class="sd">    &gt;&gt;&gt; print(s)</span>
<span class="sd">    -97.53</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the GLM cannot be fitted due to missing or non-numeric data.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AICGauss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="AICGauss.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.AICGauss.local_score">[docs]</a>
    <span class="k">def</span> <span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local AIC score for a variable and its parent variables</span>
<span class="sd">        in a Gaussian Bayesian network.</span>

<span class="sd">        The score is the log-likelihood minus a penalty term that increases with</span>
<span class="sd">        the number of model parameters (but not sample size).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local AICGauss score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; s = score.local_score(&quot;B&quot;, [&quot;A&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; print(s)</span>
<span class="sd">        -97.53</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the GLM cannot be fitted due to missing or non-numeric data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ll</span><span class="p">,</span> <span class="n">df_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>

        <span class="c1"># Adding +2 to model df to compute the likelihood df.</span>
        <span class="k">return</span> <span class="n">ll</span> <span class="o">-</span> <span class="p">(</span><span class="n">df_model</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span></div>
</div>



<div class="viewcode-block" id="LogLikelihoodCondGauss">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.LogLikelihoodCondGauss">[docs]</a>
<span class="k">class</span> <span class="nc">LogLikelihoodCondGauss</span><span class="p">(</span><span class="n">StructureScore</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Log-likelihood score for Bayesian networks with mixed discrete and continuous variables.</span>

<span class="sd">    This score is based on conditional Gaussian distributions and supports networks</span>
<span class="sd">    with both discrete and continuous variables, using the methodology described in [1].</span>
<span class="sd">    The local score computes the log-likelihood of the observed data given the</span>
<span class="sd">    network structure, handling mixed parent sets as described in the reference.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where columns can be discrete or continuous variables.</span>
<span class="sd">        Variable types should be consistent with the structure.</span>

<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping discrete variable names to their possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import LogLikelihoodCondGauss</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">    ...     {</span>
<span class="sd">    ...         &quot;A&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;B&quot;: np.random.randint(0, 2, 100),</span>
<span class="sd">    ...         &quot;C&quot;: np.random.randn(100),</span>
<span class="sd">    ...     }</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; score = LogLikelihoodCondGauss(data)</span>
<span class="sd">    &gt;&gt;&gt; ll = score.local_score(&quot;A&quot;, [&quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">    &gt;&gt;&gt; print(ll)</span>
<span class="sd">    -98.452</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the data or variable types are not suitable for conditional Gaussian modeling.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Andrews, B., Ramsey, J., &amp; Cooper, G. F. (2018). Scoring Bayesian</span>
<span class="sd">        Networks of Mixed Variables. International journal of data science and</span>
<span class="sd">        analytics, 6(1), 3–18. https://doi.org/10.1007/s41060-017-0085-7</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LogLikelihoodCondGauss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_adjusted_cov</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes an adjusted covariance matrix from the given DataFrame.</span>

<span class="sd">        This method returns the sample covariance matrix for the columns in `df`, making sure</span>
<span class="sd">        the result is always positive semi-definite. If there are not enough rows to estimate</span>
<span class="sd">        covariance (i.e., fewer rows than variables), the identity matrix is returned. If the</span>
<span class="sd">        covariance matrix is not positive semi-definite, a small value is added to the diagonal.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        df : pandas.DataFrame</span>
<span class="sd">            DataFrame whose columns are the variables for which the covariance matrix is computed.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        cov_matrix : pandas.DataFrame</span>
<span class="sd">            The adjusted covariance matrix. If not enough data, returns the identity matrix.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; df = pd.DataFrame(np.random.randn(5, 3), columns=[&quot;A&quot;, &quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; cov = LogLikelihoodCondGauss._adjusted_cov(df)</span>
<span class="sd">        &gt;&gt;&gt; print(cov)</span>
<span class="sd">                A         B         C</span>
<span class="sd">        A  0.802359  0.100722 -0.006956</span>
<span class="sd">        B  0.100722  0.818795  0.154614</span>
<span class="sd">        C -0.006956  0.154614  0.540758</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># If a number of rows less than number of variables, return variance 1 with no covariance.</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)):</span>
            <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span>
            <span class="p">)</span>

        <span class="c1"># If the matrix is not positive semidefinite, add a small error to make it.</span>
        <span class="n">df_cov</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">cov</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">df_cov</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">df_cov</span> <span class="o">=</span> <span class="n">df_cov</span> <span class="o">+</span> <span class="mf">1e-6</span>
        <span class="k">return</span> <span class="n">df_cov</span>

    <span class="k">def</span> <span class="nf">_cat_parents_product</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the product of the number of unique states for each categorical parent.</span>

<span class="sd">        For each parent in `parents` that is discrete (not continuous), this method multiplies</span>
<span class="sd">        the number of observed unique states. Parents with only one unique value are ignored</span>
<span class="sd">        (i.e., do not contribute to the product).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of parent variable names to consider.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        k : int</span>
<span class="sd">            The product of unique state counts for each discrete parent in `parents`.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; score._cat_parents_product([&quot;A&quot;, &quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">        6</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">pa</span> <span class="ow">in</span> <span class="n">parents</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">pa</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;N&quot;</span><span class="p">:</span>
                <span class="n">n_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">pa</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">n_states</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">k</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">pa</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">k</span>

    <span class="k">def</span> <span class="nf">_get_num_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the number of free parameters required for the conditional distribution</span>
<span class="sd">        of a variable given its parents in a mixed (discrete and continuous) Bayesian network.</span>

<span class="sd">        For a continuous variable, the number of parameters depends on the number of continuous</span>
<span class="sd">        parents and the number of configurations of discrete parents. For a discrete variable,</span>
<span class="sd">        it depends on the number of categories and parent configurations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the target variable (child node).</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of parent variable names.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        k : int</span>
<span class="sd">            The number of free parameters for the conditional distribution of `variable`</span>
<span class="sd">            given its parents.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; score._get_num_parameters(&quot;A&quot;, [&quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">        12</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">parent_dtypes</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">pa</span><span class="p">]</span> <span class="k">for</span> <span class="n">pa</span> <span class="ow">in</span> <span class="n">parents</span><span class="p">]</span>
        <span class="n">n_cont_parents</span> <span class="o">=</span> <span class="n">parent_dtypes</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;N&quot;</span><span class="p">:</span>
            <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cat_parents_product</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">n_cont_parents</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">n_cont_parents</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cat_parents_product</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">k</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_cat_parents_product</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>
                    <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="o">*</span> <span class="p">(</span><span class="n">n_cont_parents</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
                <span class="p">)</span>

        <span class="k">return</span> <span class="n">k</span>

    <span class="k">def</span> <span class="nf">_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the conditional log-likelihood for a variable given its parent set,</span>
<span class="sd">        supporting both continuous and discrete variables (mixed Bayesian networks).</span>

<span class="sd">        For a continuous variable, computes the log-likelihood using conditional Gaussian</span>
<span class="sd">        distributions as described in [1]. For a discrete variable, computes the</span>
<span class="sd">        log-likelihood based on the joint and marginal probabilities involving both</span>
<span class="sd">        discrete and continuous parents.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The variable (node) for which the log-likelihood is computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of parent variable names.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        log_like : float</span>
<span class="sd">            The log-likelihood value for the specified variable and parent set.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; ll = score._log_likelihood(&quot;A&quot;, [&quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; print(ll)</span>
<span class="sd">        -99.242</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If data is not suitable for log-likelihood computation (e.g., unsupported variable types).</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Andrews, B., Ramsey, J., &amp; Cooper, G. F. (2018). Scoring Bayesian</span>
<span class="sd">            Networks of Mixed Variables. International journal of data science and</span>
<span class="sd">            analytics, 6(1), 3–18. https://doi.org/10.1007/s41060-017-0085-7</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="n">variable</span><span class="p">]</span> <span class="o">+</span> <span class="n">parents</span><span class="p">]</span>

        <span class="c1"># If variable is continuous, the probability is computed as:</span>
        <span class="c1"># P(C1 | C2, D) = p(C1, C2 | D) / p(C2 | D)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;N&quot;</span><span class="p">:</span>
            <span class="n">c1</span> <span class="o">=</span> <span class="n">variable</span>
            <span class="n">c2</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">parents</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;N&quot;</span><span class="p">]</span>
            <span class="n">d</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">c2</span><span class="p">))</span>

            <span class="c1"># If D = {}, p(C1, C2 | D) = p(C1, C2) and p(C2 | D) = p(C2)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># If C2 = {}, p(C1, C2 | D) = p(C1) and p(C2 | D) = 1.</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">c2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">p_c1c2_d</span> <span class="o">=</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
                        <span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
                        <span class="n">mean</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                        <span class="n">cov</span><span class="o">=</span><span class="n">LogLikelihoodCondGauss</span><span class="o">.</span><span class="n">_adjusted_cov</span><span class="p">(</span><span class="n">df</span><span class="p">),</span>
                        <span class="n">allow_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_c1c2_d</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">p_c1c2_d</span> <span class="o">=</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
                        <span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
                        <span class="n">mean</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                        <span class="n">cov</span><span class="o">=</span><span class="n">LogLikelihoodCondGauss</span><span class="o">.</span><span class="n">_adjusted_cov</span><span class="p">(</span><span class="n">df</span><span class="p">),</span>
                        <span class="n">allow_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">df_c2</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c2</span><span class="p">]</span>
                    <span class="n">p_c2_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span>
                        <span class="mf">1e-8</span><span class="p">,</span>
                        <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
                            <span class="n">x</span><span class="o">=</span><span class="n">df_c2</span><span class="p">,</span>
                            <span class="n">mean</span><span class="o">=</span><span class="n">df_c2</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                            <span class="n">cov</span><span class="o">=</span><span class="n">LogLikelihoodCondGauss</span><span class="o">.</span><span class="n">_adjusted_cov</span><span class="p">(</span><span class="n">df_c2</span><span class="p">),</span>
                            <span class="n">allow_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="p">),</span>
                    <span class="p">)</span>

                    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_c1c2_d</span> <span class="o">/</span> <span class="n">p_c2_d</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">log_like</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">for</span> <span class="n">d_states</span><span class="p">,</span> <span class="n">df_d</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                    <span class="n">p_c1c2_d</span> <span class="o">=</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
                        <span class="n">x</span><span class="o">=</span><span class="n">df_d</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="n">c1</span><span class="p">]</span> <span class="o">+</span> <span class="n">c2</span><span class="p">],</span>
                        <span class="n">mean</span><span class="o">=</span><span class="n">df_d</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="n">c1</span><span class="p">]</span> <span class="o">+</span> <span class="n">c2</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                        <span class="n">cov</span><span class="o">=</span><span class="n">LogLikelihoodCondGauss</span><span class="o">.</span><span class="n">_adjusted_cov</span><span class="p">(</span>
                            <span class="n">df_d</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="n">c1</span><span class="p">]</span> <span class="o">+</span> <span class="n">c2</span><span class="p">]</span>
                        <span class="p">),</span>
                        <span class="n">allow_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">c2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">p_c2_d</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">p_c2_d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span>
                            <span class="mf">1e-8</span><span class="p">,</span>
                            <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
                                <span class="n">x</span><span class="o">=</span><span class="n">df_d</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c2</span><span class="p">],</span>
                                <span class="n">mean</span><span class="o">=</span><span class="n">df_d</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c2</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                                <span class="n">cov</span><span class="o">=</span><span class="n">LogLikelihoodCondGauss</span><span class="o">.</span><span class="n">_adjusted_cov</span><span class="p">(</span>
                                    <span class="n">df_d</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c2</span><span class="p">]</span>
                                <span class="p">),</span>
                                <span class="n">allow_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="p">),</span>
                        <span class="p">)</span>

                    <span class="n">log_like</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_c1c2_d</span> <span class="o">/</span> <span class="n">p_c2_d</span><span class="p">))</span>
                <span class="k">return</span> <span class="n">log_like</span>

        <span class="c1"># If variable is discrete, the probability is computed as:</span>
        <span class="c1"># P(D1 | C, D2) = (p(C| D1, D2) p(D1, D2)) / (p(C| D2) p(D2))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">d1</span> <span class="o">=</span> <span class="n">variable</span>
            <span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">parents</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;N&quot;</span><span class="p">]</span>
            <span class="n">d2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">parents</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>

            <span class="n">log_like</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">d_states</span><span class="p">,</span> <span class="n">df_d1d2</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="n">d1</span><span class="p">]</span> <span class="o">+</span> <span class="n">d2</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                <span class="c1"># Check if df_d1d2 also has the discrete variables.</span>
                <span class="c1"># If C={}, p(C | D1, D2) = 1.</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">p_c_d1d2</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">p_c_d1d2</span> <span class="o">=</span> <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
                        <span class="n">x</span><span class="o">=</span><span class="n">df_d1d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">],</span>
                        <span class="n">mean</span><span class="o">=</span><span class="n">df_d1d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                        <span class="n">cov</span><span class="o">=</span><span class="n">LogLikelihoodCondGauss</span><span class="o">.</span><span class="n">_adjusted_cov</span><span class="p">(</span><span class="n">df_d1d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">]),</span>
                        <span class="n">allow_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="p">)</span>

                <span class="c1"># P(D1, D2)</span>
                <span class="n">p_d1d2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">df_d1d2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">df_d1d2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

                <span class="c1"># If D2 = {}, p(D1 | C, D2) = (p(C | D1, D2) p(D1, D2)) / p(C)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">d2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">p_c_d2</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">p_c_d2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span>
                            <span class="mf">1e-8</span><span class="p">,</span>
                            <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
                                <span class="n">x</span><span class="o">=</span><span class="n">df_d1d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">],</span>
                                <span class="n">mean</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                                <span class="n">cov</span><span class="o">=</span><span class="n">LogLikelihoodCondGauss</span><span class="o">.</span><span class="n">_adjusted_cov</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">]),</span>
                                <span class="n">allow_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="p">),</span>
                        <span class="p">)</span>

                    <span class="n">log_like</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_c_d1d2</span> <span class="o">*</span> <span class="n">p_d1d2</span> <span class="o">/</span> <span class="n">p_c_d2</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">p_c_d2</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">df_d2</span> <span class="o">=</span> <span class="n">df</span>
                        <span class="k">for</span> <span class="n">var</span><span class="p">,</span> <span class="n">state</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">d2</span><span class="p">,</span> <span class="n">d_states</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
                            <span class="n">df_d2</span> <span class="o">=</span> <span class="n">df_d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df_d2</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">==</span> <span class="n">state</span><span class="p">]</span>

                        <span class="n">p_c_d2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span>
                            <span class="mf">1e-8</span><span class="p">,</span>
                            <span class="n">multivariate_normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
                                <span class="n">x</span><span class="o">=</span><span class="n">df_d1d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">],</span>
                                <span class="n">mean</span><span class="o">=</span><span class="n">df_d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                                <span class="n">cov</span><span class="o">=</span><span class="n">LogLikelihoodCondGauss</span><span class="o">.</span><span class="n">_adjusted_cov</span><span class="p">(</span>
                                    <span class="n">df_d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">c</span><span class="p">]</span>
                                <span class="p">),</span>
                                <span class="n">allow_singular</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="p">),</span>
                        <span class="p">)</span>

                    <span class="n">p_d2</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">d2</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> <span class="o">/</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">var</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">d2</span><span class="p">,</span> <span class="n">d_states</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
                        <span class="n">p_d2</span> <span class="o">=</span> <span class="n">p_d2</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">p_d2</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">get_level_values</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="o">==</span> <span class="n">value</span><span class="p">]</span>

                    <span class="n">log_like</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="n">p_c_d1d2</span> <span class="o">*</span> <span class="n">p_d1d2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">p_c_d2</span> <span class="o">*</span> <span class="n">p_d2</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">()[</span><span class="mi">0</span><span class="p">]))</span>
                    <span class="p">)</span>
            <span class="k">return</span> <span class="n">log_like</span>

<div class="viewcode-block" id="LogLikelihoodCondGauss.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.LogLikelihoodCondGauss.local_score">[docs]</a>
    <span class="k">def</span> <span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local log-likelihood score for a variable given its parent variables</span>
<span class="sd">        in a mixed (discrete and continuous) Bayesian network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local conditional Gaussian log-likelihood score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; ll = score.local_score(&quot;A&quot;, [&quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; print(ll)</span>
<span class="sd">        -98.452</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the log-likelihood cannot be computed due to incompatible data or variable types.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ll</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ll</span></div>
</div>



<div class="viewcode-block" id="BICCondGauss">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BICCondGauss">[docs]</a>
<span class="k">class</span> <span class="nc">BICCondGauss</span><span class="p">(</span><span class="n">LogLikelihoodCondGauss</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    BIC (Bayesian Information Criterion) score for Bayesian networks with mixed (discrete and continuous) variables.</span>

<span class="sd">    The BICCondGauss score evaluates network structures by penalizing the conditional log-likelihood</span>
<span class="sd">    with a term proportional to the number of free parameters and the logarithm of sample size.</span>
<span class="sd">    This approach generalizes the classic BIC to handle mixed discrete/continuous data as</span>
<span class="sd">    described in [1].</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where columns may be discrete or continuous variables.</span>

<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping discrete variable names to possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import BICCondGauss</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">    ...     {</span>
<span class="sd">    ...         &quot;A&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;B&quot;: np.random.randint(0, 2, 100),</span>
<span class="sd">    ...         &quot;C&quot;: np.random.randn(100),</span>
<span class="sd">    ...     }</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; score = BICCondGauss(data)</span>
<span class="sd">    &gt;&gt;&gt; s = score.local_score(&quot;A&quot;, [&quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">    &gt;&gt;&gt; print(s)</span>
<span class="sd">    -115.37</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the log-likelihood or number of parameters cannot be computed for the provided variables.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Andrews, B., Ramsey, J., &amp; Cooper, G. F. (2018). Scoring Bayesian</span>
<span class="sd">        Networks of Mixed Variables. International journal of data science and</span>
<span class="sd">        analytics, 6(1), 3–18. https://doi.org/10.1007/s41060-017-0085-7</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BICCondGauss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="BICCondGauss.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.BICCondGauss.local_score">[docs]</a>
    <span class="k">def</span> <span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local BIC score for a variable and its parent set in a mixed Bayesian network.</span>

<span class="sd">        The score is calculated as the log-likelihood minus a complexity penalty, which</span>
<span class="sd">        is proportional to the number of free parameters and the log of the sample size.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local BICCondGauss score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; s = score.local_score(&quot;A&quot;, [&quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; print(s)</span>
<span class="sd">        -115.37</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the log-likelihood or parameter count cannot be computed for the given configuration.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">ll</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_num_parameters</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ll</span> <span class="o">-</span> <span class="p">((</span><span class="n">k</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span></div>
</div>



<div class="viewcode-block" id="AICCondGauss">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.AICCondGauss">[docs]</a>
<span class="k">class</span> <span class="nc">AICCondGauss</span><span class="p">(</span><span class="n">LogLikelihoodCondGauss</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    AIC (Akaike Information Criterion) score for Bayesian networks with mixed (discrete and continuous) variables.</span>

<span class="sd">    The AICCondGauss score evaluates network structures by penalizing the conditional log-likelihood</span>
<span class="sd">    with a term equal to the number of free parameters. This generalizes the classic AIC</span>
<span class="sd">    to handle Bayesian networks with both discrete and continuous variables [1].</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : pandas.DataFrame</span>
<span class="sd">        DataFrame where columns may be discrete or continuous variables.</span>

<span class="sd">    state_names : dict, optional</span>
<span class="sd">        Dictionary mapping discrete variable names to possible states.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pgmpy.estimators import AICCondGauss</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">    ...     {</span>
<span class="sd">    ...         &quot;A&quot;: np.random.randn(100),</span>
<span class="sd">    ...         &quot;B&quot;: np.random.randint(0, 2, 100),</span>
<span class="sd">    ...         &quot;C&quot;: np.random.randn(100),</span>
<span class="sd">    ...     }</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; score = AICCondGauss(data)</span>
<span class="sd">    &gt;&gt;&gt; s = score.local_score(&quot;A&quot;, [&quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">    &gt;&gt;&gt; print(s)</span>
<span class="sd">    -99.75</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the log-likelihood or number of parameters cannot be computed for the provided variables.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Andrews, B., Ramsey, J., &amp; Cooper, G. F. (2018). Scoring Bayesian</span>
<span class="sd">        Networks of Mixed Variables. International journal of data science and</span>
<span class="sd">        analytics, 6(1), 3–18. https://doi.org/10.1007/s41060-017-0085-7</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AICCondGauss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="AICCondGauss.local_score">
<a class="viewcode-back" href="../../../structure_estimator/hill.html#pgmpy.estimators.AICCondGauss.local_score">[docs]</a>
    <span class="k">def</span> <span class="nf">local_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the local AIC score for a variable and its parent set in a mixed Bayesian network.</span>

<span class="sd">        The score is calculated as the log-likelihood minus the number of free parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        variable : str</span>
<span class="sd">            The name of the variable (node) for which the local score is to be computed.</span>
<span class="sd">        parents : list of str</span>
<span class="sd">            List of variable names considered as parents of `variable`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            The local AICCondGauss score for the specified variable and parent configuration.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; s = score.local_score(&quot;A&quot;, [&quot;B&quot;, &quot;C&quot;])</span>
<span class="sd">        &gt;&gt;&gt; print(s)</span>
<span class="sd">        -99.75</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the log-likelihood or parameter count cannot be computed for the given configuration.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ll</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_num_parameters</span><span class="p">(</span><span class="n">variable</span><span class="o">=</span><span class="n">variable</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="n">parents</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ll</span> <span class="o">-</span> <span class="n">k</span></div>
</div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../../../index.html">
    <img class="logo" src="../../../_static/logo.png" alt="Logo" />
    
  </a>
</p>









<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../started/base.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/base.html">Supported Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../factors/base.html">Parameterization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../infer/base.html">Probabilistic Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../causal_infer/base.html">Causal Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../param_estimator/base.html">Parameter Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../structure_estimator/base.html">Causal Discovery / Structure Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../metrics/metrics.html">Metrics for Testing Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../readwrite/base.html">Reading/Writing to File</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../plotting.html">Plotting Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial.html">Tutorial Notebooks</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  <li><a href="../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div><script async src="https://media.ethicalads.io/media/client/ethicalads.min.js"></script>

<div data-ea-publisher="pgmpyorg" data-ea-type="image" data-ea-style="horizontal"></div><script async src="https://www.googletagmanager.com/gtag/js?id=G-HCFR07M31W"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-HCFR07M31W');
</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2025, Ankur Ankan.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.2.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
    </div>

    

    
  </body>
</html>