

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pgmpy.estimators.MmhcEstimator &mdash; pgmpy 0.1.15 documentation</title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home" alt="Documentation Home"> pgmpy
          

          
          </a>

          
            
            
              <div class="version">
                dev branch
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../started/install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../started/contributing.html">Contributing to pgmpy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../started/license.html">License</a></li>
</ul>
<p class="caption"><span class="caption-text">Base Structures</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../base/base.html">Directed Acyclic Graph (DAG)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../base/base.html#module-pgmpy.base.PDAG">Partial Directed Acyclic Graph (PDAG)</a></li>
</ul>
<p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../models/bayesiannetwork.html">Bayesian Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/dbn.html">Dynamic Bayesian Network (DBN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/sem.html">Structural Equation Models (SEM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/naive.html">Naive Bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/noisyor.html">NoisyOr Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/markovnetwork.html">Markov Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/junctiontree.html">Junction Tree</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/clustergraph.html">Cluster Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/factorgraph.html">Factor Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/markovchain.html">Markov Chain</a></li>
</ul>
<p class="caption"><span class="caption-text">Parameterization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../factors/discrete.html">Discrete</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../factors/continuous.html">Continuous</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../factors/discretize.html">Discretizing Methods</a></li>
</ul>
<p class="caption"><span class="caption-text">Exact Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../exact_infer/ve.html">Variable Elimination</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exact_infer/ve.html#elimination-ordering">Elimination Ordering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exact_infer/bp.html">Belief Propagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exact_infer/causal.html">Causal Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exact_infer/mplp.html">MPLP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exact_infer/dbn_infer.html">Dynamic Bayesian Network Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../exact_infer/model_testing.html">Model Testing</a></li>
</ul>
<p class="caption"><span class="caption-text">Approximate Inference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../approx_infer/bn_sampling.html">Bayesian Model Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../approx_infer/gibbs.html">Gibbs Sampling</a></li>
</ul>
<p class="caption"><span class="caption-text">Parameter Estimation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../param_estimator/mle.html">Maximum Likelihood Estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../param_estimator/bayesian_est.html">Bayesian Estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../param_estimator/em.html">Expectation Maximization (EM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../param_estimator/sem_estimator.html">Structural Equation Model Estimators</a></li>
</ul>
<p class="caption"><span class="caption-text">Structure Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../structure_estimator/pc.html">PC (Constraint-Based Estimator)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../structure_estimator/pc.html#conditional-independence-tests-for-pc-algorithm">Conditional Independence Tests for PC algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../structure_estimator/hill.html">Hill Climb Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../structure_estimator/hill.html#structure-score">Structure Score</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../structure_estimator/tree.html">Tree Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../structure_estimator/mmhc.html">Mmhc Estimator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../structure_estimator/exhaustive.html">Exhaustive Search</a></li>
</ul>
<p class="caption"><span class="caption-text">Metrics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../metrics/metrics.html">Correlation Score</a></li>
</ul>
<p class="caption"><span class="caption-text">Input/Output</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../readwrite/bif.html">BIF (Bayesian Interchange Format)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../readwrite/uai.html">UAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../readwrite/xmlbif.html">XMLBIF</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../readwrite/pomdpx.html">PomdpX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../readwrite/xmlbelief.html">XMLBeliefNetwork</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">pgmpy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>pgmpy.estimators.MmhcEstimator</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for pgmpy.estimators.MmhcEstimator</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python</span>
<span class="kn">from</span> <span class="nn">pgmpy.utils.mathext</span> <span class="kn">import</span> <span class="n">powerset</span>
<span class="kn">from</span> <span class="nn">pgmpy.base</span> <span class="kn">import</span> <span class="n">UndirectedGraph</span>
<span class="kn">from</span> <span class="nn">pgmpy.models</span> <span class="kn">import</span> <span class="n">BayesianModel</span>
<span class="kn">from</span> <span class="nn">pgmpy.estimators</span> <span class="kn">import</span> <span class="n">StructureEstimator</span><span class="p">,</span> <span class="n">HillClimbSearch</span><span class="p">,</span> <span class="n">BDeuScore</span>
<span class="kn">from</span> <span class="nn">pgmpy.independencies</span> <span class="kn">import</span> <span class="n">Independencies</span><span class="p">,</span> <span class="n">IndependenceAssertion</span>
<span class="kn">from</span> <span class="nn">pgmpy.estimators.CITests</span> <span class="kn">import</span> <span class="n">chi_square</span>


<div class="viewcode-block" id="MmhcEstimator"><a class="viewcode-back" href="../../../estimators.html#pgmpy.estimators.MmhcEstimator">[docs]</a><span class="k">class</span> <span class="nc">MmhcEstimator</span><span class="p">(</span><span class="n">StructureEstimator</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Implements the MMHC hybrid structure estimation procedure for</span>
<span class="sd">        learning BayesianModels from discrete data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data: pandas DataFrame object</span>
<span class="sd">            datafame object where each column represents one variable.</span>
<span class="sd">            (If some values in the data are missing the data cells should be set to `numpy.NaN`.</span>
<span class="sd">            Note that pandas converts each column containing `numpy.NaN`s to dtype `float`.)</span>

<span class="sd">        state_names: dict (optional)</span>
<span class="sd">            A dict indicating, for each variable, the discrete set of states (or values)</span>
<span class="sd">            that the variable can take. If unspecified, the observed values in the data set</span>
<span class="sd">            are taken to be the only possible states.</span>

<span class="sd">        complete_samples_only: bool (optional, default `True`)</span>
<span class="sd">            Specifies how to deal with missing data, if present. If set to `True` all rows</span>
<span class="sd">            that contain `np.Nan` somewhere are ignored. If `False` then, for each variable,</span>
<span class="sd">            every row where neither the variable nor its parents are `np.NaN` is used.</span>
<span class="sd">            This sets the behavior of the `state_count`-method.</span>

<span class="sd">        Reference</span>
<span class="sd">        ---------</span>
<span class="sd">        Tsamardinos et al., The max-min hill-climbing Bayesian network structure learning algorithm (2005)</span>
<span class="sd">        http://www.dsl-lab.org/supplements/mmhc_paper/paper_online.pdf</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MmhcEstimator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="MmhcEstimator.estimate"><a class="viewcode-back" href="../../../estimators.html#pgmpy.estimators.MmhcEstimator.estimate">[docs]</a>    <span class="k">def</span> <span class="nf">estimate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scoring_method</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tabu_length</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Estimates a BayesianModel for the data set, using MMHC. First estimates a</span>
<span class="sd">        graph skeleton using MMPC and then orients the edges using score-based local</span>
<span class="sd">        search (hill climbing).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        significance_level: float, default: 0.01</span>
<span class="sd">            The significance level to use for conditional independence tests in the data set. See `mmpc`-method.</span>

<span class="sd">        scoring_method: instance of a Scoring method (default: BDeuScore)</span>
<span class="sd">            The method to use for scoring during Hill Climb Search. Can be an instance of any of the</span>
<span class="sd">            scoring methods implemented in pgmpy.</span>

<span class="sd">        tabu_length: int</span>
<span class="sd">            If provided, the last `tabu_length` graph modifications cannot be reversed</span>
<span class="sd">            during the search procedure. This serves to enforce a wider exploration</span>
<span class="sd">            of the search space. Default value: 100.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        model: BayesianModel()-instance, not yet parametrized.</span>

<span class="sd">        Reference</span>
<span class="sd">        ---------</span>
<span class="sd">        Tsamardinos et al., The max-min hill-climbing Bayesian network structure learning algorithm (2005),</span>
<span class="sd">        Algorithm 3</span>
<span class="sd">        http://www.dsl-lab.org/supplements/mmhc_paper/paper_online.pdf</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.estimators import PC</span>
<span class="sd">        &gt;&gt;&gt; data = pd.DataFrame(np.random.randint(0, 2, size=(2500, 4)), columns=list(&#39;XYZW&#39;))</span>
<span class="sd">        &gt;&gt;&gt; data[&#39;sum&#39;] = data.sum(axis=1)</span>
<span class="sd">        &gt;&gt;&gt; est = MmhcEstimator(data)</span>
<span class="sd">        &gt;&gt;&gt; model = est.estimate()</span>
<span class="sd">        &gt;&gt;&gt; print(model.edges())</span>
<span class="sd">        [(&#39;Z&#39;, &#39;sum&#39;), (&#39;X&#39;, &#39;sum&#39;), (&#39;W&#39;, &#39;sum&#39;), (&#39;Y&#39;, &#39;sum&#39;)]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">scoring_method</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">scoring_method</span> <span class="o">=</span> <span class="n">BDeuScore</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">equivalent_sample_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

        <span class="n">skel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mmpc</span><span class="p">(</span><span class="n">significance_level</span><span class="p">)</span>

        <span class="n">hc</span> <span class="o">=</span> <span class="n">HillClimbSearch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">hc</span><span class="o">.</span><span class="n">estimate</span><span class="p">(</span>
            <span class="n">scoring_method</span><span class="o">=</span><span class="n">scoring_method</span><span class="p">,</span>
            <span class="n">white_list</span><span class="o">=</span><span class="n">skel</span><span class="o">.</span><span class="n">to_directed</span><span class="p">()</span><span class="o">.</span><span class="n">edges</span><span class="p">(),</span>
            <span class="n">tabu_length</span><span class="o">=</span><span class="n">tabu_length</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">model</span></div>

<div class="viewcode-block" id="MmhcEstimator.mmpc"><a class="viewcode-back" href="../../../estimators.html#pgmpy.estimators.MmhcEstimator.mmpc">[docs]</a>    <span class="k">def</span> <span class="nf">mmpc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">significance_level</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Estimates a graph skeleton (UndirectedGraph) for the data set, using then</span>
<span class="sd">        MMPC (max-min parents-and-children) algorithm.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        significance_level: float, default=0.01</span>
<span class="sd">            The significance level to use for conditional independence tests in the data set.</span>

<span class="sd">            `significance_level` is the desired Type 1 error probability of</span>
<span class="sd">            falsely rejecting the null hypothesis that variables are independent,</span>
<span class="sd">            given that they are. The lower `significance_level`, the less likely</span>
<span class="sd">            we are to accept dependencies, resulting in a sparser graph.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        skeleton: UndirectedGraph</span>
<span class="sd">            An estimate for the undirected graph skeleton of the BN underlying the data.</span>
<span class="sd">        seperating_sets: dict</span>
<span class="sd">            A dict containing for each pair of not directly connected nodes a</span>
<span class="sd">            seperating set (&quot;witnessing set&quot;) of variables that makes then</span>
<span class="sd">            conditionally independent. (needed for edge orientation)</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        Tsamardinos et al., The max-min hill-climbing Bayesian network structure</span>
<span class="sd">        learning algorithm (2005), Algorithm 1 &amp; 2</span>
<span class="sd">        http://www.dsl-lab.org/supplements/mmhc_paper/paper_online.pdf</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from pgmpy.estimators import PC</span>
<span class="sd">        &gt;&gt;&gt; data = pd.DataFrame(np.random.randint(0, 2, size=(5000, 5)), columns=list(&#39;ABCDE&#39;))</span>
<span class="sd">        &gt;&gt;&gt; data[&#39;F&#39;] = data[&#39;A&#39;] + data[&#39;B&#39;] + data [&#39;C&#39;]</span>
<span class="sd">        &gt;&gt;&gt; est = PC(data)</span>
<span class="sd">        &gt;&gt;&gt; skel, sep_sets = est.estimate_skeleton()</span>
<span class="sd">        &gt;&gt;&gt; skel.edges()</span>
<span class="sd">        [(&#39;A&#39;, &#39;F&#39;), (&#39;B&#39;, &#39;F&#39;), (&#39;C&#39;, &#39;F&#39;)]</span>
<span class="sd">        &gt;&gt;&gt; # all independencies are unconditional:</span>
<span class="sd">        &gt;&gt;&gt; sep_sets</span>
<span class="sd">        {(&#39;D&#39;, &#39;A&#39;): (), (&#39;C&#39;, &#39;A&#39;): (), (&#39;C&#39;, &#39;E&#39;): (), (&#39;E&#39;, &#39;F&#39;): (), (&#39;B&#39;, &#39;D&#39;): (),</span>
<span class="sd">         (&#39;B&#39;, &#39;E&#39;): (), (&#39;D&#39;, &#39;F&#39;): (), (&#39;D&#39;, &#39;E&#39;): (), (&#39;A&#39;, &#39;E&#39;): (), (&#39;B&#39;, &#39;A&#39;): (),</span>
<span class="sd">         (&#39;B&#39;, &#39;C&#39;): (), (&#39;C&#39;, &#39;D&#39;): ()}</span>
<span class="sd">        &gt;&gt;&gt; data = pd.DataFrame(np.random.randint(0, 2, size=(5000, 3)), columns=list(&#39;XYZ&#39;))</span>
<span class="sd">        &gt;&gt;&gt; data[&#39;X&#39;] += data[&#39;Z&#39;]</span>
<span class="sd">        &gt;&gt;&gt; data[&#39;Y&#39;] += data[&#39;Z&#39;]</span>
<span class="sd">        &gt;&gt;&gt; est = PC(data)</span>
<span class="sd">        &gt;&gt;&gt; skel, sep_sets = est.estimate_skeleton()</span>
<span class="sd">        &gt;&gt;&gt; skel.edges()</span>
<span class="sd">        [(&#39;X&#39;, &#39;Z&#39;), (&#39;Y&#39;, &#39;Z&#39;)]</span>
<span class="sd">        &gt;&gt;&gt; # X, Y dependent, but conditionally independent given Z:</span>
<span class="sd">        &gt;&gt;&gt; sep_sets</span>
<span class="sd">        {(&#39;X&#39;, &#39;Y&#39;): (&#39;Z&#39;,)}</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">nodes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_names</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>

        <span class="k">def</span> <span class="nf">assoc</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Zs</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Measure for (conditional) association between variables. Use negative</span>
<span class="sd">            p-value of independence test.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">chi_square</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Zs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">def</span> <span class="nf">min_assoc</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Zs</span><span class="p">):</span>
            <span class="s2">&quot;Minimal association of X, Y given any subset of Zs.&quot;</span>
            <span class="k">return</span> <span class="nb">min</span><span class="p">(</span><span class="n">assoc</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Zs_subset</span><span class="p">)</span> <span class="k">for</span> <span class="n">Zs_subset</span> <span class="ow">in</span> <span class="n">powerset</span><span class="p">(</span><span class="n">Zs</span><span class="p">))</span>

        <span class="k">def</span> <span class="nf">max_min_heuristic</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Zs</span><span class="p">):</span>
            <span class="s2">&quot;Finds variable that maximizes min_assoc with `node` relative to `neighbors`.&quot;</span>
            <span class="n">max_min_assoc</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">best_Y</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">for</span> <span class="n">Y</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">Zs</span> <span class="o">+</span> <span class="p">[</span><span class="n">X</span><span class="p">]):</span>
                <span class="n">min_assoc_val</span> <span class="o">=</span> <span class="n">min_assoc</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Zs</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">min_assoc_val</span> <span class="o">&gt;=</span> <span class="n">max_min_assoc</span><span class="p">:</span>
                    <span class="n">best_Y</span> <span class="o">=</span> <span class="n">Y</span>
                    <span class="n">max_min_assoc</span> <span class="o">=</span> <span class="n">min_assoc_val</span>

            <span class="k">return</span> <span class="p">(</span><span class="n">best_Y</span><span class="p">,</span> <span class="n">max_min_assoc</span><span class="p">)</span>

        <span class="c1"># Find parents and children for each node</span>
        <span class="n">neighbors</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
            <span class="n">neighbors</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="c1"># Forward Phase</span>
            <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">new_neighbor</span><span class="p">,</span> <span class="n">new_neighbor_min_assoc</span> <span class="o">=</span> <span class="n">max_min_heuristic</span><span class="p">(</span>
                    <span class="n">node</span><span class="p">,</span> <span class="n">neighbors</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">new_neighbor_min_assoc</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">neighbors</span><span class="p">[</span><span class="n">node</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_neighbor</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">break</span>

            <span class="c1"># Backward Phase</span>
            <span class="k">for</span> <span class="n">neigh</span> <span class="ow">in</span> <span class="n">neighbors</span><span class="p">[</span><span class="n">node</span><span class="p">]:</span>
                <span class="n">other_neighbors</span> <span class="o">=</span> <span class="p">[</span><span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">neighbors</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="k">if</span> <span class="n">n</span> <span class="o">!=</span> <span class="n">neigh</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">sep_set</span> <span class="ow">in</span> <span class="n">powerset</span><span class="p">(</span><span class="n">other_neighbors</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">chi_square</span><span class="p">(</span>
                        <span class="n">X</span><span class="o">=</span><span class="n">node</span><span class="p">,</span>
                        <span class="n">Y</span><span class="o">=</span><span class="n">neigh</span><span class="p">,</span>
                        <span class="n">Z</span><span class="o">=</span><span class="n">sep_set</span><span class="p">,</span>
                        <span class="n">data</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
                        <span class="n">significance_level</span><span class="o">=</span><span class="n">significance_level</span><span class="p">,</span>
                    <span class="p">):</span>
                        <span class="n">neighbors</span><span class="p">[</span><span class="n">node</span><span class="p">]</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">neigh</span><span class="p">)</span>
                        <span class="k">break</span>

        <span class="c1"># correct for false positives</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">neigh</span> <span class="ow">in</span> <span class="n">neighbors</span><span class="p">[</span><span class="n">node</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">node</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">neighbors</span><span class="p">[</span><span class="n">neigh</span><span class="p">]:</span>
                    <span class="n">neighbors</span><span class="p">[</span><span class="n">node</span><span class="p">]</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">neigh</span><span class="p">)</span>

        <span class="n">skel</span> <span class="o">=</span> <span class="n">UndirectedGraph</span><span class="p">()</span>
        <span class="n">skel</span><span class="o">.</span><span class="n">add_nodes_from</span><span class="p">(</span><span class="n">nodes</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
            <span class="n">skel</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">([(</span><span class="n">node</span><span class="p">,</span> <span class="n">neigh</span><span class="p">)</span> <span class="k">for</span> <span class="n">neigh</span> <span class="ow">in</span> <span class="n">neighbors</span><span class="p">[</span><span class="n">node</span><span class="p">]])</span>

        <span class="k">return</span> <span class="n">skel</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2021, Ankur Ankan

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-177825880-1', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>