<!DOCTYPE html>

<html lang="en" data-content_root="../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>pgmpy.estimators.CITests &#8212; 1.0.0 | pgmpy docs</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/alabaster.css?v=7b53859b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <script src="../../../_static/documentation_options.js?v=8d563738"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="canonical" href="https://pgmpy.org/_modules/pgmpy/estimators/CITests.html" />
    <link rel="icon" href="../../../_static/logo_favi.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for pgmpy.estimators.CITests</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Callable</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_decomposition</span> <span class="kn">import</span> <span class="n">CCA</span>

<span class="kn">from</span> <span class="nn">pgmpy.global_vars</span> <span class="kn">import</span> <span class="n">logger</span>
<span class="kn">from</span> <span class="nn">pgmpy.independencies</span> <span class="kn">import</span> <span class="n">IndependenceAssertion</span>
<span class="kn">from</span> <span class="nn">pgmpy.utils</span> <span class="kn">import</span> <span class="n">get_dataset_type</span>


<span class="k">def</span> <span class="nf">get_callable_ci_test</span><span class="p">(</span>
    <span class="n">test</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">Callable</span><span class="p">],</span>
    <span class="n">full</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">independencies</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
    <span class="c1"># renamed to specify you are obtaining a Callable</span>
    <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">test</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">test</span>

    <span class="n">supported_tests</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;continuous&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;pearsonr&quot;</span><span class="p">:</span> <span class="n">pearsonr</span><span class="p">,</span>
            <span class="s2">&quot;gcm&quot;</span><span class="p">:</span> <span class="n">gcm</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;discrete&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;chi_square&quot;</span><span class="p">:</span> <span class="n">chi_square</span><span class="p">,</span>
            <span class="s2">&quot;g_sq&quot;</span><span class="p">:</span> <span class="n">g_sq</span><span class="p">,</span>
            <span class="s2">&quot;log_likelihood&quot;</span><span class="p">:</span> <span class="n">log_likelihood</span><span class="p">,</span>
            <span class="s2">&quot;modified_log_likelihood&quot;</span><span class="p">:</span> <span class="n">modified_log_likelihood</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s2">&quot;mixed&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;pillai&quot;</span><span class="p">:</span> <span class="n">pillai_trace</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">}</span>
    <span class="n">flattened_supported_methods</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">key</span><span class="p">:</span> <span class="n">value</span>
        <span class="k">for</span> <span class="n">subdict</span> <span class="ow">in</span> <span class="n">supported_tests</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">subdict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Automatically determine method</span>
            <span class="n">var_type</span> <span class="o">=</span> <span class="n">get_dataset_type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">test</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">supported_tests</span><span class="p">[</span><span class="n">var_type</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot determine a suitable CI test for the data. &quot;</span>
                <span class="s2">&quot;Please specify CI test to use&quot;</span>
            <span class="p">)</span>

    <span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">full</span><span class="p">:</span>
        <span class="n">flattened_supported_methods</span><span class="p">[</span><span class="s2">&quot;power_divergence&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">power_divergence</span>
        <span class="n">flattened_supported_methods</span><span class="p">[</span><span class="s2">&quot;independence_match&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">independence_match</span>

    <span class="k">if</span> <span class="n">test</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">flattened_supported_methods</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;ci_test must either be one of </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">flattened_supported_methods</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">, or a function. Got: </span><span class="si">{</span><span class="n">test</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">full</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">test</span> <span class="o">==</span> <span class="s2">&quot;independence_match&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">independencies</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;For using independence_match, independencies argument must be specified&quot;</span>
                <span class="p">)</span>
        <span class="k">elif</span> <span class="n">data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;For using Chi Square or Pearsonr, data argument must be specified&quot;</span>
            <span class="p">)</span>

    <span class="k">return</span> <span class="n">flattened_supported_methods</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>


<div class="viewcode-block" id="independence_match">
<a class="viewcode-back" href="../../../structure_estimator/pc.html#pgmpy.estimators.CITests.independence_match">[docs]</a>
<span class="k">def</span> <span class="nf">independence_match</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">independencies</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Checks if `X \u27c2 Y | Z` is in `independencies`. This method is implemented to</span>
<span class="sd">    have an uniform API when the independencies are provided instead of data.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: str</span>
<span class="sd">        The first variable for testing the independence condition X \u27c2 Y | Z</span>

<span class="sd">    Y: str</span>
<span class="sd">        The second variable for testing the independence condition X \u27c2 Y | Z</span>

<span class="sd">    Z: list/array-like</span>
<span class="sd">        A list of conditional variable for testing the condition X \u27c2 Y | Z</span>

<span class="sd">    data: pandas.DataFrame The dataset in which to test the independence condition.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    p-value: float (Fixed to 0 since it is always confident)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">IndependenceAssertion</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">)</span> <span class="ow">in</span> <span class="n">independencies</span></div>



<div class="viewcode-block" id="chi_square">
<a class="viewcode-back" href="../../../structure_estimator/pc.html#pgmpy.estimators.CITests.chi_square">[docs]</a>
<span class="k">def</span> <span class="nf">chi_square</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Chi-square conditional independence test.</span>
<span class="sd">    Tests the null hypothesis that X is independent from Y given Zs.</span>

<span class="sd">    This is done by comparing the observed frequencies with the expected</span>
<span class="sd">    frequencies if X,Y were conditionally independent, using a chisquare</span>
<span class="sd">    deviance statistic. The expected frequencies given independence are</span>
<span class="sd">    :math:`P(X,Y,Zs) = P(X|Zs)*P(Y|Zs)*P(Zs)`. The latter term can be computed</span>
<span class="sd">    as :math:`P(X,Zs)*P(Y,Zs)/P(Zs).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: int, string, hashable object</span>
<span class="sd">        A variable name contained in the data set</span>

<span class="sd">    Y: int, string, hashable object</span>
<span class="sd">        A variable name contained in the data set, different from X</span>

<span class="sd">    Z: list, array-like</span>
<span class="sd">        A list of variable names contained in the data set, different from X and Y.</span>
<span class="sd">        This is the separating set that (potentially) makes X and Y independent.</span>
<span class="sd">        Default: []</span>

<span class="sd">    data: pandas.DataFrame</span>
<span class="sd">        The dataset on which to test the independence condition.</span>

<span class="sd">    boolean: bool</span>
<span class="sd">        If boolean=True, an additional argument `significance_level` must</span>
<span class="sd">        be specified. If p_value of the test is greater than equal to</span>
<span class="sd">        `significance_level`, returns True. Otherwise returns False.</span>
<span class="sd">        If boolean=False, returns the chi2 and p_value of the test.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    CI Test Results: tuple or bool</span>
<span class="sd">        If boolean = False, Returns a tuple (chi, p_value, dof). `chi` is the</span>
<span class="sd">        chi-squared test statistic. The `p_value` for the test, i.e. the</span>
<span class="sd">        probability of observing the computed chi-square statistic (or an even</span>
<span class="sd">        higher value), given the null hypothesis that X \u27c2 Y | Zs is True.</span>
<span class="sd">        If boolean = True, returns True if the p_value of the test is greater</span>
<span class="sd">        than `significance_level` else returns False.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] https://en.wikipedia.org/wiki/Chi-squared_test</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; np.random.seed(42)</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">    ...     np.random.randint(0, 2, size=(50000, 4)), columns=list(&quot;ABCD&quot;)</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; data[&quot;E&quot;] = data[&quot;A&quot;] + data[&quot;B&quot;] + data[&quot;C&quot;]</span>
<span class="sd">    &gt;&gt;&gt; chi_square(X=&quot;A&quot;, Y=&quot;C&quot;, Z=[], data=data, boolean=True, significance_level=0.05)</span>
<span class="sd">    np.True_</span>
<span class="sd">    &gt;&gt;&gt; chi_square(</span>
<span class="sd">    ...     X=&quot;A&quot;, Y=&quot;B&quot;, Z=[&quot;D&quot;], data=data, boolean=True, significance_level=0.05</span>
<span class="sd">    ... )</span>
<span class="sd">    np.True_</span>
<span class="sd">    &gt;&gt;&gt; chi_square(</span>
<span class="sd">    ...     X=&quot;A&quot;, Y=&quot;B&quot;, Z=[&quot;D&quot;, &quot;E&quot;], data=data, boolean=True, significance_level=0.05</span>
<span class="sd">    ... )</span>
<span class="sd">    np.False_</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">power_divergence</span><span class="p">(</span>
        <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="n">boolean</span><span class="p">,</span> <span class="n">lambda_</span><span class="o">=</span><span class="s2">&quot;pearson&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="g_sq">
<a class="viewcode-back" href="../../../structure_estimator/pc.html#pgmpy.estimators.CITests.g_sq">[docs]</a>
<span class="k">def</span> <span class="nf">g_sq</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    G squared test for conditional independence. Also commonly known as G-test,</span>
<span class="sd">    likelihood-ratio or maximum likelihood statistical significance test.</span>
<span class="sd">    Tests the null hypothesis that X is independent of Y given Zs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: int, string, hashable object</span>
<span class="sd">        A variable name contained in the data set</span>

<span class="sd">    Y: int, string, hashable object</span>
<span class="sd">        A variable name contained in the data set, different from X</span>

<span class="sd">    Z: list (array-like)</span>
<span class="sd">        A list of variable names contained in the data set, different from X and Y.</span>
<span class="sd">        This is the separating set that (potentially) makes X and Y independent.</span>
<span class="sd">        Default: []</span>

<span class="sd">    data: pandas.DataFrame</span>
<span class="sd">        The dataset on which to test the independence condition.</span>

<span class="sd">    boolean: bool</span>
<span class="sd">        If boolean=True, an additional argument `significance_level` must be</span>
<span class="sd">        specified. If p_value of the test is greater than equal to</span>
<span class="sd">        `significance_level`, returns True. Otherwise returns False. If</span>
<span class="sd">        boolean=False, returns the chi2 and p_value of the test.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    CI Test Results: tuple or bool</span>
<span class="sd">        If boolean = False, Returns a tuple (chi, p_value, dof). `chi` is the</span>
<span class="sd">        chi-squared test statistic. The `p_value` for the test, i.e. the</span>
<span class="sd">        probability of observing the computed chi-square statistic (or an even</span>
<span class="sd">        higher value), given the null hypothesis that X \u27c2 Y | Zs is True.</span>
<span class="sd">        If boolean = True, returns True if the p_value of the test is greater</span>
<span class="sd">        than `significance_level` else returns False.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] https://en.wikipedia.org/wiki/G-test</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; np.random.seed(42)</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">    ...     np.random.randint(0, 2, size=(50000, 4)), columns=list(&quot;ABCD&quot;)</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; data[&quot;E&quot;] = data[&quot;A&quot;] + data[&quot;B&quot;] + data[&quot;C&quot;]</span>
<span class="sd">    &gt;&gt;&gt; g_sq(X=&quot;A&quot;, Y=&quot;C&quot;, Z=[], data=data, boolean=True, significance_level=0.05)</span>
<span class="sd">    np.True_</span>
<span class="sd">    &gt;&gt;&gt; g_sq(X=&quot;A&quot;, Y=&quot;B&quot;, Z=[&quot;D&quot;], data=data, boolean=True, significance_level=0.05)</span>
<span class="sd">    np.True_</span>
<span class="sd">    &gt;&gt;&gt; g_sq(</span>
<span class="sd">    ...     X=&quot;A&quot;, Y=&quot;B&quot;, Z=[&quot;D&quot;, &quot;E&quot;], data=data, boolean=True, significance_level=0.05</span>
<span class="sd">    ... )</span>
<span class="sd">    np.False_</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">power_divergence</span><span class="p">(</span>
        <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="n">boolean</span><span class="p">,</span> <span class="n">lambda_</span><span class="o">=</span><span class="s2">&quot;log-likelihood&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="log_likelihood">
<a class="viewcode-back" href="../../../structure_estimator/pc.html#pgmpy.estimators.CITests.log_likelihood">[docs]</a>
<span class="k">def</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Log likelihood ratio test for conditional independence. Also commonly known</span>
<span class="sd">    as G-test, G-squared test or maximum likelihood statistical significance</span>
<span class="sd">    test.  Tests the null hypothesis that X is independent of Y given Zs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: int, string, hashable object</span>
<span class="sd">        A variable name contained in the data set</span>

<span class="sd">    Y: int, string, hashable object</span>
<span class="sd">        A variable name contained in the data set, different from X</span>

<span class="sd">    Z: list (array-like)</span>
<span class="sd">        A list of variable names contained in the data set, different from X and Y.</span>
<span class="sd">        This is the separating set that (potentially) makes X and Y independent.</span>
<span class="sd">        Default: []</span>

<span class="sd">    data: pandas.DataFrame</span>
<span class="sd">        The dataset on which to test the independence condition.</span>

<span class="sd">    boolean: bool</span>
<span class="sd">        If boolean=True, an additional argument `significance_level` must be</span>
<span class="sd">        specified. If p_value of the test is greater than equal to</span>
<span class="sd">        `significance_level`, returns True. Otherwise returns False.  If</span>
<span class="sd">        boolean=False, returns the chi2 and p_value of the test.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    CI Test Results: tuple or bool</span>
<span class="sd">        If boolean = False, Returns a tuple (chi, p_value, dof). `chi` is the</span>
<span class="sd">        chi-squared test statistic. The `p_value` for the test, i.e. the</span>
<span class="sd">        probability of observing the computed chi-square statistic (or an even</span>
<span class="sd">        higher value), given the null hypothesis that X \u27c2 Y | Zs is True.</span>
<span class="sd">        If boolean = True, returns True if the p_value of the test is greater</span>
<span class="sd">        than `significance_level` else returns False.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] https://en.wikipedia.org/wiki/G-test</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; np.random.seed(42)</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">    ...     np.random.randint(0, 2, size=(50000, 4)), columns=list(&quot;ABCD&quot;)</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; data[&quot;E&quot;] = data[&quot;A&quot;] + data[&quot;B&quot;] + data[&quot;C&quot;]</span>
<span class="sd">    &gt;&gt;&gt; log_likelihood(</span>
<span class="sd">    ...     X=&quot;A&quot;, Y=&quot;C&quot;, Z=[], data=data, boolean=True, significance_level=0.05</span>
<span class="sd">    ... )</span>
<span class="sd">    np.True_</span>
<span class="sd">    &gt;&gt;&gt; log_likelihood(</span>
<span class="sd">    ...     X=&quot;A&quot;, Y=&quot;B&quot;, Z=[&quot;D&quot;], data=data, boolean=True, significance_level=0.05</span>
<span class="sd">    ... )</span>
<span class="sd">    np.True_</span>
<span class="sd">    &gt;&gt;&gt; log_likelihood(</span>
<span class="sd">    ...     X=&quot;A&quot;, Y=&quot;B&quot;, Z=[&quot;D&quot;, &quot;E&quot;], data=data, boolean=True, significance_level=0.05</span>
<span class="sd">    ... )</span>
<span class="sd">    np.False_</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">power_divergence</span><span class="p">(</span>
        <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="n">boolean</span><span class="p">,</span> <span class="n">lambda_</span><span class="o">=</span><span class="s2">&quot;log-likelihood&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="modified_log_likelihood">
<a class="viewcode-back" href="../../../structure_estimator/pc.html#pgmpy.estimators.CITests.modified_log_likelihood">[docs]</a>
<span class="k">def</span> <span class="nf">modified_log_likelihood</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Modified log likelihood ratio test for conditional independence.</span>
<span class="sd">    Tests the null hypothesis that X is independent of Y given Zs.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: int, string, hashable object</span>
<span class="sd">        A variable name contained in the data set</span>

<span class="sd">    Y: int, string, hashable object</span>
<span class="sd">        A variable name contained in the data set, different from X</span>

<span class="sd">    Z: list (array-like)</span>
<span class="sd">        A list of variable names contained in the data set, different from X and Y.</span>
<span class="sd">        This is the separating set that (potentially) makes X and Y independent.</span>
<span class="sd">        Default: []</span>

<span class="sd">    data: pandas.DataFrame</span>
<span class="sd">        The dataset on which to test the independence condition.</span>

<span class="sd">    boolean: bool</span>
<span class="sd">        If boolean=True, an additional argument `significance_level` must be</span>
<span class="sd">        specified. If p_value of the test is greater than equal to</span>
<span class="sd">        `significance_level`, returns True. Otherwise returns False.</span>
<span class="sd">        If boolean=False, returns the chi2 and p_value of the test.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    CI Test Results: tuple or bool</span>
<span class="sd">        If boolean = False, Returns a tuple (chi, p_value, dof). `chi` is the</span>
<span class="sd">        chi-squared test statistic. The `p_value` for the test, i.e. the</span>
<span class="sd">        probability of observing the computed chi-square statistic (or an even</span>
<span class="sd">        higher value), given the null hypothesis that X \u27c2 Y | Zs is True.</span>
<span class="sd">        If boolean = True, returns True if the p_value of the test is greater</span>
<span class="sd">        than `significance_level` else returns False.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; np.random.seed(42)</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">    ...     np.random.randint(0, 2, size=(50000, 4)), columns=list(&quot;ABCD&quot;)</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; data[&quot;E&quot;] = data[&quot;A&quot;] + data[&quot;B&quot;] + data[&quot;C&quot;]</span>
<span class="sd">    &gt;&gt;&gt; modified_log_likelihood(</span>
<span class="sd">    ...     X=&quot;A&quot;, Y=&quot;C&quot;, Z=[], data=data, boolean=True, significance_level=0.05</span>
<span class="sd">    ... )</span>
<span class="sd">    np.True_</span>
<span class="sd">    &gt;&gt;&gt; modified_log_likelihood(</span>
<span class="sd">    ...     X=&quot;A&quot;, Y=&quot;B&quot;, Z=[&quot;D&quot;], data=data, boolean=True, significance_level=0.05</span>
<span class="sd">    ... )</span>
<span class="sd">    np.True_</span>
<span class="sd">    &gt;&gt;&gt; modified_log_likelihood(</span>
<span class="sd">    ...     X=&quot;A&quot;, Y=&quot;B&quot;, Z=[&quot;D&quot;, &quot;E&quot;], data=data, boolean=True, significance_level=0.05</span>
<span class="sd">    ... )</span>
<span class="sd">    np.False_</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">power_divergence</span><span class="p">(</span>
        <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
        <span class="n">Y</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span>
        <span class="n">Z</span><span class="o">=</span><span class="n">Z</span><span class="p">,</span>
        <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
        <span class="n">boolean</span><span class="o">=</span><span class="n">boolean</span><span class="p">,</span>
        <span class="n">lambda_</span><span class="o">=</span><span class="s2">&quot;mod-log-likelihood&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="power_divergence">
<a class="viewcode-back" href="../../../structure_estimator/pc.html#pgmpy.estimators.CITests.power_divergence">[docs]</a>
<span class="k">def</span> <span class="nf">power_divergence</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">lambda_</span><span class="o">=</span><span class="s2">&quot;cressie-read&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the Cressie-Read power divergence statistic [1]. The null hypothesis</span>
<span class="sd">    for the test is X is independent of Y given Z. A lot of the frequency comparision</span>
<span class="sd">    based statistics (eg. chi-square, G-test etc) belong to power divergence family,</span>
<span class="sd">    and are special cases of this test.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: int, string, hashable object</span>
<span class="sd">        A variable name contained in the data set</span>

<span class="sd">    Y: int, string, hashable object</span>
<span class="sd">        A variable name contained in the data set, different from X</span>

<span class="sd">    Z: list, array-like</span>
<span class="sd">        A list of variable names contained in the data set, different from X and Y.</span>
<span class="sd">        This is the separating set that (potentially) makes X and Y independent.</span>
<span class="sd">        Default: []</span>

<span class="sd">    data: pandas.DataFrame</span>
<span class="sd">        The dataset on which to test the independence condition.</span>

<span class="sd">    lambda_: float or string</span>
<span class="sd">        The lambda parameter for the power_divergence statistic. Some values of</span>
<span class="sd">        lambda_ results in other well known tests:</span>
<span class="sd">            &quot;pearson&quot;             1          &quot;Chi-squared test&quot;</span>
<span class="sd">            &quot;log-likelihood&quot;      0          &quot;G-test or log-likelihood&quot;</span>
<span class="sd">            &quot;freeman-tuckey&quot;     -1/2        &quot;Freeman-Tuckey Statistic&quot;</span>
<span class="sd">            &quot;mod-log-likelihood&quot;  -1         &quot;Modified Log-likelihood&quot;</span>
<span class="sd">            &quot;neyman&quot;              -2         &quot;Neyman&#39;s statistic&quot;</span>
<span class="sd">            &quot;cressie-read&quot;        2/3        &quot;The value recommended in the paper[1]&quot;</span>

<span class="sd">    boolean: bool</span>
<span class="sd">        If boolean=True, an additional argument `significance_level` must</span>
<span class="sd">            be specified. If p_value of the test is greater than equal to</span>
<span class="sd">            `significance_level`, returns True. Otherwise returns False.</span>

<span class="sd">        If boolean=False, returns the chi2 and p_value of the test.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    CI Test Results: tuple or bool</span>
<span class="sd">        If boolean = False, Returns a tuple (chi, p_value, dof). `chi` is the</span>
<span class="sd">        chi-squared test statistic. The `p_value` for the test, i.e. the</span>
<span class="sd">        probability of observing the computed chi-square statistic (or an even</span>
<span class="sd">        higher value), given the null hypothesis that X \u27c2 Y | Zs is True.</span>
<span class="sd">        If boolean = True, returns True if the p_value of the test is greater</span>
<span class="sd">        than `significance_level` else returns False.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Cressie, Noel, and Timothy RC Read. &quot;Multinomial goodness‐of‐fit tests.&quot;</span>
<span class="sd">      Journal of the Royal Statistical Society: Series B (Methodological) 46.3 (1984): 440-464.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import pandas as pd</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; np.random.seed(42)</span>
<span class="sd">    &gt;&gt;&gt; data = pd.DataFrame(</span>
<span class="sd">    ...     np.random.randint(0, 2, size=(50000, 4)), columns=list(&quot;ABCD&quot;)</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; data[&quot;E&quot;] = data[&quot;A&quot;] + data[&quot;B&quot;] + data[&quot;C&quot;]</span>
<span class="sd">    &gt;&gt;&gt; chi_square(X=&quot;A&quot;, Y=&quot;C&quot;, Z=[], data=data, boolean=True, significance_level=0.05)</span>
<span class="sd">    np.True_</span>
<span class="sd">    &gt;&gt;&gt; chi_square(</span>
<span class="sd">    ...     X=&quot;A&quot;, Y=&quot;B&quot;, Z=[&quot;D&quot;], data=data, boolean=True, significance_level=0.05</span>
<span class="sd">    ... )</span>
<span class="sd">    np.True_</span>
<span class="sd">    &gt;&gt;&gt; chi_square(</span>
<span class="sd">    ...     X=&quot;A&quot;, Y=&quot;B&quot;, Z=[&quot;D&quot;, &quot;E&quot;], data=data, boolean=True, significance_level=0.05</span>
<span class="sd">    ... )</span>
<span class="sd">    np.False_</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Step 1: Check if the arguments are valid and type conversions.</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="s2">&quot;__iter__&quot;</span><span class="p">):</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Z must be an iterable. Got object type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">X</span> <span class="ow">in</span> <span class="n">Z</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">Y</span> <span class="ow">in</span> <span class="n">Z</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The variables X or Y can&#39;t be in Z. Found </span><span class="si">{</span><span class="n">X</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">X</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">Z</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="n">Y</span><span class="si">}</span><span class="s2"> in Z.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Step 2: Do a simple contingency test if there are no conditional variables.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">chi</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">dof</span><span class="p">,</span> <span class="n">expected</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">chi2_contingency</span><span class="p">(</span>
            <span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">],</span> <span class="n">observed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
            <span class="n">lambda_</span><span class="o">=</span><span class="n">lambda_</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># Step 3: If there are conditionals variables, iterate over unique states and do</span>
    <span class="c1">#         the contingency test.</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">chi</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">dof</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">z_state</span><span class="p">,</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="c1"># Compute the contingency table</span>
            <span class="n">unique_x</span><span class="p">,</span> <span class="n">x_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">X</span><span class="p">],</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">unique_y</span><span class="p">,</span> <span class="n">y_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">Y</span><span class="p">],</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">contingency</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span>
                <span class="n">x_inv</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_y</span><span class="p">)</span> <span class="o">+</span> <span class="n">y_inv</span><span class="p">,</span> <span class="n">minlength</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_x</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_y</span><span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_x</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_y</span><span class="p">))</span>

            <span class="c1"># If all values of a column in the contingency table are zeros, skip the test.</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">contingency</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">any</span><span class="p">(</span><span class="n">contingency</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">z_state</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Skipping the test </span><span class="si">{</span><span class="n">X</span><span class="si">}</span><span class="s2"> </span><span class="se">\u27c2</span><span class="s2"> </span><span class="si">{</span><span class="n">Y</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">Z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n">z_state</span><span class="si">}</span><span class="s2">. Not enough samples&quot;</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">z_str</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                        <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">var</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n">state</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">var</span><span class="p">,</span> <span class="n">state</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">z_state</span><span class="p">)]</span>
                    <span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Skipping the test </span><span class="si">{</span><span class="n">X</span><span class="si">}</span><span class="s2"> </span><span class="se">\u27c2</span><span class="s2"> </span><span class="si">{</span><span class="n">Y</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">z_str</span><span class="si">}</span><span class="s2">. Not enough samples&quot;</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">c</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">chi2_contingency</span><span class="p">(</span><span class="n">contingency</span><span class="p">,</span> <span class="n">lambda_</span><span class="o">=</span><span class="n">lambda_</span><span class="p">)</span>
                <span class="n">chi</span> <span class="o">+=</span> <span class="n">c</span>
                <span class="n">dof</span> <span class="o">+=</span> <span class="n">d</span>
        <span class="n">p_value</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">chi</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">)</span>

    <span class="c1"># Step 4: Return the values</span>
    <span class="k">if</span> <span class="n">boolean</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">p_value</span> <span class="o">&gt;=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;significance_level&quot;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">chi</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">dof</span></div>



<div class="viewcode-block" id="pearsonr">
<a class="viewcode-back" href="../../../structure_estimator/pc.html#pgmpy.estimators.CITests.pearsonr">[docs]</a>
<span class="k">def</span> <span class="nf">pearsonr</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes Pearson correlation coefficient and p-value for testing non-correlation.</span>
<span class="sd">    Should be used only on continuous data. In case when :math:`Z != \null` uses</span>
<span class="sd">    linear regression and computes pearson coefficient on residuals.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: str</span>
<span class="sd">        The first variable for testing the independence condition X \u27c2 Y | Z</span>

<span class="sd">    Y: str</span>
<span class="sd">        The second variable for testing the independence condition X \u27c2 Y | Z</span>

<span class="sd">    Z: list/array-like</span>
<span class="sd">        A list of conditional variable for testing the condition X \u27c2 Y | Z</span>

<span class="sd">    data: pandas.DataFrame</span>
<span class="sd">        The dataset in which to test the independence condition.</span>

<span class="sd">    boolean: bool</span>
<span class="sd">        If boolean=True, an additional argument `significance_level` must</span>
<span class="sd">            be specified. If p_value of the test is greater than equal to</span>
<span class="sd">            `significance_level`, returns True. Otherwise returns False.</span>

<span class="sd">        If boolean=False, returns the pearson correlation coefficient and p_value</span>
<span class="sd">            of the test.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    CI Test results: tuple or bool</span>
<span class="sd">        If boolean=True, returns True if p-value &gt;= significance_level, else False. If</span>
<span class="sd">        boolean=False, returns a tuple of (Pearson&#39;s correlation Coefficient, p-value)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] https://en.wikipedia.org/wiki/Pearson_correlation_coefficient</span>
<span class="sd">    [2] https://en.wikipedia.org/wiki/Partial_correlation#Using_linear_regression</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Step 1: Test if the inputs are correct</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="s2">&quot;__iter__&quot;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Variable Z. Expected type: iterable. Got type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Variable data. Expected type: pandas.DataFrame. Got type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Step 2: If Z is empty compute a non-conditional test.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">coef</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">X</span><span class="p">],</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Y</span><span class="p">])</span>

    <span class="c1"># Step 3: If Z is non-empty, use linear regression to compute residuals and test independence on it.</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X_coef</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z</span><span class="p">],</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">X</span><span class="p">],</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">Y_coef</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z</span><span class="p">],</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Y</span><span class="p">],</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">residual_X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">X</span><span class="p">]</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_coef</span><span class="p">)</span>
        <span class="n">residual_Y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Y</span><span class="p">]</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y_coef</span><span class="p">)</span>
        <span class="n">coef</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">residual_X</span><span class="p">,</span> <span class="n">residual_Y</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">boolean</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">p_value</span> <span class="o">&gt;=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;significance_level&quot;</span><span class="p">]:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">coef</span><span class="p">,</span> <span class="n">p_value</span></div>



<span class="k">def</span> <span class="nf">_get_predictions</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to get predictions using XGBoost for `ci_pillai`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Step 0: Check if XGboost is installed.</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span><span class="p">,</span> <span class="n">XGBRegressor</span>
    <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. xgboost is required for using pillai_trace test. Please install using: pip install xgboost&quot;</span>
        <span class="p">)</span> <span class="kn">from</span> <span class="kc">None</span>

    <span class="c1"># Step 1: Check if any of the conditional variables are categorical</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z</span><span class="p">]</span><span class="o">.</span><span class="n">dtypes</span> <span class="o">==</span> <span class="s2">&quot;category&quot;</span><span class="p">):</span>
        <span class="n">enable_categorical</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">enable_categorical</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Step 2: Check variable type of X, choose estimator, and compute predictions.</span>
    <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">X</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;category&quot;</span><span class="p">:</span>
        <span class="n">clf_x</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span>
            <span class="n">enable_categorical</span><span class="o">=</span><span class="n">enable_categorical</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seed&quot;</span><span class="p">),</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seed&quot;</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">x_cat_index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">factorize</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">X</span><span class="p">])</span>
        <span class="n">clf_x</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">pred_x</span> <span class="o">=</span> <span class="n">clf_x</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">clf_x</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span>
            <span class="n">enable_categorical</span><span class="o">=</span><span class="n">enable_categorical</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seed&quot;</span><span class="p">),</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seed&quot;</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">X</span><span class="p">]</span>
        <span class="n">x_cat_index</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">clf_x</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">pred_x</span> <span class="o">=</span> <span class="n">clf_x</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z</span><span class="p">])</span>

    <span class="c1"># Step 3: Check variable type of Y, choose estimator, and compute predictions.</span>
    <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Y</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;category&quot;</span><span class="p">:</span>
        <span class="n">clf_y</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span>
            <span class="n">enable_categorical</span><span class="o">=</span><span class="n">enable_categorical</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seed&quot;</span><span class="p">),</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seed&quot;</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">y_cat_index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">factorize</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Y</span><span class="p">])</span>
        <span class="n">clf_y</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">pred_y</span> <span class="o">=</span> <span class="n">clf_y</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">clf_y</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span>
            <span class="n">enable_categorical</span><span class="o">=</span><span class="n">enable_categorical</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seed&quot;</span><span class="p">),</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seed&quot;</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Y</span><span class="p">]</span>
        <span class="n">y_cat_index</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">clf_y</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">pred_y</span> <span class="o">=</span> <span class="n">clf_y</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z</span><span class="p">])</span>

    <span class="c1"># Step 4: Return the predictions.</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">pred_x</span><span class="p">,</span> <span class="n">pred_y</span><span class="p">,</span> <span class="n">x_cat_index</span><span class="p">,</span> <span class="n">y_cat_index</span><span class="p">)</span>


<div class="viewcode-block" id="pillai_trace">
<a class="viewcode-back" href="../../../structure_estimator/pc.html#pgmpy.estimators.CITests.pillai_trace">[docs]</a>
<span class="k">def</span> <span class="nf">pillai_trace</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A mixed-data residualization based conditional independence test[1].</span>

<span class="sd">    Uses XGBoost estimator to compute LS residuals[2], and then does an</span>
<span class="sd">    association test (Pillai&#39;s Trace) on the residuals.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: str</span>
<span class="sd">        The first variable for testing the independence condition X \u27c2 Y | Z</span>

<span class="sd">    Y: str</span>
<span class="sd">        The second variable for testing the independence condition X \u27c2 Y | Z</span>

<span class="sd">    Z: list/array-like</span>
<span class="sd">        A list of conditional variable for testing the condition X \u27c2 Y | Z</span>

<span class="sd">    data: pandas.DataFrame</span>
<span class="sd">        The dataset in which to test the independence condition.</span>

<span class="sd">    boolean: bool</span>
<span class="sd">        If boolean=True, an additional argument `significance_level` must</span>
<span class="sd">            be specified. If p_value of the test is greater than equal to</span>
<span class="sd">            `significance_level`, returns True. Otherwise returns False.</span>

<span class="sd">        If boolean=False, returns the pearson correlation coefficient and p_value</span>
<span class="sd">            of the test.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    CI Test results: tuple or bool</span>
<span class="sd">        If boolean=True, returns True if p-value &gt;= significance_level, else False. If</span>
<span class="sd">        boolean=False, returns a tuple of (Pearson&#39;s correlation Coefficient, p-value)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Ankan, Ankur, and Johannes Textor.</span>
<span class="sd">        &quot;A simple unified approach to testing high-dimensional&quot;</span>
<span class="sd">        &quot;conditional independences for categorical and ordinal data.&quot;</span>
<span class="sd">        Proceedings of the AAAI Conference on Artificial Intelligence.</span>
<span class="sd">    [2] Li, C.; and Shepherd, B. E. 2010.</span>
<span class="sd">      Test of Association Between Two Ordinal Variables While Adjusting for Covariates.</span>
<span class="sd">      Journal of the American Statistical Association.</span>
<span class="sd">    [3] Muller, K. E. and Peterson B. L. (1984) Practical Methods for computing power</span>
<span class="sd">      in testing the multivariate general linear hypothesis.</span>
<span class="sd">      Computational Statistics &amp; Data Analysis.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Step 1: Test if the inputs are correct</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="s2">&quot;__iter__&quot;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Variable Z. Expected type: iterable. Got type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Variable data. Expected type: pandas.DataFrame. Got type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Step 1.1: If no conditional variables are specified, use a constant value.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;cont_Z&quot;</span><span class="p">]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">cont_Z</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

    <span class="c1"># Step 2: Get the predictions</span>
    <span class="n">pred_x</span><span class="p">,</span> <span class="n">pred_y</span><span class="p">,</span> <span class="n">x_cat_index</span><span class="p">,</span> <span class="n">y_cat_index</span> <span class="o">=</span> <span class="n">_get_predictions</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># Step 3: Compute the residuals</span>
    <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">X</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;category&quot;</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">X</span><span class="p">])</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span>
            <span class="p">:,</span> <span class="n">x_cat_index</span><span class="o">.</span><span class="n">categories</span><span class="p">[</span><span class="n">x_cat_index</span><span class="o">.</span><span class="n">codes</span><span class="p">]</span>
        <span class="p">]</span>
        <span class="c1"># Drop last column to avoid multicollinearity</span>
        <span class="n">res_x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">pred_x</span><span class="p">)</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">res_x</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">X</span><span class="p">]</span> <span class="o">-</span> <span class="n">pred_x</span>

    <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Y</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;category&quot;</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Y</span><span class="p">])</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span>
            <span class="p">:,</span> <span class="n">y_cat_index</span><span class="o">.</span><span class="n">categories</span><span class="p">[</span><span class="n">y_cat_index</span><span class="o">.</span><span class="n">codes</span><span class="p">]</span>
        <span class="p">]</span>
        <span class="c1"># Drop last column to avoid multicollinearity</span>
        <span class="n">res_y</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">pred_y</span><span class="p">)</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">res_y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Y</span><span class="p">]</span> <span class="o">-</span> <span class="n">pred_y</span>

    <span class="c1"># Step 4: Compute Pillai&#39;s trace.</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">res_x</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
        <span class="n">res_x</span> <span class="o">=</span> <span class="n">res_x</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">res_y</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
        <span class="n">res_y</span> <span class="o">=</span> <span class="n">res_y</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>

    <span class="n">cca</span> <span class="o">=</span> <span class="n">CCA</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">res_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">res_y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">res_x_c</span><span class="p">,</span> <span class="n">res_y_c</span> <span class="o">=</span> <span class="n">cca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">res_x</span><span class="p">,</span> <span class="n">res_y</span><span class="p">)</span>

    <span class="n">cancor</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">res_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">res_y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])):</span>
        <span class="n">cancor</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">res_x_c</span><span class="p">[:,</span> <span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">res_y_c</span><span class="p">[:,</span> <span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">T</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

    <span class="n">coef</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">cancor</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="c1"># Step 5: Compute p-value using f-approximation [3].</span>
    <span class="n">s</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">res_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">res_y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">df1</span> <span class="o">=</span> <span class="n">res_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">res_y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">df2</span> <span class="o">=</span> <span class="n">s</span> <span class="o">*</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">s</span> <span class="o">-</span> <span class="n">res_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">res_y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">f_stat</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef</span> <span class="o">/</span> <span class="n">df1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">df2</span> <span class="o">/</span> <span class="p">(</span><span class="n">s</span> <span class="o">-</span> <span class="n">coef</span><span class="p">))</span>
    <span class="n">p_value</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">f_stat</span><span class="p">,</span> <span class="n">df1</span><span class="p">,</span> <span class="n">df2</span><span class="p">)</span>

    <span class="c1"># Step 6: Return</span>
    <span class="k">if</span> <span class="n">boolean</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">p_value</span> <span class="o">&gt;=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;significance_level&quot;</span><span class="p">]:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">coef</span><span class="p">,</span> <span class="n">p_value</span></div>



<div class="viewcode-block" id="gcm">
<a class="viewcode-back" href="../../../structure_estimator/pc.html#pgmpy.estimators.CITests.gcm">[docs]</a>
<span class="k">def</span> <span class="nf">gcm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">boolean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The Generalized Covariance Measure(GCM) test for CI.</span>

<span class="sd">    It performs linear regressions on the conditioning variable and then tests</span>
<span class="sd">    for a vanishing covariance between the resulting residuals. Details of the</span>
<span class="sd">    method can be found in [1].</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X: str</span>
<span class="sd">        The first variable for testing the independence condition X \u27c2 Y | Z</span>

<span class="sd">    Y: str</span>
<span class="sd">        The second variable for testing the independence condition X \u27c2 Y | Z</span>

<span class="sd">    Z: list/array-like</span>
<span class="sd">        A list of conditional variable for testing the condition X \u27c2 Y | Z</span>

<span class="sd">    data: pandas.DataFrame</span>
<span class="sd">        The dataset in which to test the independence condition.</span>

<span class="sd">    boolean: bool</span>
<span class="sd">        If boolean=True, an additional argument `significance_level` must</span>
<span class="sd">            be specified. If p_value of the test is greater than equal to</span>
<span class="sd">            `significance_level`, returns True. Otherwise returns False.</span>

<span class="sd">        If boolean=False, returns the pearson correlation coefficient and p_value</span>
<span class="sd">            of the test.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    CI Test results: tuple or bool</span>
<span class="sd">        If boolean=True, returns True if p-value &gt;= significance_level, else False. If</span>
<span class="sd">        boolean=False, returns a tuple of (Pearson&#39;s correlation Coefficient, p-value)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Rajen D. Shah, and Jonas Peters.</span>
<span class="sd">      &quot;The Hardness of Conditional Independence</span>
<span class="sd">        Testing and the Generalised Covariance Measure&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Step 1: Test if the inputs are correct</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="s2">&quot;__iter__&quot;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Variable Z. Expected type: iterable. Got type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Variable data. Expected type: pandas.DataFrame. Got type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Step 1.1: Add another column with constant values to handle intercepts. When Z=[],</span>
    <span class="c1">#           this can act as the constant vector.</span>
    <span class="n">Z</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;intercept&quot;</span><span class="p">]</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">intercept</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

    <span class="c1"># Step 2: Compute the linear regression and the residuals</span>
    <span class="n">X_coef</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z</span><span class="p">],</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">X</span><span class="p">],</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">Y_coef</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z</span><span class="p">],</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Y</span><span class="p">],</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">res_x</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">X</span><span class="p">]</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_coef</span><span class="p">)</span>
    <span class="n">res_y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Y</span><span class="p">]</span> <span class="o">-</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">Z</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y_coef</span><span class="p">)</span>

    <span class="c1"># Step 3: Compute the Generalised Covariance Measure.</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">res_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">t_stat</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">res_x</span><span class="p">,</span> <span class="n">res_y</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">res_x</span> <span class="o">*</span> <span class="n">res_y</span><span class="p">)</span>

    <span class="c1"># Step 4: Compute p-value using standard normal distribution.</span>
    <span class="n">p_value</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_stat</span><span class="p">)))</span>

    <span class="c1"># Step 6: Return</span>
    <span class="k">if</span> <span class="n">boolean</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">p_value</span> <span class="o">&gt;=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;significance_level&quot;</span><span class="p">]:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">t_stat</span><span class="p">,</span> <span class="n">p_value</span></div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../../../index.html">
    <img class="logo" src="../../../_static/logo.png" alt="Logo" />
    
  </a>
</p>









<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../started/base.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models/base.html">Supported Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../factors/base.html">Parameterization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../infer/base.html">Probabilistic Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../causal_infer/base.html">Causal Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../param_estimator/base.html">Parameter Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../structure_estimator/base.html">Causal Discovery / Structure Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../metrics/metrics.html">Metrics for Testing Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../readwrite/base.html">Reading/Writing to File</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../plotting.html">Plotting Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorial.html">Tutorial Notebooks</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  <li><a href="../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div><script async src="https://media.ethicalads.io/media/client/ethicalads.min.js"></script>

<div data-ea-publisher="pgmpyorg" data-ea-type="image" data-ea-style="horizontal"></div><script async src="https://www.googletagmanager.com/gtag/js?id=G-HCFR07M31W"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-HCFR07M31W');
</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2025, Ankur Ankan.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.2.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
    </div>

    

    
  </body>
</html>